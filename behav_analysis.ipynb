{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "\n",
    "class Data_Functions:\n",
    "    \"\"\"\n",
    "    This class contains functions used for processing experiment files as well as\n",
    "    participant, behavioral, and physiological data.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_par(self, par_num: list[str | int]) -> Tuple[int, str]:\n",
    "        \"\"\"\n",
    "        Create the participant number and ID.\n",
    "\n",
    "        Args:\n",
    "            par_num (list[str  |  int]): Participant number.\n",
    "\n",
    "        Raises:\n",
    "            Exception: Invalid participant number.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[int, str]:\n",
    "                Participant number\n",
    "                -and-\n",
    "                Participant ID\n",
    "        \"\"\"\n",
    "        if isinstance(par_num, str):\n",
    "            par_num = int(par_num)\n",
    "        elif isinstance(par_num, int):\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(\"Invalid participant number.\")\n",
    "        par_num_str = \"{:02d}\".format(par_num)\n",
    "        par_ID = f\"participant_{par_num_str}\"\n",
    "        return par_num, par_ID\n",
    "\n",
    "    def parse_log_file(self, par_dir: str, exp_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Parses the experiment log file into start and end marker data.\n",
    "\n",
    "        Args:\n",
    "            par_dir (str): Path to specific participant directory\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            dict: Start and end marker data\n",
    "                keys:\n",
    "                    'start_marker', 'end_marker'\n",
    "                values:\n",
    "                    start marker dictionary, end marker dictionary\n",
    "                        keys:\n",
    "                            'marker_ID', 'marker_value', 'marker_string', 'timestamp'\n",
    "                        values:\n",
    "                            'marker_ID', 'marker_value', 'marker_string', 'timestamp'\n",
    "        \"\"\"\n",
    "\n",
    "        def _parse_udp(udp: str) -> dict:\n",
    "            \"\"\"\n",
    "            Parses UDP file lines into marker information.\n",
    "\n",
    "            Args:\n",
    "                udp (str): File line with UDP data\n",
    "\n",
    "            Returns:\n",
    "                dict: Marker data\n",
    "                    keys:\n",
    "                        'marker_ID', 'marker_value', 'marker_string', 'timestamp'\n",
    "                    values:\n",
    "                        'marker_ID', 'marker_value', 'marker_string', 'timestamp'\n",
    "            \"\"\"\n",
    "            marker_ID_info = udp[2].strip(\",\").split(\"=\")\n",
    "            marker_ID_str = marker_ID_info[0]\n",
    "            marker_ID = marker_ID_info[1]\n",
    "\n",
    "            marker_val_info = udp[3].strip(\",\").split(\"=\")\n",
    "            marker_val_str = marker_val_info[0]\n",
    "            marker_val = marker_val_info[1]\n",
    "\n",
    "            marker_string_info = udp[4].strip(\",\").split(\"=\")\n",
    "            marker_string_str = marker_string_info[0]\n",
    "            marker_string = marker_string_info[1]\n",
    "\n",
    "            marker_ts_info = udp[5].strip(\"\\n\").split(\"=\")\n",
    "            marker_ts_str = marker_ts_info[0]\n",
    "            marker_ts = marker_ts_info[1]\n",
    "\n",
    "            marker_dict = {\n",
    "                marker_ID_str: marker_ID,\n",
    "                marker_val_str: marker_val,\n",
    "                marker_string_str: marker_string,\n",
    "                marker_ts_str: marker_ts,\n",
    "            }\n",
    "\n",
    "            return marker_dict\n",
    "\n",
    "        log_dir = os.path.join(par_dir, exp_name, \"data\")\n",
    "        for filename in os.listdir(log_dir):\n",
    "            if \".log\" in filename:\n",
    "                log_filename = filename\n",
    "        log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "        with open(log_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        udp_lines = []\n",
    "        for line in lines:\n",
    "            if \"UDP\" in line:  # only select lines with UDP info\n",
    "                udp_lines.append(line.split(\"\\t\")[-1])\n",
    "\n",
    "        marker_data = {}\n",
    "        try:\n",
    "            start_udp = udp_lines[0].split(\" \")\n",
    "            marker_data[\"start_marker\"] = _parse_udp(start_udp)\n",
    "        except:\n",
    "            marker_data[\"start_marker\"] = \"_\"\n",
    "        try:\n",
    "            end_udp = udp_lines[1].split(\" \")\n",
    "            marker_data[\"end_marker\"] = _parse_udp(end_udp)\n",
    "        except:\n",
    "            if (\n",
    "                exp_name == \"go_no_go\"\n",
    "            ):  # Go/No-go start marker did not write to log file\n",
    "                marker_ID = int(marker_data[\"start_marker\"][\"marker_ID\"]) + 1\n",
    "                marker_val = 22\n",
    "                marker_string = \"go_no_go_end\"\n",
    "                end_ts = marker_data[\"start_marker\"][\"timestamp\"]\n",
    "                end_ts = int(\n",
    "                    float(end_ts) + float(lines[-1].split(\"\\t\")[0]) * 1e9 - 0.4 * 1e9\n",
    "                )\n",
    "                marker_data[\"end_marker\"] = {\n",
    "                    \"marker_ID\": marker_ID,\n",
    "                    \"marker_value\": marker_val,\n",
    "                    \"marker_string\": marker_string,\n",
    "                    \"timestamp\": end_ts,\n",
    "                }\n",
    "            else:\n",
    "                marker_data[\"end_marker\"] = \"_\"\n",
    "\n",
    "        return marker_data\n",
    "\n",
    "    def parse_narrative_log_file(self, par_dir: str, exp_name: str) -> float:\n",
    "        \"\"\"\n",
    "        Parses the narrative log file to get the end timestamp for narrative experiments.\n",
    "\n",
    "        Args:\n",
    "            par_dir (str): Path to specific participant directory\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            float: End timestamp of a narrative experiment\n",
    "        \"\"\"\n",
    "        log_dir = os.path.join(par_dir, exp_name, \"data\")\n",
    "        for filename in os.listdir(log_dir):\n",
    "            if \".log\" in filename:\n",
    "                log_filename = filename\n",
    "        log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "        with open(log_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        udp_lines = []\n",
    "        for line in lines:\n",
    "            if \"UDP\" in line:\n",
    "                udp_lines.append(line.split(\"\\t\")[0])\n",
    "\n",
    "        end_time = float(udp_lines[1]) * 1e9\n",
    "\n",
    "        return end_time\n",
    "\n",
    "    def parse_task_order_file(self, par_dir: str, exp_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Parses the task order file to get the order of task CSV files for a given experiment.\n",
    "\n",
    "        Args:\n",
    "            par_dir (str): Path to specific participant directory\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Column of task order CSV filenames\n",
    "                column name: 'task_order'\n",
    "        \"\"\"\n",
    "\n",
    "        exp_dir = os.path.join(par_dir, exp_name)\n",
    "        for filename in os.listdir(exp_dir):\n",
    "            if \".csv\" in filename:\n",
    "                task_order_filename = filename\n",
    "        task_order_filepath = os.path.join(exp_dir, task_order_filename)\n",
    "        task_order = pd.read_csv(task_order_filepath)\n",
    "\n",
    "        return task_order\n",
    "\n",
    "    def get_data_filepath(self, par_dir: str, exp_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Gets the file path to the data CSV file for a given experiment.\n",
    "\n",
    "        Args:\n",
    "            par_dir (str): Path to specific participant directory\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            str: Path to experiment CSV data file\n",
    "        \"\"\"\n",
    "\n",
    "        data_dir = os.path.join(par_dir, exp_name, \"data\")\n",
    "        for filename in os.listdir(data_dir):\n",
    "            if \".csv\" in filename:\n",
    "                data_filename = filename\n",
    "        data_filepath = os.path.join(data_dir, data_filename)\n",
    "\n",
    "        return data_filepath\n",
    "\n",
    "    def get_all_marker_timestamps(self, par_dir: str, exp_order: list) -> dict:\n",
    "        \"\"\"\n",
    "        Organize the start and end timestamps for each experiment into a dictionary.\n",
    "\n",
    "        Args:\n",
    "            par_dir (str): Path to specific participant directory\n",
    "            exp_order (list): _description_\n",
    "\n",
    "        Returns:\n",
    "            dict: Start and end timestamps for each experiment\n",
    "                keys:\n",
    "                     'audio_narrative', 'go_no_go', 'king_devick', 'n_back', 'resting_state',\n",
    "                     'tower_of_london', 'video_narrative_cmiyc', 'video_narrative_sherlock', 'vSAT'\n",
    "                values:\n",
    "                    [start timestamp, end timestamp]\n",
    "        \"\"\"\n",
    "        all_marker_timestamps = {}\n",
    "        for exp_name in exp_order:\n",
    "            marker_dict = self.parse_log_file(par_dir=par_dir, exp_name=exp_name)\n",
    "            start_marker, end_marker = (\n",
    "                marker_dict[\"start_marker\"],\n",
    "                marker_dict[\"end_marker\"],\n",
    "            )\n",
    "            if (\n",
    "                \"narrative\" in exp_name\n",
    "                and \"participant_01\" not in par_dir\n",
    "                and \"participant_02\" not in par_dir\n",
    "                and \"participant_03\" not in par_dir\n",
    "            ):  # Narrative experiment timestamps changed for Participant 04+\n",
    "                try:\n",
    "                    start_ts = start_marker[\"timestamp\"]\n",
    "                except:\n",
    "                    start_ts = \"_\"\n",
    "                    print(\"Start marker not found for {exp_name}\")\n",
    "                try:\n",
    "                    end_ts = float(start_ts) + self.parse_narrative_log_file(\n",
    "                        par_dir, exp_name\n",
    "                    )\n",
    "                except:\n",
    "                    print(\"End marker not found for {exp_name}\")\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    start_ts = start_marker[\"timestamp\"]\n",
    "                except:\n",
    "                    start_ts = \"_\"\n",
    "                    print(\"Start marker not found for {exp_name}\")\n",
    "\n",
    "                try:\n",
    "                    end_ts = end_marker[\"timestamp\"]\n",
    "                except:\n",
    "                    end_ts = \"_\"\n",
    "                    print(\"End marker not found for {exp_name}\")\n",
    "            all_marker_timestamps[exp_name] = [start_ts, end_ts]\n",
    "\n",
    "        return all_marker_timestamps\n",
    "\n",
    "    def get_cols(self, df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get a selection of columns from a given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Experiment data\n",
    "            cols (list): List of columns to select from the DataFrame\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with selected columns only\n",
    "        \"\"\"\n",
    "        return df[cols]\n",
    "\n",
    "    def create_col(self, x, num_rows: int, dtype=object) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Create a Series column of a value.\n",
    "\n",
    "        Args:\n",
    "            x (Any): Value for each row in the column\n",
    "            num_rows (int): Number of rows in the column\n",
    "            dtype (_type_, optional): Type of x\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: Column with num_rows rows of x\n",
    "        \"\"\"\n",
    "        return pd.Series([x] * num_rows, dtype=dtype)\n",
    "\n",
    "    def flatten(self, input_list: List[list]) -> list:\n",
    "        \"\"\"\n",
    "        Flatten a list of lists into a single list.\n",
    "\n",
    "        Args:\n",
    "            input_list (List[list]): List of lists\n",
    "\n",
    "        Returns:\n",
    "            list: Single list with all elements of the input list\n",
    "        \"\"\"\n",
    "        return [x for xs in input_list for x in xs]\n",
    "\n",
    "    def parse_df(\n",
    "        self, df: pd.DataFrame, num_blocks: int, num_trials: int\n",
    "    ) -> Tuple[dict, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Parses a DataFrame into a dictionary organized by block and a DataFrame with NaN rows removed.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame to prase\n",
    "            num_blocks (int): Number of blocks in the experiment\n",
    "            num_trials (int): Number of trials in the experiment\n",
    "\n",
    "        Returns:\n",
    "            Tuple[dict, pd.DataFrame]:\n",
    "                dict: dictionary organized by block\n",
    "                    keys:\n",
    "                        'block_1', 'block2', ... 'block_N'\n",
    "                    values:\n",
    "                        DataFrame of behavioral data for that block\n",
    "                pd.DataFrame: DataFrame with no NaN rows\n",
    "        \"\"\"\n",
    "        df_by_block = {}\n",
    "        for i in range(num_blocks):\n",
    "            block_name = f\"block_{i+1}\"\n",
    "            if i == 0:\n",
    "                temp_df = df.iloc[\n",
    "                    i * num_trials : (i + 1) * num_trials\n",
    "                ]  # select rows for this block\n",
    "                df_no_nan = temp_df.copy()\n",
    "            else:\n",
    "                temp_df = df.iloc[\n",
    "                    (i * num_trials) + i : ((i + 1) * num_trials) + i\n",
    "                ]  # skip Nan line between blocks\n",
    "                df_no_nan = pd.concat([df_no_nan, temp_df])\n",
    "            df_by_block[block_name] = temp_df\n",
    "\n",
    "        return df_by_block, df_no_nan\n",
    "\n",
    "    def get_exp_ts(self, df: pd.DataFrame, exp_name: str) -> Tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Get the start and end timestamps from an experiment-organized DataFrame\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with experiment-organized start and end marker timestamps\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            Tuple[int, int]: start timestamp, end timestamp\n",
    "        \"\"\"\n",
    "        df_temp = df[df[\"exp_name\"] == exp_name]\n",
    "        start_ts = df_temp[\"start_timestamp\"].item()\n",
    "        end_ts = df_temp[\"end_timestamp\"].item()\n",
    "\n",
    "        return start_ts, end_ts\n",
    "\n",
    "    def get_exp_dt(\n",
    "        self, df: pd.DataFrame, exp_name: str\n",
    "    ) -> Tuple[datetime.datetime, datetime.datetime]:\n",
    "        \"\"\"\n",
    "        Get the start and end datetimes from an experiment-organized DataFrame\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with experiment-organized start and end marker timestamps\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            Tuple[datetime.datetime, datetime.datetime]: start datetime, end datetime\n",
    "        \"\"\"\n",
    "        df_temp = df[df[\"exp_name\"] == exp_name]\n",
    "        start_dt = datetime.datetime.fromtimestamp(\n",
    "            df_temp[\"start_timestamp\"].item() / 1e9\n",
    "        )\n",
    "        end_dt = datetime.datetime.fromtimestamp(df_temp[\"end_timestamp\"].item() / 1e9)\n",
    "\n",
    "        return start_dt, end_dt\n",
    "\n",
    "    def get_start_index_dt(\n",
    "        self, df: pd.DataFrame, start_dt: datetime.datetime\n",
    "    ) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Get the index of the start datetime of an experiment\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Experiment data with datetime column\n",
    "            start_dt (datetime.datetime): Start datetime of the experiment\n",
    "\n",
    "        Returns:\n",
    "            Optional[int]: Start index or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for loc, dt in enumerate(df[\"datetime\"]):\n",
    "                if not dt < start_dt:\n",
    "                    break\n",
    "            if loc < df[\"datetime\"].shape[0] - 1:\n",
    "                return loc\n",
    "            else:\n",
    "                print(\"Start index datetime not found!\")\n",
    "                return None\n",
    "        except:\n",
    "            print(\"Start index datetime not found!\")\n",
    "            return None\n",
    "\n",
    "    def get_end_index_dt(\n",
    "        self, df: pd.DataFrame, end_dt: datetime.datetime\n",
    "    ) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Get the index of the end datetime of an experiment\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Experiment data with datetime column\n",
    "            end_dt (datetime.datetime): End datetime of the experiment\n",
    "\n",
    "        Returns:\n",
    "            Optional[int]: End index or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for loc, dt in enumerate(df[\"datetime\"]):\n",
    "                if dt > end_dt:\n",
    "                    break\n",
    "            return loc\n",
    "        except:\n",
    "            print(\"End index datetime not found!\")\n",
    "            return None\n",
    "\n",
    "    def get_start_index_ts(self, df: pd.DataFrame, start_ts: float) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Get the index of the start timestamp of an experiment\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Experiment data with timestamp column\n",
    "            start_ts (float): Start timestamp of the experiment\n",
    "\n",
    "        Returns:\n",
    "            Optional[int]: Start index or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for loc, ts in enumerate(df[\"timestamps\"]):\n",
    "                if not ts < start_ts:\n",
    "                    break\n",
    "            if loc < df[\"timestamps\"].shape[0] - 1:\n",
    "                return loc\n",
    "            else:\n",
    "                print(\"Start index timestamp not found!\")\n",
    "                return None\n",
    "        except:\n",
    "            print(\"Start index timestamp not found!\")\n",
    "            return None\n",
    "\n",
    "    def get_end_index_ts(self, df: pd.DataFrame, end_ts: float) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Get the index of the end timestamp of an experiment\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Experiment data with timestamp column\n",
    "            end_ts (float): End timestamp of the experiment\n",
    "\n",
    "        Returns:\n",
    "            Optional[int]: End index or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for loc, ts in enumerate(df[\"timestamps\"]):\n",
    "                if ts > end_ts:\n",
    "                    break\n",
    "            return loc\n",
    "        except:\n",
    "            print(\"End index timestamp not found!\")\n",
    "            return None\n",
    "\n",
    "    def adjust_df_ts(\n",
    "        self, df: pd.DataFrame, start_ts: int, cols: list, by_block: bool = False\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Offset experiment times by the initial timestamp of the experiment (relative to absolute timestamps).\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame to time-adjust\n",
    "            start_ts (int): Start timestamp of the experiment\n",
    "            cols (list): Columns to adjust the timestamps of\n",
    "            by_block (bool, optional): Is the DataFrame organized by block? Defaults to False\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Timestamp-adjusted DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        if by_block:\n",
    "            for block, temp_df in df.items():\n",
    "                temp_df = temp_df.copy()\n",
    "                for col in cols:\n",
    "                    temp_df[col] = (\n",
    "                        temp_df[col] + start_ts\n",
    "                    )  # add start timestamp to relative timestamps\n",
    "                df[block] = temp_df\n",
    "        else:\n",
    "            for col in cols:\n",
    "                df[col] = (\n",
    "                    df[col] + start_ts\n",
    "                )  # add start timestamp to relative timestamps\n",
    "        return df\n",
    "\n",
    "    def c_to_f(self, temp: float) -> float:\n",
    "        \"\"\"\n",
    "        Convert celsius to fahrenheit.\n",
    "\n",
    "        Args:\n",
    "            temp (float): Temperature in fahrenheit\n",
    "\n",
    "        Returns:\n",
    "            float: Temperature in celsius\n",
    "        \"\"\"\n",
    "        return round(temp * 9 / 5 + 32, 2)\n",
    "\n",
    "\n",
    "class Audio_Narrative(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Audio Narrative experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        clip_duration: Number of seconds in the narrative clip\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        response: Participant response to the narrative\n",
    "        block_start_time: Start timestamp of the narrative clip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"audio_narrative\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.clip_duration = 423  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "\n",
    "        cols = [\"pieman_clip.started\", \"participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"pieman_clip.ended\",\n",
    "            self.df_simp[\"pieman_clip.started\"] + self.clip_duration,\n",
    "        )\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\n",
    "                \"Audio Narrative: Need to combine 'participant response' columns into a single column.\"\n",
    "            )\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"pieman_clip.started\"][0]\n",
    "\n",
    "\n",
    "class Go_No_Go(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Go/No-Go experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"go_no_go\"\n",
    "        self.num_blocks = 4\n",
    "        self.num_trials = 20\n",
    "        # NOTE: stimulus duration depends on participant response\n",
    "        # NOTE: inter-stimulus duration is variable\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\n",
    "            \"match\",\n",
    "            \"GNG_stim\",\n",
    "            \"inter_stim_plus.started\",\n",
    "            \"go_image.started\",\n",
    "            \"go_resp.corr\",\n",
    "            \"go_resp.rt\",\n",
    "        ]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp = self.df_simp.copy()\n",
    "        self.df_simp[\"GNG_stim\"] = self.df_simp[\"GNG_stim\"].apply(self._strip_stim)\n",
    "        self.df_simp.insert(\n",
    "            3,\n",
    "            \"inter_stim_plus.ended\",\n",
    "            self.df_simp[\"inter_stim_plus.started\"] + self.df[\"inter_stim_interval\"],\n",
    "        )\n",
    "        self.df_simp.insert(\n",
    "            5,\n",
    "            \"go_image.ended\",\n",
    "            self.df_simp[\"go_image.started\"] + self.df_simp[\"go_resp.rt\"],\n",
    "        )\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "    def _strip_stim(self, row):\n",
    "        try:\n",
    "            return row.split(\"\\\\\")[0].split(\"_stimuli\")[0]\n",
    "        except:\n",
    "            return row\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_go_list = []\n",
    "        self.num_corr_gng_list = []\n",
    "\n",
    "        for i, block in enumerate(df_by_block.values()):\n",
    "            if (i + 1) % 2 != 0:  # Go blocks\n",
    "                num_corr_go = int(sum(block[\"go_resp.corr\"]))\n",
    "                self.num_corr_go_list.append(num_corr_go)\n",
    "            else:  # Go/No-Go blocks\n",
    "                num_corr_gng = int(sum(block[\"go_resp.corr\"]))\n",
    "                self.num_corr_gng_list.append(num_corr_gng)\n",
    "\n",
    "        self.total_corr_go = sum(self.num_corr_go_list)\n",
    "        self.total_corr_gng = sum(self.num_corr_gng_list)\n",
    "        self.total_corr = self.total_corr_go + self.total_corr_gng\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_go_list = []\n",
    "        self.resp_time_gng_list = []\n",
    "\n",
    "        for i, block in enumerate(df_by_block.values()):\n",
    "            if (i + 1) % 2 != 0:  # Go blocks\n",
    "                try:  # handle Nan\n",
    "                    resp_time_go = np.nanmean(block[\"go_resp.rt\"])\n",
    "                    self.resp_time_go_list.append(resp_time_go)\n",
    "                except:\n",
    "                    pass\n",
    "            else:  # Go/No-Go blocks\n",
    "                try:  # handle Nan\n",
    "                    resp_time_gng = np.nanmean(block[\"go_resp.rt\"])\n",
    "                    self.resp_time_gng_list.append(resp_time_gng)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        self.avg_resp_time_go = mean(self.resp_time_go_list)\n",
    "        self.avg_resp_time_gng = mean(self.resp_time_gng_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_go, self.avg_resp_time_gng]\n",
    "\n",
    "\n",
    "class King_Devick(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the King Devick experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_new: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"king_devick\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 3\n",
    "        self.num_trials_new = 4  # added a card for participants 15+\n",
    "        # NOTE: card duration depends on participant response\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = [\"card_1\", \"card_2\", \"card_3\"]\n",
    "        self.task_order_new = [\n",
    "            \"card_1\",\n",
    "            \"card_2\",\n",
    "            \"card_3\",\n",
    "            \"card_4\",\n",
    "        ]  # added a card for participants 15+\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        num_incorrect_col = pd.Series(self._parse_data_file(par_dir=par_dir))\n",
    "        self.df.insert(len(self.df.columns), \"num_incorrect\", num_incorrect_col)\n",
    "        cols = [\"card_image.started\", \"card_resp.rt\", \"num_incorrect\"]\n",
    "        self.df_simp = self.get_cols(self.df, cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"card_image.ended\",\n",
    "            self.df_simp[\"card_image.started\"] + self.df_simp[\"card_resp.rt\"],\n",
    "        )\n",
    "\n",
    "    def _parse_data_file(self, par_dir):\n",
    "        data_dir = os.path.join(par_dir, self.exp_name, \"data\")\n",
    "        for filename in os.listdir(data_dir):\n",
    "            if \"data.txt\" in filename:\n",
    "                data_filename = filename\n",
    "        data_filepath = os.path.join(data_dir, data_filename)\n",
    "\n",
    "        with open(data_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        par_resp = []\n",
    "        for line in lines:\n",
    "            if \"number incorrect\" in line:\n",
    "                par_resp.append(line.split(\" \")[-1].strip(\"\\n\"))\n",
    "\n",
    "        return par_resp\n",
    "\n",
    "\n",
    "class N_Back(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the N-Back experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        stim_duration: Duration of stimulus\n",
    "        inter_stim_duration: Duration between stimuli\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"n_back\"\n",
    "        self.num_blocks = 9\n",
    "        self.num_trials = 20\n",
    "        self.stim_duration = 0.5  # seconds\n",
    "        self.inter_stim_duration = 3.0  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp, self.task_order_simp2 = self._simp_task_order(\n",
    "            task_order=self.task_order\n",
    "        )\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"match\", \"stim_text.started\", \"stim_resp.corr\", \"stim_resp.rt\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            2, \"stim_text.ended\", self.df_simp[\"stim_text.started\"] + 0.5\n",
    "        )  # stimulus duration is 0.5 seconds\n",
    "        self.df_simp.insert(\n",
    "            3, \"inter_stim.started\", self.df_simp[\"stim_text.started\"] + 0.5\n",
    "        )  # inter-stimulus interval starts 0.5 seconds after stimulus\n",
    "        self.df_simp.insert(\n",
    "            4, \"inter_stim.ended\", self.df_simp[\"inter_stim.started\"] + 3\n",
    "        )  # inter-stimulus duration is 3 seconds\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_ZB_list = []\n",
    "        self.num_corr_OB_list = []\n",
    "        self.num_corr_TB_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if \"0_back\" in task_type:\n",
    "                num_corr_ZB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_ZB_list.append(num_corr_ZB)\n",
    "            elif \"1_back\" in task_type:\n",
    "                num_corr_OB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_OB_list.append(num_corr_OB)\n",
    "            elif \"2_back\" in task_type:\n",
    "                num_corr_TB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_TB_list.append(num_corr_TB)\n",
    "\n",
    "        self.total_corr_ZB = sum(self.num_corr_ZB_list)\n",
    "        self.total_corr_OB = sum(self.num_corr_OB_list)\n",
    "        self.total_corr_TB = sum(self.num_corr_TB_list)\n",
    "        self.total_corr = self.total_corr_ZB + self.total_corr_OB + self.total_corr_TB\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_ZB_list = []\n",
    "        self.resp_time_OB_list = []\n",
    "        self.resp_time_TB_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if \"0_back\" in task_type:\n",
    "                resp_time_ZB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_ZB_list.append(resp_time_ZB)\n",
    "            elif \"1_back\" in task_type:\n",
    "                resp_time_OB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_OB_list.append(resp_time_OB)\n",
    "            elif \"2_back\" in task_type:\n",
    "                resp_time_TB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_TB_list.append(resp_time_TB)\n",
    "\n",
    "        self.avg_resp_time_ZB = mean(self.resp_time_ZB_list)\n",
    "        self.avg_resp_time_OB = mean(self.resp_time_OB_list)\n",
    "        self.avg_resp_time_TB = mean(self.resp_time_TB_list)\n",
    "        self.avg_resp_time = [\n",
    "            self.avg_resp_time_ZB,\n",
    "            self.avg_resp_time_OB,\n",
    "            self.avg_resp_time_TB,\n",
    "        ]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = []\n",
    "        task_order_simp2 = []\n",
    "        for task in task_order:\n",
    "            if \"ZB\" in task:\n",
    "                temp = task.split(\"-\")\n",
    "                task_simp = f\"0_back-{temp[1]}\"\n",
    "                task_simp2 = \"0_back\"\n",
    "            elif \"OB\" in task:\n",
    "                task_simp = \"1_back\"\n",
    "                task_simp2 = \"1_back\"\n",
    "            elif \"TB\" in task:\n",
    "                task_simp = \"2_back\"\n",
    "                task_simp2 = \"2_back\"\n",
    "            task_order_simp.append(task_simp)\n",
    "            task_order_simp2.append(task_simp2)\n",
    "\n",
    "        return task_order_simp, task_order_simp2\n",
    "\n",
    "\n",
    "class Resting_State(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Resting State experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        session_duration: Duration of each session (eyes open and eyes closed)\n",
    "        inter_stim_duration: Duration between stimuli\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"resting_state\"\n",
    "        self.num_blocks = 2\n",
    "        self.num_trials = 1\n",
    "        self.session_duration = 210  # seconds for each task (eyes open and eyes closed)\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"trial_cross.started\", \"halfway_tone.started\", \"done_sound.started\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.replace(\" \", \"_\") for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "\n",
    "class Tower_of_London(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Tower of London experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        stim_duration: Duration of stimulus\n",
    "        response_duration: Duration the participant has to respond\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"tower_of_london\"\n",
    "        self.num_blocks = 6\n",
    "        self.num_trials = 6\n",
    "        self.stim_duration = 7  # seconds\n",
    "        self.response_duration = 3  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\n",
    "            \"match\",\n",
    "            \"image_stim\",\n",
    "            \"stim_image.started\",\n",
    "            \"stim_text.started\",\n",
    "            \"stim_resp.corr\",\n",
    "            \"stim_resp.rt\",\n",
    "        ]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp = self.df_simp.copy()\n",
    "        self.df_simp[\"image_stim\"] = self.df_simp[\"image_stim\"].apply(self._strip_stim)\n",
    "        self.df_simp.insert(\n",
    "            3,\n",
    "            \"stim_image.ended\",\n",
    "            self.df_simp[\"stim_image.started\"] + self.stim_duration,\n",
    "        )\n",
    "        self.df_simp.insert(\n",
    "            5,\n",
    "            \"stim_text.ended\",\n",
    "            self.df_simp[\"stim_text.started\"] + self.response_duration,\n",
    "        )\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _strip_stim(self, row):\n",
    "        try:\n",
    "            temp_list = row.split(\"\\\\\")\n",
    "            if len(temp_list) == 3:\n",
    "                return temp_list[1].split(\"stim_\")[1]\n",
    "            else:\n",
    "                return temp_list[0].split(\"_stimuli\")[0]\n",
    "        except:\n",
    "            return row\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_MM_list = []\n",
    "        self.num_corr_ZM_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"MM\":\n",
    "                num_corr_MM = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_MM_list.append(num_corr_MM)\n",
    "            elif task_type == \"ZM\":\n",
    "                num_corr_ZM = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_ZM_list.append(num_corr_ZM)\n",
    "\n",
    "        self.total_corr_MM = sum(self.num_corr_MM_list)\n",
    "        self.total_corr_ZM = sum(self.num_corr_ZM_list)\n",
    "        self.total_corr = self.total_corr_MM + self.total_corr_ZM\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_MM_list = []\n",
    "        self.resp_time_ZM_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"MM\":\n",
    "                resp_time_MM = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_MM_list.append(resp_time_MM)\n",
    "            elif task_type == \"ZM\":\n",
    "                resp_time_ZM = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_ZM_list.append(resp_time_ZM)\n",
    "\n",
    "        self.avg_resp_time_MM = mean(self.resp_time_MM_list)\n",
    "        self.avg_resp_time_ZM = mean(self.resp_time_ZM_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_MM, self.avg_resp_time_ZM]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "\n",
    "class Video_Narrative_CMIYC(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Video Narrative CMIYC experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        clip_duration: Number of seconds in the narrative clip\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        response: Participant response to the narrative\n",
    "        block_start_time: Start timestamp of the narrative clip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"video_narrative_cmiyc\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.clip_duration = 300  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"video_start.started\", \"catchme_participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"video_start.ended\",\n",
    "            self.df_simp[\"video_start.started\"] + self.clip_duration,\n",
    "        )\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"catchme_participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\n",
    "                \"Video Narrative CMIYC: Need to combine 'participant response' columns into a single column.\"\n",
    "            )\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"video_start.started\"][0]\n",
    "\n",
    "\n",
    "class Video_Narrative_Sherlock(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Video Narrative Sherlock experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        clip_duration: Number of seconds in the narrative clip\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        response: Participant response to the narrative\n",
    "        block_start_time: Start timestamp of the narrative clip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"video_narrative_sherlock\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.clip_duration = 300  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"video_start.started\", \"sherlock_participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"video_start.ended\",\n",
    "            self.df_simp[\"video_start.started\"] + self.clip_duration,\n",
    "        )\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"sherlock_participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\n",
    "                \"ERROR: Sherlock - Need to combine 'participant response' columns into a single column.\"\n",
    "            )\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"video_start.started\"][0]\n",
    "\n",
    "\n",
    "class vSAT(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the vSAT experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"vSAT\"\n",
    "        self.num_blocks = 4\n",
    "        self.num_trials = 30\n",
    "        # NOTE: stimulus duration is variable\n",
    "        # NOTE: stimulus location is variable\n",
    "        # NOTE: inter-stimulus duration is variable\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\n",
    "            \"match\",\n",
    "            \"stim_time\",\n",
    "            \"inter_stim_time\",\n",
    "            \"x_pos\",\n",
    "            \"y_pos\",\n",
    "            \"inter_stim_text.started\",\n",
    "            \"vSAT_square.started\",\n",
    "            \"stim_resp.corr\",\n",
    "            \"stim_resp.rt\",\n",
    "            \"feedback_sound.started\",\n",
    "        ]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self._add_pos_col()\n",
    "        self.df_simp.insert(\n",
    "            5,\n",
    "            \"inter_stim_text.ended\",\n",
    "            self.df_simp[\"inter_stim_text.started\"] + self.df_simp[\"inter_stim_time\"],\n",
    "        )\n",
    "        self.df_simp.insert(\n",
    "            7,\n",
    "            \"vSAT_square.ended\",\n",
    "            self.df_simp[\"vSAT_square.started\"] + self.df_simp[\"stim_time\"],\n",
    "        )\n",
    "        self.df_simp.insert(\n",
    "            11, \"feedback_sound.ended\", self.df_simp[\"feedback_sound.started\"] + 0.5\n",
    "        )  # 0.5 second feedback sound\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_SAT_list = []\n",
    "        self.num_corr_vSAT_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"SAT\":\n",
    "                num_corr_SAT = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_SAT_list.append(num_corr_SAT)\n",
    "            elif task_type == \"vSAT\":\n",
    "                num_corr_vSAT = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_vSAT_list.append(num_corr_vSAT)\n",
    "\n",
    "        self.total_corr_SAT = sum(self.num_corr_SAT_list)\n",
    "        self.total_corr_vSAT = sum(self.num_corr_vSAT_list)\n",
    "        self.total_corr = self.total_corr_SAT + self.total_corr_vSAT\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_SAT_list = []\n",
    "        self.resp_time_vSAT_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"SAT\":\n",
    "                resp_time_SAT = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_SAT_list.append(resp_time_SAT)\n",
    "            elif task_type == \"vSAT\":\n",
    "                resp_time_vSAT = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_vSAT_list.append(resp_time_vSAT)\n",
    "\n",
    "        self.avg_resp_time_SAT = mean(self.resp_time_SAT_list)\n",
    "        self.avg_resp_time_vSAT = mean(self.resp_time_vSAT_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_SAT, self.avg_resp_time_vSAT]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "    def _add_pos_col(self):\n",
    "        x_pos_col = self.df_simp[\"x_pos\"]\n",
    "        y_pos_col = self.df_simp[\"y_pos\"]\n",
    "\n",
    "        pos_list = []\n",
    "        for x_pos, y_pos in zip(x_pos_col, y_pos_col):\n",
    "            if x_pos == 0 and y_pos == 0:\n",
    "                pos = \"center\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == 0.25 and y_pos == 0.25:\n",
    "                pos = \"top-right\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == 0.25 and y_pos == -0.25:\n",
    "                pos = \"bottom-right\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == -0.25 and y_pos == 0.25:\n",
    "                pos = \"top-left\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == -0.25 and y_pos == -0.25:\n",
    "                pos = \"bottom-left\"\n",
    "                pos_list.append(pos)\n",
    "            else:\n",
    "                pos = \"Nan\"\n",
    "                pos_list.append(pos)\n",
    "\n",
    "        self.df_simp.insert(loc=4, column=\"position\", value=pos_list)\n",
    "        self.df_simp = self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"])\n",
    "\n",
    "\n",
    "class Participant_Behav(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing participants and behavioral data from the experiments.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        par_num: Participant number\n",
    "        par_id: Participant ID\n",
    "        par_dir: Path to specific participant directory\n",
    "        exp_order: Experiment order\n",
    "        all_marker_timestamps: Dictionary with start and end timestamps for each experiment\n",
    "        marker_ts_df: DataFrame with start and end timestamps for each experiment\n",
    "        audio_narrative: Audio Narrative experiment instance\n",
    "        go_no_go: Go/No-Go experiment instance\n",
    "        king_devick: King Devick experiment instance\n",
    "        n_back: N-Back experiment instance\n",
    "        tower_of_london: Tower of London experiment instance\n",
    "        video_narrative_cmiyc: Video Narrative CMIYC experiment instance\n",
    "        video_narrative_sherlock: Video Narrative Sherlock experiment instance\n",
    "        vSAT: vSAT experiment instance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_num):\n",
    "        super().__init__()\n",
    "        self.par_num, self.par_ID = self.process_par(par_num)\n",
    "        data_dir = r\"C:\\Kernel\\participants\"\n",
    "        # self.par_dir = os.path.join(os.getcwd(), \"participants\", self.par_ID)\n",
    "        self.par_dir = os.path.join(data_dir, self.par_ID)\n",
    "\n",
    "        self.exp_order = self.get_exp_order()\n",
    "        self.all_marker_timestamps = self.get_all_marker_timestamps(\n",
    "            par_dir=self.par_dir, exp_order=self.exp_order\n",
    "        )\n",
    "        self._create_marker_ts_csv()\n",
    "        self.marker_ts_df = self._create_marker_ts_df()\n",
    "\n",
    "        self.audio_narrative = Audio_Narrative(par_dir=self.par_dir)\n",
    "        self.audio_narrative.start_ts = self.get_start_ts(\"audio_narrative\")\n",
    "        self.audio_narrative.df_adj_ts = self.adjust_df_ts(\n",
    "            self.audio_narrative.df_simp,\n",
    "            self.audio_narrative.start_ts,\n",
    "            [\"pieman_clip.started\", \"pieman_clip.ended\"],\n",
    "        )\n",
    "\n",
    "        self.go_no_go = Go_No_Go(par_dir=self.par_dir)\n",
    "        self.go_no_go.start_ts = self.get_start_ts(\"go_no_go\")\n",
    "        self.go_no_go.df_adj_ts = self.adjust_df_ts(\n",
    "            self.go_no_go.df_no_nan,\n",
    "            self.go_no_go.start_ts,\n",
    "            [\n",
    "                \"inter_stim_plus.started\",\n",
    "                \"inter_stim_plus.ended\",\n",
    "                \"go_image.started\",\n",
    "                \"go_image.ended\",\n",
    "            ],\n",
    "        )\n",
    "        self.go_no_go.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.go_no_go.df_by_block,\n",
    "            self.go_no_go.start_ts,\n",
    "            [\n",
    "                \"inter_stim_plus.started\",\n",
    "                \"inter_stim_plus.ended\",\n",
    "                \"go_image.started\",\n",
    "                \"go_image.ended\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.king_devick = King_Devick(par_dir=self.par_dir)\n",
    "        self.king_devick.start_ts = self.get_start_ts(\"king_devick\")\n",
    "        self.king_devick.df_adj_ts = self.adjust_df_ts(\n",
    "            self.king_devick.df_simp,\n",
    "            self.king_devick.start_ts,\n",
    "            [\"card_image.started\", \"card_image.ended\"],\n",
    "        )\n",
    "\n",
    "        self.n_back = N_Back(par_dir=self.par_dir)\n",
    "        self.n_back.start_ts = self.get_start_ts(\"n_back\")\n",
    "        self.n_back.df_adj_ts = self.adjust_df_ts(\n",
    "            self.n_back.df_no_nan,\n",
    "            self.n_back.start_ts,\n",
    "            [\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "                \"inter_stim.started\",\n",
    "                \"inter_stim.ended\",\n",
    "            ],\n",
    "        )\n",
    "        self.n_back.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.n_back.df_by_block,\n",
    "            self.n_back.start_ts,\n",
    "            [\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "                \"inter_stim.started\",\n",
    "                \"inter_stim.ended\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.resting_state = Resting_State(par_dir=self.par_dir)\n",
    "        self.resting_state.start_ts = self.get_start_ts(\"resting_state\")\n",
    "        self.resting_state.df_adj_ts = self.adjust_df_ts(\n",
    "            self.resting_state.df_simp,\n",
    "            self.resting_state.start_ts,\n",
    "            [\"trial_cross.started\", \"halfway_tone.started\", \"done_sound.started\"],\n",
    "        )\n",
    "\n",
    "        self.tower_of_london = Tower_of_London(par_dir=self.par_dir)\n",
    "        self.tower_of_london.start_ts = self.get_start_ts(\"tower_of_london\")\n",
    "        self.tower_of_london.df_adj_ts = self.adjust_df_ts(\n",
    "            self.tower_of_london.df_no_nan,\n",
    "            self.tower_of_london.start_ts,\n",
    "            [\n",
    "                \"stim_image.started\",\n",
    "                \"stim_image.ended\",\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "            ],\n",
    "        )\n",
    "        self.tower_of_london.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.tower_of_london.df_by_block,\n",
    "            self.tower_of_london.start_ts,\n",
    "            [\n",
    "                \"stim_image.started\",\n",
    "                \"stim_image.ended\",\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.video_narrative_cmiyc = Video_Narrative_CMIYC(par_dir=self.par_dir)\n",
    "        self.video_narrative_cmiyc.start_ts = self.get_start_ts(\"video_narrative_cmiyc\")\n",
    "        self.video_narrative_cmiyc.df_adj_ts = self.adjust_df_ts(\n",
    "            self.video_narrative_cmiyc.df_simp,\n",
    "            self.video_narrative_cmiyc.start_ts,\n",
    "            [\"video_start.started\", \"video_start.ended\"],\n",
    "        )\n",
    "\n",
    "        self.video_narrative_sherlock = Video_Narrative_Sherlock(par_dir=self.par_dir)\n",
    "        self.video_narrative_sherlock.start_ts = self.get_start_ts(\n",
    "            \"video_narrative_sherlock\"\n",
    "        )\n",
    "        self.video_narrative_sherlock.df_adj_ts = self.adjust_df_ts(\n",
    "            self.video_narrative_sherlock.df_simp,\n",
    "            self.video_narrative_sherlock.start_ts,\n",
    "            [\"video_start.started\", \"video_start.ended\"],\n",
    "        )\n",
    "\n",
    "        self.vSAT = vSAT(par_dir=self.par_dir)\n",
    "        self.vSAT.start_ts = self.get_start_ts(\"vSAT\")\n",
    "        self.vSAT.df_adj_ts = self.adjust_df_ts(\n",
    "            self.vSAT.df_no_nan,\n",
    "            self.vSAT.start_ts,\n",
    "            [\n",
    "                \"inter_stim_text.started\",\n",
    "                \"inter_stim_text.ended\",\n",
    "                \"vSAT_square.started\",\n",
    "                \"vSAT_square.ended\",\n",
    "                \"feedback_sound.started\",\n",
    "                \"feedback_sound.ended\",\n",
    "            ],\n",
    "        )\n",
    "        self.vSAT.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.vSAT.df_by_block,\n",
    "            self.vSAT.start_ts,\n",
    "            [\n",
    "                \"inter_stim_text.started\",\n",
    "                \"inter_stim_text.ended\",\n",
    "                \"vSAT_square.started\",\n",
    "                \"vSAT_square.ended\",\n",
    "                \"feedback_sound.started\",\n",
    "                \"feedback_sound.ended\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.by_block_ts_dict = self._create_by_block_ts_dict()\n",
    "\n",
    "    def get_exp_order(self) -> list:\n",
    "        \"\"\"\n",
    "        Gets the experiment order from a text file.\n",
    "\n",
    "        Returns:\n",
    "            list: Experiment order\n",
    "        \"\"\"\n",
    "\n",
    "        exp_order_filename = f\"{self.par_ID}_experiment_order.txt\"\n",
    "        exp_order_filepath = os.path.join(self.par_dir, exp_order_filename)\n",
    "\n",
    "        with open(exp_order_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        exp_order = []\n",
    "        for line in lines:\n",
    "            if \"Block\" in line or \"-\" in line or line == \"\\n\":\n",
    "                pass\n",
    "            else:\n",
    "                exp_order.append(line.strip(\"\\n\"))\n",
    "\n",
    "        return exp_order\n",
    "\n",
    "    def _create_marker_ts_csv(self) -> None:\n",
    "        \"\"\"\n",
    "        Create a CSV file containing the start and end timestamps for each experiment.\n",
    "        \"\"\"\n",
    "        filepath = os.path.join(\n",
    "            self.par_dir,\n",
    "            f\"{self.par_ID}_marker_timestamps.csv\",\n",
    "        )\n",
    "        if os.path.exists(filepath):\n",
    "            pass\n",
    "        else:\n",
    "            marker_list = []\n",
    "            for exp_name, ts_list in self.all_marker_timestamps.items():\n",
    "                temp_list = []\n",
    "                temp_list.append(exp_name)\n",
    "                temp_list.extend(ts_list)\n",
    "                marker_list.append(temp_list)\n",
    "            marker_ts_df = pd.DataFrame(\n",
    "                marker_list, columns=[\"exp_name\", \"start_timestamp\", \"end_timestamp\"]\n",
    "            )\n",
    "            marker_ts_df.to_csv(filepath, index=False)\n",
    "\n",
    "    def _create_marker_ts_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a DataFrame from a CSV file containing the start and end timestamps for each experiment.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Start and end timestamps for each experiment\n",
    "        \"\"\"\n",
    "        marker_ts_filepath = os.path.join(\n",
    "            self.par_dir, f\"{self.par_ID}_marker_timestamps.csv\"\n",
    "        )\n",
    "\n",
    "        return pd.read_csv(marker_ts_filepath)\n",
    "\n",
    "    def get_start_ts(self, exp_name: str) -> float:\n",
    "        \"\"\"\n",
    "        Get the start timestamp of an experiment\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            float: Start timestamp of the experiment\n",
    "        \"\"\"\n",
    "        return float(int(self.all_marker_timestamps[exp_name][0]) / 1e9)\n",
    "\n",
    "    def get_end_ts(self, exp_name: str) -> float:\n",
    "        \"\"\"\n",
    "        Get the end timestamp of an experiment\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Name of the experiment\n",
    "\n",
    "        Returns:\n",
    "            float: End timestamp of the experiment\n",
    "        \"\"\"\n",
    "        return float(int(self.all_marker_timestamps[exp_name][1]) / 1e9)\n",
    "\n",
    "    def _create_by_block_ts_dict(self) -> dict:\n",
    "        \"\"\"\n",
    "        Creates a dictionary with the start and end timestamps for each block and trial of each experiment.\n",
    "\n",
    "        Returns:\n",
    "            dict: Block and trial start and end timestamps for each experiment\n",
    "                keys:\n",
    "                    'audio_narrative', 'go_no_go', 'king_devick', 'n_back', 'resting_state',\n",
    "                    'tower_of_london', 'video_narrative_cmiyc', 'video_narrative_sherlock', 'vSAT'\n",
    "                values: start and end timestamp dict\n",
    "                    keys:\n",
    "                        (start timestamp, end_timestamp)\n",
    "                    values: block and trial dict\n",
    "                        keys:\n",
    "                            'block', 'trial'\n",
    "                        values:\n",
    "                            'block name', 'trial number'\n",
    "        \"\"\"\n",
    "\n",
    "        def format_ts(exp_name: str) -> Tuple[float, float]:\n",
    "            \"\"\"\n",
    "            Format timestamp into UTC second format from nanosecond format.\n",
    "\n",
    "            Args:\n",
    "                exp_name (str): Experiment name\n",
    "\n",
    "            Returns:\n",
    "                Tuple[float, float]: Start timestamp, end timestamp\n",
    "            \"\"\"\n",
    "            start_ts, end_ts = self.get_exp_ts(self.marker_ts_df, exp_name=exp_name)\n",
    "            return start_ts / 1e9, end_ts / 1e9\n",
    "\n",
    "        def get_value_dict(block: str, trial: int) -> dict:\n",
    "            \"\"\"\n",
    "            Create a dictionary with block and trial values.\n",
    "\n",
    "            Args:\n",
    "                block (str): Experiment block\n",
    "                trial (int): Experiment trial\n",
    "\n",
    "            Returns:\n",
    "                dict: Block and trial dictionary\n",
    "                    keys:\n",
    "                        'block', 'trial'\n",
    "                    values:\n",
    "                        'block name', 'trial number'\n",
    "            \"\"\"\n",
    "            return {\"block\": block, \"trial\": trial}\n",
    "\n",
    "        by_block_ts_dict = {}\n",
    "        for exp_name in self.exp_order:\n",
    "            block_ts_df = {}\n",
    "\n",
    "            if exp_name == \"audio_narrative\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.audio_narrative.df_simp[\n",
    "                    \"pieman_clip.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                clip_length = 423  # 423 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                value_dict = get_value_dict(\"audio_narrative\", 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"go_no_go\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(\n",
    "                        self.go_no_go.task_order_simp,\n",
    "                        self.go_no_go.df_by_block.values(),\n",
    "                    )\n",
    "                ):\n",
    "                    block_start_time = block_df[\"inter_stim_plus.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"go_image.started\"].iloc[-1] + 0.5\n",
    "                    )  # image shown for 0.5 seconds\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"king_devick\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                task_order = (\n",
    "                    self.king_devick.task_order_new\n",
    "                    if self.king_devick.task_order_new\n",
    "                    else self.king_devick.task_order\n",
    "                )\n",
    "                for i, (block, block_start_time, rt) in enumerate(\n",
    "                    zip(\n",
    "                        task_order,\n",
    "                        self.king_devick.df_simp[\"card_image.started\"].values,\n",
    "                        self.king_devick.df_simp[\"card_resp.rt\"].values,\n",
    "                    )\n",
    "                ):\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_ts = block_start_ts + rt\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"n_back\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(self.n_back.task_order_simp2, self.n_back.df_by_block.values())\n",
    "                ):\n",
    "                    block_start_time = block_df[\"stim_text.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"stim_text.started\"].iloc[-1] + 0.5\n",
    "                    )  # number shown for 0.5 seconds\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"resting_state\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.resting_state.df_simp[\n",
    "                    \"trial_cross.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                block_end_ts = block_start_ts + (\n",
    "                    self.resting_state.df_simp[\"halfway_tone.started\"].item()\n",
    "                    - block_start_time\n",
    "                )\n",
    "                value_dict = get_value_dict(self.resting_state.task_order_simp[0], 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "                block_start_time = self.resting_state.df_simp[\n",
    "                    \"halfway_tone.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                block_end_ts = block_start_ts + (\n",
    "                    self.resting_state.df_simp[\"done_sound.started\"].item()\n",
    "                    - block_start_time\n",
    "                )\n",
    "                value_dict = get_value_dict(self.resting_state.task_order_simp[1], 2)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"tower_of_london\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(\n",
    "                        self.tower_of_london.task_order_simp,\n",
    "                        self.tower_of_london.df_by_block.values(),\n",
    "                    )\n",
    "                ):\n",
    "                    block_start_time = block_df[\"stim_image.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"stim_text.started\"].iloc[-1] + 3\n",
    "                    )  # 3 seconds to respond\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"video_narrative_cmiyc\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.video_narrative_cmiyc.df_simp[\n",
    "                    \"video_start.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time  # NOTE\n",
    "                clip_length = 300  # 300 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                value_dict = get_value_dict(\"video_narrative_cmiyc\", 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"video_narrative_sherlock\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.video_narrative_sherlock.df_simp[\n",
    "                    \"video_start.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                clip_length = 300  # 300 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                value_dict = get_value_dict(\"video_narrative_sherlock\", 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"vSAT\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(self.vSAT.task_order_simp, self.vSAT.df_by_block.values())\n",
    "                ):\n",
    "                    block_start_time = block_df[\"inter_stim_text.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"feedback_sound.started\"].iloc[-1] + 0.5\n",
    "                    )  # 0.5 second delay\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "            by_block_ts_dict[exp_name] = block_ts_df\n",
    "\n",
    "        return by_block_ts_dict\n",
    "\n",
    "    def get_exp(self, exp_name: str):\n",
    "        \"\"\"\n",
    "        Get an instance of the experiment class.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Experiment name\n",
    "\n",
    "        Returns:\n",
    "            class: Instance of experiment class\n",
    "        \"\"\"\n",
    "        if exp_name == \"audio_narrative\":\n",
    "            return self.audio_narrative\n",
    "        elif exp_name == \"go_no_go\":\n",
    "            return self.go_no_go\n",
    "        elif exp_name == \"king_devick\":\n",
    "            return self.king_devick\n",
    "        elif exp_name == \"n_back\":\n",
    "            return self.n_back\n",
    "        elif exp_name == \"resting_state\":\n",
    "            return self.resting_state\n",
    "        elif exp_name == \"tower_of_london\":\n",
    "            return self.tower_of_london\n",
    "        elif exp_name == \"video_narrative_cmiyc\":\n",
    "            return self.video_narrative_cmiyc\n",
    "        elif exp_name == \"video_narrative_sherlock\":\n",
    "            return self.video_narrative_sherlock\n",
    "        elif exp_name == \"vSAT\":\n",
    "            return self.vSAT\n",
    "\n",
    "    def get_start_dt(self, exp_name: str) -> datetime.datetime:\n",
    "        \"\"\"\n",
    "        Convert start timestamp of an experiment into the start datetime.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Experiment name\n",
    "\n",
    "        Returns:\n",
    "            datetime.datetime: Start datetime of an experiment\n",
    "        \"\"\"\n",
    "        return datetime.datetime.fromtimestamp(\n",
    "            int(self.all_marker_timestamps[exp_name][0]) / 1e9\n",
    "        )\n",
    "\n",
    "    def get_end_dt(self, exp_name: str) -> datetime.datetime:\n",
    "        \"\"\"\n",
    "        Convert end timestamp of an experiment into the end datetime.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Experiment name\n",
    "\n",
    "        Returns:\n",
    "            datetime.datetime: End datetime of an experiment\n",
    "        \"\"\"\n",
    "        return datetime.datetime.fromtimestamp(\n",
    "            int(self.all_marker_timestamps[exp_name][1]) / 1e9\n",
    "        )\n",
    "\n",
    "\n",
    "def create_behav_results_tables(num_pars: int) -> None:\n",
    "    \"\"\"\n",
    "    Write the processed experiment and behavioral data into CSV files.\n",
    "\n",
    "    Args:\n",
    "        num_pars (int): Number of participants\n",
    "    \"\"\"\n",
    "\n",
    "    def get_num_rows(exp, new: bool = False) -> int:\n",
    "        \"\"\"\n",
    "        Get the number of rows needed for the experiment (number of blocks * number of trials).\n",
    "\n",
    "        Args:\n",
    "            exp (class): Instance of an experiment class\n",
    "            new (bool, optional): Is there a new number of rows? Defaults to False\n",
    "\n",
    "        Returns:\n",
    "            int: Number of rows in the experiment\n",
    "        \"\"\"\n",
    "        if new:\n",
    "            return int(exp.num_blocks * exp.num_trials_new)\n",
    "        else:\n",
    "            return int(exp.num_blocks * exp.num_trials)\n",
    "\n",
    "    data_fun = Data_Functions()\n",
    "\n",
    "    audio_df_list = []\n",
    "    gng_df_list = []\n",
    "    kd_df_list = []\n",
    "    n_back_df_list = []\n",
    "    rs_df_list = []\n",
    "    tol_df_list = []\n",
    "    video_cmiyc_df_list = []\n",
    "    video_sherlock_df_list = []\n",
    "    vsat_df_list = []\n",
    "\n",
    "    for i in range(num_pars):\n",
    "        par_num = f\"{(i+1):02d}\"\n",
    "        par = Participant_Behav(par_num=par_num)\n",
    "\n",
    "        # Audio Narrative ----\n",
    "        exp = par.audio_narrative\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1])\n",
    "        block_col = pd.Series([\"audio_narrative\"])\n",
    "\n",
    "        temp_audio_df = exp.df_adj_ts\n",
    "        temp_audio_df.insert(0, \"block\", block_col)\n",
    "        temp_audio_df.insert(0, \"trial\", trial_col)\n",
    "        temp_audio_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_audio_df.rename(\n",
    "            columns={\n",
    "                \"pieman_clip.started\": \"stim_start\",\n",
    "                \"pieman_clip.ended\": \"stim_end\",\n",
    "                \"participant_response.text\": \"response\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        audio_df_list.append(temp_audio_df)\n",
    "\n",
    "        # Go/No-Go -----\n",
    "        exp = par.go_no_go\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        gng_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp, gng_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_gng_df = pd.DataFrame()\n",
    "        temp_gng_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_gng_df.reset_index(inplace=True, drop=True)\n",
    "        temp_gng_df.insert(0, \"block\", block_col)\n",
    "        temp_gng_df.insert(0, \"trial\", trial_col)\n",
    "        temp_gng_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_gng_df.rename(\n",
    "            columns={\n",
    "                \"GNG_stim\": \"stim\",\n",
    "                \"inter_stim_plus.started\": \"inter_stim_start\",\n",
    "                \"inter_stim_plus.ended\": \"inter_stim_end\",\n",
    "                \"go_image.started\": \"stim_start\",\n",
    "                \"go_image.ended\": \"stim_end\",\n",
    "                \"go_resp.corr\": \"correct_response\",\n",
    "                \"go_resp.rt\": \"response_time\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        gng_df_list.append(temp_gng_df.copy())\n",
    "\n",
    "        # King Devick -----\n",
    "        exp = par.king_devick\n",
    "\n",
    "        if int(par_num) >= 15:  # participants 15+ have a 4th card\n",
    "            num_rows = get_num_rows(exp=exp, new=True)\n",
    "            trial_col = pd.Series([1, 2, 3, 4])\n",
    "            block_col = pd.Series(exp.task_order_new)\n",
    "        else:\n",
    "            num_rows = get_num_rows(exp=exp)\n",
    "            trial_col = pd.Series([1, 2, 3])\n",
    "            block_col = pd.Series(exp.task_order)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        temp_kd_df = exp.df_adj_ts\n",
    "        temp_kd_df.insert(0, \"block\", block_col)\n",
    "        temp_kd_df.insert(0, \"trial\", trial_col)\n",
    "        temp_kd_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_kd_df = temp_kd_df.rename(\n",
    "            columns={\n",
    "                \"card_image.started\": \"stim_start\",\n",
    "                \"card_image.ended\": \"stim_end\",\n",
    "                \"card_resp.rt\": \"response_time\",\n",
    "            }\n",
    "        )\n",
    "        kd_df_list.append(temp_kd_df.copy())\n",
    "\n",
    "        # N-Back -----\n",
    "        exp = par.n_back\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        n_back_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp2, n_back_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_n_back_df = pd.DataFrame()\n",
    "        temp_n_back_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_n_back_df.reset_index(inplace=True, drop=True)\n",
    "        temp_n_back_df.insert(0, \"block\", block_col)\n",
    "        temp_n_back_df.insert(0, \"trial\", trial_col)\n",
    "        temp_n_back_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_n_back_df.rename(\n",
    "            columns={\n",
    "                \"stim_text.started\": \"stim_start\",\n",
    "                \"stim_text.ended\": \"stim_end\",\n",
    "                \"inter_stim.started\": \"inter_stim_start\",\n",
    "                \"inter_stim.ended\": \"inter_stim_end\",\n",
    "                \"stim_resp.corr\": \"correct_response\",\n",
    "                \"stim_resp.rt\": \"response_time\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        n_back_df_list.append(temp_n_back_df.copy())\n",
    "\n",
    "        # Resting State -----\n",
    "        exp = par.resting_state\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1, 2])\n",
    "        block_col = pd.Series(exp.task_order_simp)\n",
    "\n",
    "        temp_rs_df = pd.DataFrame(\n",
    "            {\n",
    "                \"stim_start\": [\n",
    "                    exp.df_adj_ts[\"trial_cross.started\"][0],\n",
    "                    exp.df_adj_ts[\"halfway_tone.started\"][0],\n",
    "                ],\n",
    "                \"stim_end\": [\n",
    "                    exp.df_adj_ts[\"halfway_tone.started\"][0],\n",
    "                    exp.df_adj_ts[\"done_sound.started\"][0],\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        temp_rs_df.insert(0, \"block\", block_col)\n",
    "        temp_rs_df.insert(0, \"trial\", trial_col)\n",
    "        temp_rs_df.insert(0, \"participant\", par_num_col)\n",
    "        rs_df_list.append(temp_rs_df)\n",
    "\n",
    "        # Tower of London -----\n",
    "        exp = par.tower_of_london\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        tol_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp, tol_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_tol_df = pd.DataFrame()\n",
    "        temp_tol_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_tol_df.reset_index(inplace=True, drop=True)\n",
    "        temp_tol_df.insert(0, \"block\", block_col)\n",
    "        temp_tol_df.insert(0, \"trial\", trial_col)\n",
    "        temp_tol_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_tol_df.rename(\n",
    "            columns={\n",
    "                \"image_stim\": \"stim\",\n",
    "                \"stim_image.started\": \"stim_start\",\n",
    "                \"stim_image.ended\": \"stim_end\",\n",
    "                \"stim_text.started\": \"response_start\",\n",
    "                \"stim_text.ended\": \"response_end\",\n",
    "                \"stim_resp.corr\": \"correct_response\",\n",
    "                \"stim_resp.rt\": \"response_time\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        tol_df_list.append(temp_tol_df.copy())\n",
    "\n",
    "        # Video Narrative CMIYC ----\n",
    "        exp = par.video_narrative_cmiyc\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1])\n",
    "        block_col = pd.Series([\"video_narrative_cmiyc\"])\n",
    "\n",
    "        temp_video_cmiyc_df = exp.df_adj_ts\n",
    "        temp_video_cmiyc_df.insert(0, \"block\", block_col)\n",
    "        temp_video_cmiyc_df.insert(0, \"trial\", trial_col)\n",
    "        temp_video_cmiyc_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_video_cmiyc_df.rename(\n",
    "            columns={\n",
    "                \"video_start.started\": \"stim_start\",\n",
    "                \"video_start.ended\": \"stim_end\",\n",
    "                \"catchme_participant_response.text\": \"response\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        video_cmiyc_df_list.append(temp_video_cmiyc_df)\n",
    "\n",
    "        # Video Narrative Sherlock ----\n",
    "        exp = par.video_narrative_sherlock\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1])\n",
    "        block_col = pd.Series([\"video_narrative_sherlock\"])\n",
    "\n",
    "        temp_video_sherlock_df = exp.df_adj_ts\n",
    "        temp_video_sherlock_df.insert(0, \"block\", block_col)\n",
    "        temp_video_sherlock_df.insert(0, \"trial\", trial_col)\n",
    "        temp_video_sherlock_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_video_sherlock_df.rename(\n",
    "            columns={\n",
    "                \"video_start.started\": \"stim_start\",\n",
    "                \"video_start.ended\": \"stim_end\",\n",
    "                \"sherlock_participant_response.text\": \"response\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        video_sherlock_df_list.append(temp_video_sherlock_df)\n",
    "\n",
    "        # vSAT -----\n",
    "        exp = par.vSAT\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        vsat_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp, vsat_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_vsat_df = pd.DataFrame()\n",
    "        temp_vsat_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_vsat_df.reset_index(inplace=True, drop=True)\n",
    "        temp_vsat_df.insert(0, \"block\", block_col)\n",
    "        temp_vsat_df.insert(0, \"trial\", trial_col)\n",
    "        temp_vsat_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_vsat_df.rename(\n",
    "            columns={\n",
    "                \"stim_resp.corr\": \"correct_response\",\n",
    "                \"inter_stim_text.started\": \"inter_stim_start\",\n",
    "                \"inter_stim_text.ended\": \"inter_stim_end\",\n",
    "                \"vSAT_square.started\": \"stim_start\",\n",
    "                \"vSAT_square.ended\": \"stim_end\",\n",
    "                \"stim_resp.rt\": \"response_time\",\n",
    "                \"feedback_sound.started\": \"feedback_sound_start\",\n",
    "                \"feedback_sound.ended\": \"feedback_sound_end\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        vsat_df_list.append(temp_vsat_df.copy())\n",
    "\n",
    "        # Audio Narrative ----\n",
    "        audio_df = pd.concat(audio_df_list, axis=0)\n",
    "        audio_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"results/behavioral\",\n",
    "            f\"{par.audio_narrative.exp_name}_behav.csv\",\n",
    "        )\n",
    "        audio_df.to_csv(audio_filepath, index=False)\n",
    "\n",
    "        # Go/No-Go -----\n",
    "        gng_df = pd.concat(gng_df_list, axis=0)\n",
    "        gng_filepath = os.path.join(\n",
    "            os.getcwd(), \"results/behavioral\", f\"{par.go_no_go.exp_name}_behav.csv\"\n",
    "        )\n",
    "        gng_df.to_csv(gng_filepath, index=False)\n",
    "\n",
    "        # King Devick -----\n",
    "        kd_df = pd.concat(kd_df_list, axis=0)\n",
    "        kd_filepath = os.path.join(\n",
    "            os.getcwd(), \"results/behavioral\", f\"{par.king_devick.exp_name}_behav.csv\"\n",
    "        )\n",
    "        kd_df.to_csv(kd_filepath, index=False)\n",
    "\n",
    "        # N-Back -----\n",
    "        n_back_df = pd.concat(n_back_df_list, axis=0)\n",
    "        n_back_filepath = os.path.join(\n",
    "            os.getcwd(), \"results/behavioral\", f\"{par.n_back.exp_name}_behav.csv\"\n",
    "        )\n",
    "        n_back_df.to_csv(n_back_filepath, index=False)\n",
    "\n",
    "        # Resting State -----\n",
    "        rs_df = pd.concat(rs_df_list, axis=0)\n",
    "        rs_filepath = os.path.join(\n",
    "            os.getcwd(), \"results/behavioral\", f\"{par.resting_state.exp_name}_behav.csv\"\n",
    "        )\n",
    "        rs_df.to_csv(rs_filepath, index=False)\n",
    "\n",
    "        # Tower of London -----\n",
    "        tol_df = pd.concat(tol_df_list, axis=0)\n",
    "        tol_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"results/behavioral\",\n",
    "            f\"{par.tower_of_london.exp_name}_behav.csv\",\n",
    "        )\n",
    "        tol_df.to_csv(tol_filepath, index=False)\n",
    "\n",
    "        # Video Narrative CMIYC ----\n",
    "        video_cmiyc_df = pd.concat(video_cmiyc_df_list, axis=0)\n",
    "        video_cmiyc_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"results/behavioral\",\n",
    "            f\"{par.video_narrative_cmiyc.exp_name}_behav.csv\",\n",
    "        )\n",
    "        video_cmiyc_df.to_csv(video_cmiyc_filepath, index=False)\n",
    "\n",
    "        # Video Narrative Sherlock ----\n",
    "        video_sherlock_df = pd.concat(video_sherlock_df_list, axis=0)\n",
    "        video_sherlock_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"results/behavioral\",\n",
    "            f\"{par.video_narrative_sherlock.exp_name}_behav.csv\",\n",
    "        )\n",
    "        video_sherlock_df.to_csv(video_sherlock_filepath, index=False)\n",
    "\n",
    "        # vSAT -----\n",
    "        vsat_df = pd.concat(vsat_df_list, axis=0)\n",
    "        vsat_filepath = os.path.join(\n",
    "            os.getcwd(), \"results/behavioral\", f\"{par.vSAT.exp_name}_behav.csv\"\n",
    "        )\n",
    "        vsat_df.to_csv(vsat_filepath, index=False)\n",
    "\n",
    "\n",
    "def load_results(\n",
    "    results_dir: str, exp_name: str = None, par_num: list[int | list | tuple] = None\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Read the experiment behavioral results from CSV files into DataFrame or a dictionary of DataFrames.\n",
    "\n",
    "    Args:\n",
    "        results_dir (str): Path to the results directory\n",
    "        exp_name (str, optional): Get results for a specific experiment? Defaults to None\n",
    "        par_num (list[int  |  list  |  tuple], optional): Participants to select. Single participant, list of participants, or slice of participants.\n",
    "                                                      Defaults to None (all participants).\n",
    "\n",
    "    Returns:\n",
    "        Union[pd.DataFrame, dict]:\n",
    "            pd.DataFrame: Behavioral data for a specified experiment.\n",
    "            -or-\n",
    "            dict: Behavioral results dictionary\n",
    "                keys:\n",
    "                    'audio_narrative', 'go_no_go', 'king_devick', 'n_back', 'resting_state',\n",
    "                    'tower_of_london', 'video_narrative_cmiyc', 'video_narrative_sherlock', 'vSAT'\n",
    "                values:\n",
    "                    DataFrame of behavioral results for each experiment\n",
    "    \"\"\"\n",
    "\n",
    "    if exp_name:\n",
    "        for results_csv in os.listdir(results_dir):\n",
    "            if exp_name in results_csv:\n",
    "                full_path = os.path.join(results_dir, results_csv)\n",
    "                df = pd.read_csv(full_path)\n",
    "                if isinstance(par_num, int):\n",
    "                    return df[df[\"participant\"] == par_num]\n",
    "                elif isinstance(par_num, list):\n",
    "                    return df[df[\"participant\"].isin(par_num)]\n",
    "                elif isinstance(par_num, tuple):\n",
    "                    return df[\n",
    "                        (df[\"participant\"] >= par_num[0])\n",
    "                        & (df[\"participant\"] <= par_num[1])\n",
    "                    ]\n",
    "                else:\n",
    "                    return df\n",
    "        print(\n",
    "            \"Invalid experiment name.\"\n",
    "        )  # only reached if invalid experiment name argument\n",
    "    else:\n",
    "        exp_dict = {}\n",
    "        for results_csv in os.listdir(results_dir):\n",
    "            exp_name = results_csv.split(\"_behav\")[0]\n",
    "            full_path = os.path.join(results_dir, results_csv)\n",
    "            df = pd.read_csv(full_path)\n",
    "            if isinstance(par_num, int):\n",
    "                df = df[df[\"participant\"] == par_num]\n",
    "            elif isinstance(par_num, list):\n",
    "                df = df[df[\"participant\"].isin(par_num)]\n",
    "            elif isinstance(par_num, tuple):\n",
    "                df = df[\n",
    "                    (df[\"participant\"] >= par_num[0])\n",
    "                    & (df[\"participant\"] <= par_num[1])\n",
    "                ]\n",
    "            else:\n",
    "                pass\n",
    "            exp_dict[exp_name] = df\n",
    "        return exp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_num = \"01\"\n",
    "par = Participant_Behav(par_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_behav_results_tables(num_pars=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "par_num = \"08\"\n",
    "par = Participant_Behav(par_num=par_num)\n",
    "\n",
    "print(\"Audio narrative response:\")\n",
    "print(par.audio_narrative.response)\n",
    "print(\"\\nVideo narrative (CMIYC) response:\")\n",
    "print(par.video_narrative_cmiyc.response)\n",
    "print(\"\\nVideo narrative (Sherlock) response:\")\n",
    "print(par.video_narrative_sherlock.response)\n",
    "\n",
    "print(\"\\nGo/No-Go:\")\n",
    "print(\"'Go blocks' correct responses:\", f\"{par.go_no_go.total_corr_go}/{par.go_no_go.num_trials*2}\")\n",
    "print(\"'Go blocks' avg response time:\", f\"{round(par.go_no_go.avg_resp_time_go, 3)} seconds\")\n",
    "print(\"'Go/No-Go blocks' correct responses:\", f\"{par.go_no_go.total_corr_gng}/{par.go_no_go.num_trials*2}\")\n",
    "print(\"'Go/No-Go blocks' avg response time:\", f\"{round(par.go_no_go.avg_resp_time_gng, 3)} seconds\")\n",
    "\n",
    "print(\"\\nN-Back:\")\n",
    "print(\"'Zero-back blocks' correct responses:\", f\"{par.n_back.total_corr_ZB}/{par.n_back.num_trials*3}\")\n",
    "print(\"'Zero-back blocks' avg response time:\", f\"{round(par.n_back.avg_resp_time_ZB, 3)} seconds\")\n",
    "print(\"'One-back blocks' correct responses:\", f\"{par.n_back.total_corr_OB}/{par.n_back.num_trials*3}\")\n",
    "print(\"'One-back blocks' avg response time:\", f\"{round(par.n_back.avg_resp_time_OB, 3)} seconds\")\n",
    "print(\"'Two-back blocks' correct responses:\", f\"{par.n_back.total_corr_TB}/{par.n_back.num_trials*3}\")\n",
    "print(\"'Two-back blocks' avg response time:\", f\"{round(par.n_back.avg_resp_time_TB, 3)} seconds\")\n",
    "\n",
    "print(\"\\nTower of London:\")\n",
    "print(\"'Multi-move blocks' correct responses:\", f\"{par.tower_of_london.total_corr_MM}/{par.tower_of_london.num_trials*3}\")\n",
    "print(\"'Multi-move blocks' avg response time:\", f\"{round(par.tower_of_london.avg_resp_time_MM, 3)} seconds\")\n",
    "print(\"'Zero-move blocks' correct responses:\", f\"{par.tower_of_london.total_corr_ZM}/{par.tower_of_london.num_trials*3}\")\n",
    "print(\"'Zero-move blocks' avg response time:\", f\"{round(par.tower_of_london.avg_resp_time_ZM, 3)} seconds\")\n",
    "\n",
    "print(\"\\nvSAT:\")\n",
    "print(\"'SAT blocks' correct responses:\", f\"{par.vSAT.total_corr_SAT}/{par.vSAT.num_trials*2}\")\n",
    "print(\"'SAT blocks' avg response time:\", f\"{round(par.vSAT.avg_resp_time_SAT, 3)} seconds\")\n",
    "print(\"'vSAT blocks' correct responses:\", f\"{par.vSAT.total_corr_vSAT}/{par.vSAT.num_trials*2}\")\n",
    "print(\"'vSAT blocks' avg response time:\", f\"{round(par.vSAT.avg_resp_time_vSAT, 3)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc7c3b5b3ed8bccdeb6381f95d0763ef1bb082ae76d136fc0c3d4673d6eca8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
