{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from typing import Tuple, Union\n",
    "from data_functions import Data_Functions\n",
    "\n",
    "\n",
    "class Audio_Narrative(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Audio Narrative experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        clip_duration: Number of seconds in the narrative clip\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        response: Participant response to the narrative\n",
    "        block_start_time: Start timestamp of the narrative clip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"audio_narrative\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.clip_duration = 423  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "\n",
    "        cols = [\"pieman_clip.started\", \"participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"pieman_clip.ended\",\n",
    "            self.df_simp[\"pieman_clip.started\"] + self.clip_duration,\n",
    "        )\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\n",
    "                \"Audio Narrative: Need to combine 'participant response' columns into a single column.\"\n",
    "            )\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"pieman_clip.started\"][0]\n",
    "\n",
    "\n",
    "class Go_No_Go(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Go/No-Go experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"go_no_go\"\n",
    "        self.num_blocks = 4\n",
    "        self.num_trials = 20\n",
    "        # NOTE: stimulus duration depends on participant response\n",
    "        # NOTE: inter-stimulus duration is variable\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\n",
    "            \"match\",\n",
    "            \"GNG_stim\",\n",
    "            \"inter_stim_plus.started\",\n",
    "            \"go_image.started\",\n",
    "            \"go_image.stopped\",\n",
    "            \"go_resp.corr\",\n",
    "            \"go_resp.rt\",\n",
    "        ]\n",
    "        for idx, row in self.df.iterrows():\n",
    "            if (\n",
    "                row[\"go_image.stopped\"] == float(\"NaN\")\n",
    "                or row[\"go_image.stopped\"] == \"None\"\n",
    "            ):\n",
    "                self.df.at[idx, \"go_image.stopped\"] = (\n",
    "                    row[\"go_image.started\"] + row[\"go_resp.rt\"]\n",
    "                )\n",
    "\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp = self.df_simp.copy()\n",
    "        self.df_simp[\"GNG_stim\"] = self.df_simp[\"GNG_stim\"].apply(self._strip_stim)\n",
    "        self.df_simp.insert(\n",
    "            3,\n",
    "            \"inter_stim_plus.ended\",\n",
    "            self.df_simp[\"inter_stim_plus.started\"] + self.df[\"inter_stim_interval\"],\n",
    "        )\n",
    "        # self.df_simp.rename(\n",
    "        #     columns={\n",
    "        #         \"go_image.stopped\": \"go_image.ended\",\n",
    "        #     },\n",
    "        #     inplace=True,\n",
    "        # )\n",
    "        # self.df_simp.insert(\n",
    "        #     5,\n",
    "        #     \"go_image.ended\",\n",
    "        #     self.df_simp[\"go_image.started\"] + self.df_simp[\"go_resp.rt\"],\n",
    "        # )\n",
    "\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "    def _strip_stim(self, row):\n",
    "        try:\n",
    "            return row.split(\"\\\\\")[0].split(\"_stimuli\")[0]\n",
    "        except:\n",
    "            return row\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_go_list = []\n",
    "        self.num_corr_gng_list = []\n",
    "\n",
    "        for i, block in enumerate(df_by_block.values()):\n",
    "            if (i + 1) % 2 != 0:  # Go blocks\n",
    "                num_corr_go = int(sum(block[\"go_resp.corr\"]))\n",
    "                self.num_corr_go_list.append(num_corr_go)\n",
    "            else:  # Go/No-Go blocks\n",
    "                num_corr_gng = int(sum(block[\"go_resp.corr\"]))\n",
    "                self.num_corr_gng_list.append(num_corr_gng)\n",
    "\n",
    "        self.total_corr_go = sum(self.num_corr_go_list)\n",
    "        self.total_corr_gng = sum(self.num_corr_gng_list)\n",
    "        self.total_corr = self.total_corr_go + self.total_corr_gng\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_go_list = []\n",
    "        self.resp_time_gng_list = []\n",
    "\n",
    "        for i, block in enumerate(df_by_block.values()):\n",
    "            if (i + 1) % 2 != 0:  # Go blocks\n",
    "                try:  # handle Nan\n",
    "                    resp_time_go = np.nanmean(block[\"go_resp.rt\"])\n",
    "                    self.resp_time_go_list.append(resp_time_go)\n",
    "                except:\n",
    "                    pass\n",
    "            else:  # Go/No-Go blocks\n",
    "                try:  # handle Nan\n",
    "                    resp_time_gng = np.nanmean(block[\"go_resp.rt\"])\n",
    "                    self.resp_time_gng_list.append(resp_time_gng)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        self.avg_resp_time_go = mean(self.resp_time_go_list)\n",
    "        self.avg_resp_time_gng = mean(self.resp_time_gng_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_go, self.avg_resp_time_gng]\n",
    "\n",
    "\n",
    "class King_Devick(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the King Devick experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_new: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"king_devick\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 3\n",
    "        self.num_trials_new = 4  # added a card for participants 15+\n",
    "        # NOTE: card duration depends on participant response\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = [\"card_1\", \"card_2\", \"card_3\"]\n",
    "        self.task_order_new = [\n",
    "            \"card_1\",\n",
    "            \"card_2\",\n",
    "            \"card_3\",\n",
    "            \"card_4\",\n",
    "        ]  # added a card for participants 15+\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        num_incorrect_col = pd.Series(self._parse_data_file(par_dir=par_dir))\n",
    "        self.df.insert(len(self.df.columns), \"num_incorrect\", num_incorrect_col)\n",
    "        cols = [\"card_image.started\", \"card_resp.rt\", \"num_incorrect\"]\n",
    "        self.df_simp = self.get_cols(self.df, cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"card_image.ended\",\n",
    "            self.df_simp[\"card_image.started\"] + self.df_simp[\"card_resp.rt\"],\n",
    "        )\n",
    "\n",
    "    def _parse_data_file(self, par_dir):\n",
    "        data_dir = os.path.join(par_dir, self.exp_name, \"data\")\n",
    "        for filename in os.listdir(data_dir):\n",
    "            if \"data.txt\" in filename:\n",
    "                data_filename = filename\n",
    "        data_filepath = os.path.join(data_dir, data_filename)\n",
    "\n",
    "        with open(data_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        par_resp = []\n",
    "        for line in lines:\n",
    "            if \"number incorrect\" in line:\n",
    "                par_resp.append(line.split(\" \")[-1].strip(\"\\n\"))\n",
    "\n",
    "        return par_resp\n",
    "\n",
    "\n",
    "class N_Back(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the N-Back experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        stim_duration: Duration of stimulus\n",
    "        inter_stim_duration: Duration between stimuli\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"n_back\"\n",
    "        self.num_blocks = 9\n",
    "        self.num_trials = 20\n",
    "        self.stim_duration = 0.5  # seconds\n",
    "        self.inter_stim_duration = 3.0  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp, self.task_order_simp2 = self._simp_task_order(\n",
    "            task_order=self.task_order\n",
    "        )\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"match\", \"stim_text.started\", \"stim_resp.corr\", \"stim_resp.rt\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            2, \"stim_text.ended\", self.df_simp[\"stim_text.started\"] + 0.5\n",
    "        )  # stimulus duration is 0.5 seconds\n",
    "        self.df_simp.insert(\n",
    "            3, \"inter_stim.started\", self.df_simp[\"stim_text.started\"] + 0.5\n",
    "        )  # inter-stimulus interval starts 0.5 seconds after stimulus\n",
    "        self.df_simp.insert(\n",
    "            4, \"inter_stim.ended\", self.df_simp[\"inter_stim.started\"] + 3\n",
    "        )  # inter-stimulus duration is 3 seconds\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_ZB_list = []\n",
    "        self.num_corr_OB_list = []\n",
    "        self.num_corr_TB_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if \"0_back\" in task_type:\n",
    "                num_corr_ZB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_ZB_list.append(num_corr_ZB)\n",
    "            elif \"1_back\" in task_type:\n",
    "                num_corr_OB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_OB_list.append(num_corr_OB)\n",
    "            elif \"2_back\" in task_type:\n",
    "                num_corr_TB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_TB_list.append(num_corr_TB)\n",
    "\n",
    "        self.total_corr_ZB = sum(self.num_corr_ZB_list)\n",
    "        self.total_corr_OB = sum(self.num_corr_OB_list)\n",
    "        self.total_corr_TB = sum(self.num_corr_TB_list)\n",
    "        self.total_corr = self.total_corr_ZB + self.total_corr_OB + self.total_corr_TB\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_ZB_list = []\n",
    "        self.resp_time_OB_list = []\n",
    "        self.resp_time_TB_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if \"0_back\" in task_type:\n",
    "                resp_time_ZB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_ZB_list.append(resp_time_ZB)\n",
    "            elif \"1_back\" in task_type:\n",
    "                resp_time_OB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_OB_list.append(resp_time_OB)\n",
    "            elif \"2_back\" in task_type:\n",
    "                resp_time_TB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_TB_list.append(resp_time_TB)\n",
    "\n",
    "        self.avg_resp_time_ZB = mean(self.resp_time_ZB_list)\n",
    "        self.avg_resp_time_OB = mean(self.resp_time_OB_list)\n",
    "        self.avg_resp_time_TB = mean(self.resp_time_TB_list)\n",
    "        self.avg_resp_time = [\n",
    "            self.avg_resp_time_ZB,\n",
    "            self.avg_resp_time_OB,\n",
    "            self.avg_resp_time_TB,\n",
    "        ]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = []\n",
    "        task_order_simp2 = []\n",
    "        for task in task_order:\n",
    "            if \"ZB\" in task:\n",
    "                temp = task.split(\"-\")\n",
    "                task_simp = f\"0_back-{temp[1]}\"\n",
    "                task_simp2 = \"0_back\"\n",
    "            elif \"OB\" in task:\n",
    "                task_simp = \"1_back\"\n",
    "                task_simp2 = \"1_back\"\n",
    "            elif \"TB\" in task:\n",
    "                task_simp = \"2_back\"\n",
    "                task_simp2 = \"2_back\"\n",
    "            task_order_simp.append(task_simp)\n",
    "            task_order_simp2.append(task_simp2)\n",
    "\n",
    "        return task_order_simp, task_order_simp2\n",
    "\n",
    "\n",
    "class Resting_State(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Resting State experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        session_duration: Duration of each session (eyes open and eyes closed)\n",
    "        inter_stim_duration: Duration between stimuli\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"resting_state\"\n",
    "        self.num_blocks = 2\n",
    "        self.num_trials = 1\n",
    "        self.session_duration = 210  # seconds for each task (eyes open and eyes closed)\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"trial_cross.started\", \"halfway_tone.started\", \"done_sound.started\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.replace(\" \", \"_\") for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "\n",
    "class Tower_of_London(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Tower of London experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        stim_duration: Duration of stimulus\n",
    "        response_duration: Duration the participant has to respond\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"tower_of_london\"\n",
    "        self.num_blocks = 6\n",
    "        self.num_trials = 6\n",
    "        self.stim_duration = 7  # seconds\n",
    "        self.response_duration = 3  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\n",
    "            \"match\",\n",
    "            \"image_stim\",\n",
    "            \"stim_image.started\",\n",
    "            \"stim_text.started\",\n",
    "            \"stim_resp.corr\",\n",
    "            \"stim_resp.rt\",\n",
    "        ]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp = self.df_simp.copy()\n",
    "        self.df_simp[\"image_stim\"] = self.df_simp[\"image_stim\"].apply(self._strip_stim)\n",
    "        self.df_simp.insert(\n",
    "            3,\n",
    "            \"stim_image.ended\",\n",
    "            self.df_simp[\"stim_image.started\"] + self.stim_duration,\n",
    "        )\n",
    "        self.df_simp.insert(\n",
    "            5,\n",
    "            \"stim_text.ended\",\n",
    "            self.df_simp[\"stim_text.started\"] + self.response_duration,\n",
    "        )\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _strip_stim(self, row):\n",
    "        try:\n",
    "            temp_list = row.split(\"\\\\\")\n",
    "            if len(temp_list) == 3:\n",
    "                return temp_list[1].split(\"stim_\")[1]\n",
    "            else:\n",
    "                return temp_list[0].split(\"_stimuli\")[0]\n",
    "        except:\n",
    "            return row\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_MM_list = []\n",
    "        self.num_corr_ZM_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"MM\":\n",
    "                num_corr_MM = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_MM_list.append(num_corr_MM)\n",
    "            elif task_type == \"ZM\":\n",
    "                num_corr_ZM = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_ZM_list.append(num_corr_ZM)\n",
    "\n",
    "        self.total_corr_MM = sum(self.num_corr_MM_list)\n",
    "        self.total_corr_ZM = sum(self.num_corr_ZM_list)\n",
    "        self.total_corr = self.total_corr_MM + self.total_corr_ZM\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_MM_list = []\n",
    "        self.resp_time_ZM_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"MM\":\n",
    "                resp_time_MM = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_MM_list.append(resp_time_MM)\n",
    "            elif task_type == \"ZM\":\n",
    "                resp_time_ZM = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_ZM_list.append(resp_time_ZM)\n",
    "\n",
    "        self.avg_resp_time_MM = mean(self.resp_time_MM_list)\n",
    "        self.avg_resp_time_ZM = mean(self.resp_time_ZM_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_MM, self.avg_resp_time_ZM]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "\n",
    "class Video_Narrative_CMIYC(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Video Narrative CMIYC experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        clip_duration: Number of seconds in the narrative clip\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        response: Participant response to the narrative\n",
    "        block_start_time: Start timestamp of the narrative clip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"video_narrative_cmiyc\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.clip_duration = 300  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"video_start.started\", \"catchme_participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"video_start.ended\",\n",
    "            self.df_simp[\"video_start.started\"] + self.clip_duration,\n",
    "        )\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"catchme_participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\n",
    "                \"Video Narrative CMIYC: Need to combine 'participant response' columns into a single column.\"\n",
    "            )\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"video_start.started\"][0]\n",
    "\n",
    "\n",
    "class Video_Narrative_Sherlock(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the Video Narrative Sherlock experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        clip_duration: Number of seconds in the narrative clip\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        response: Participant response to the narrative\n",
    "        block_start_time: Start timestamp of the narrative clip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"video_narrative_sherlock\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.clip_duration = 300  # seconds\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\"video_start.started\", \"sherlock_participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_simp.insert(\n",
    "            1,\n",
    "            \"video_start.ended\",\n",
    "            self.df_simp[\"video_start.started\"] + self.clip_duration,\n",
    "        )\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"sherlock_participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\n",
    "                \"ERROR: Sherlock - Need to combine 'participant response' columns into a single column.\"\n",
    "            )\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"video_start.started\"][0]\n",
    "\n",
    "\n",
    "class vSAT(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing the vSAT experiment.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions\n",
    "\n",
    "    Attributes:\n",
    "        exp_name: Name of the experiment\n",
    "        num_blocks: Number of blocks in the experiment\n",
    "        num_trials: Number of trials in the experiment\n",
    "        data_filepath: Path to the experiment directory\n",
    "        marker_data: Start and end marker data for the experiment\n",
    "        task_order: Order of experiment tasks\n",
    "        task_order_simp: Simplified order of experiment tasks\n",
    "        df: Full experimental data\n",
    "        df_simp: Selection of experimental data\n",
    "        df_by_block: Selection of experimental data organized into task blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"vSAT\"\n",
    "        self.num_blocks = 4\n",
    "        self.num_trials = 30\n",
    "        # NOTE: stimulus duration is variable\n",
    "        # NOTE: stimulus location is variable\n",
    "        # NOTE: inter-stimulus duration is variable\n",
    "        self.data_filepath = self.get_data_filepath(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(\n",
    "            par_dir=par_dir, exp_name=self.exp_name\n",
    "        )\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = pd.read_csv(self.data_filepath)\n",
    "        cols = [\n",
    "            \"match\",\n",
    "            \"stim_time\",\n",
    "            \"inter_stim_time\",\n",
    "            \"x_pos\",\n",
    "            \"y_pos\",\n",
    "            \"inter_stim_text.started\",\n",
    "            \"vSAT_square.started\",\n",
    "            \"stim_resp.corr\",\n",
    "            \"stim_resp.rt\",\n",
    "            \"feedback_sound.started\",\n",
    "        ]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self._add_pos_col()\n",
    "        self.df_simp.insert(\n",
    "            5,\n",
    "            \"inter_stim_text.ended\",\n",
    "            self.df_simp[\"inter_stim_text.started\"] + self.df_simp[\"inter_stim_time\"],\n",
    "        )\n",
    "        self.df_simp.insert(\n",
    "            7,\n",
    "            \"vSAT_square.ended\",\n",
    "            self.df_simp[\"vSAT_square.started\"] + self.df_simp[\"stim_time\"],\n",
    "        )\n",
    "        self.df_simp.insert(\n",
    "            11, \"feedback_sound.ended\", self.df_simp[\"feedback_sound.started\"] + 0.5\n",
    "        )  # 0.5 second feedback sound\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(\n",
    "            df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials\n",
    "        )\n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_SAT_list = []\n",
    "        self.num_corr_vSAT_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"SAT\":\n",
    "                num_corr_SAT = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_SAT_list.append(num_corr_SAT)\n",
    "            elif task_type == \"vSAT\":\n",
    "                num_corr_vSAT = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_vSAT_list.append(num_corr_vSAT)\n",
    "\n",
    "        self.total_corr_SAT = sum(self.num_corr_SAT_list)\n",
    "        self.total_corr_vSAT = sum(self.num_corr_vSAT_list)\n",
    "        self.total_corr = self.total_corr_SAT + self.total_corr_vSAT\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_SAT_list = []\n",
    "        self.resp_time_vSAT_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"SAT\":\n",
    "                resp_time_SAT = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_SAT_list.append(resp_time_SAT)\n",
    "            elif task_type == \"vSAT\":\n",
    "                resp_time_vSAT = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_vSAT_list.append(resp_time_vSAT)\n",
    "\n",
    "        self.avg_resp_time_SAT = mean(self.resp_time_SAT_list)\n",
    "        self.avg_resp_time_vSAT = mean(self.resp_time_vSAT_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_SAT, self.avg_resp_time_vSAT]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "    def _add_pos_col(self):\n",
    "        x_pos_col = self.df_simp[\"x_pos\"]\n",
    "        y_pos_col = self.df_simp[\"y_pos\"]\n",
    "\n",
    "        pos_list = []\n",
    "        for x_pos, y_pos in zip(x_pos_col, y_pos_col):\n",
    "            if x_pos == 0 and y_pos == 0:\n",
    "                pos = \"center\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == 0.25 and y_pos == 0.25:\n",
    "                pos = \"top-right\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == 0.25 and y_pos == -0.25:\n",
    "                pos = \"bottom-right\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == -0.25 and y_pos == 0.25:\n",
    "                pos = \"top-left\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == -0.25 and y_pos == -0.25:\n",
    "                pos = \"bottom-left\"\n",
    "                pos_list.append(pos)\n",
    "            else:\n",
    "                pos = \"Nan\"\n",
    "                pos_list.append(pos)\n",
    "\n",
    "        self.df_simp.insert(loc=4, column=\"position\", value=pos_list)\n",
    "        self.df_simp = self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"])\n",
    "\n",
    "\n",
    "class Participant_Behav(Data_Functions):\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing participants and behavioral data from the experiments.\n",
    "\n",
    "    Args:\n",
    "        Data_Functions (class): Experiment processing functions.\n",
    "\n",
    "    Attributes:\n",
    "        par_num: Participant number\n",
    "        par_id: Participant ID\n",
    "        par_dir: Path to specific participant directory\n",
    "        exp_order: Experiment order\n",
    "        all_marker_timestamps: Dictionary with start and end timestamps for each experiment\n",
    "        marker_ts_df: DataFrame with start and end timestamps for each experiment\n",
    "        audio_narrative: Audio Narrative experiment instance\n",
    "        go_no_go: Go/No-Go experiment instance\n",
    "        king_devick: King Devick experiment instance\n",
    "        n_back: N-Back experiment instance\n",
    "        tower_of_london: Tower of London experiment instance\n",
    "        video_narrative_cmiyc: Video Narrative CMIYC experiment instance\n",
    "        video_narrative_sherlock: Video Narrative Sherlock experiment instance\n",
    "        vSAT: vSAT experiment instance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_num, adj_ts_markers=True):\n",
    "        super().__init__()\n",
    "        self.par_num, self.par_ID = self.process_par(par_num)\n",
    "        self.raw_data_dir = r\"C:\\Kernel\\raw_data\"  # TODO: make this path relative\n",
    "        self.processed_data_dir = os.path.join(\n",
    "            os.getcwd(), \"processed_data\", \"behavioral\"\n",
    "        )\n",
    "        self.par_dir = os.path.join(self.raw_data_dir, self.par_ID)\n",
    "        self.forms_filepath = os.path.join(\n",
    "            os.getcwd(), \"processed_data\", \"participant_forms.xlsx\"\n",
    "        )\n",
    "        self.exp_order = self.get_exp_order()\n",
    "        self.session_dict = self.create_session_dict()\n",
    "        self.form_info = self.load_form_info()\n",
    "\n",
    "        self.all_marker_timestamps = self.get_all_marker_timestamps(\n",
    "            par_dir=self.par_dir, exp_order=self.exp_order\n",
    "        )\n",
    "        if adj_ts_markers:\n",
    "            self.all_marker_timestamps_adj = self.adjust_all_marker_timestamps(\n",
    "                copy.deepcopy(self.all_marker_timestamps),\n",
    "                self.processed_data_dir,\n",
    "                self.par_num,\n",
    "            )\n",
    "        self._create_marker_ts_csv()\n",
    "        marker_csv_filepath = r\"C:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Experiment\\main\\marker_dict.csv\"\n",
    "        self.marker_dict = self.load_marker_dict(\n",
    "            marker_csv_filepath\n",
    "        )  # TODO: make this path relative\n",
    "        self.marker_ts_df = self._create_marker_ts_df()\n",
    "\n",
    "        self.audio_narrative = Audio_Narrative(par_dir=self.par_dir)\n",
    "        self.audio_narrative.start_ts = self.get_start_ts(\n",
    "            \"audio_narrative\", adj_ts_markers\n",
    "        )\n",
    "        self.audio_narrative.end_ts = self.get_end_ts(\"audio_narrative\", adj_ts_markers)\n",
    "        self.audio_narrative.df_adj_ts = self.adjust_df_ts(\n",
    "            self.audio_narrative.df_simp,\n",
    "            self.audio_narrative.start_ts,\n",
    "            [\"pieman_clip.started\", \"pieman_clip.ended\"],\n",
    "        )\n",
    "\n",
    "        self.go_no_go = Go_No_Go(par_dir=self.par_dir)\n",
    "        self.go_no_go.start_ts = self.get_start_ts(\"go_no_go\", adj_ts_markers)\n",
    "        self.go_no_go.end_ts = self.get_end_ts(\"go_no_go\", adj_ts_markers)\n",
    "        self.go_no_go.df_adj_ts = self.adjust_df_ts(\n",
    "            self.go_no_go.df_no_nan,\n",
    "            self.go_no_go.start_ts,\n",
    "            [\n",
    "                \"inter_stim_plus.started\",\n",
    "                \"inter_stim_plus.ended\",\n",
    "                \"go_image.started\",\n",
    "                \"go_image.stopped\",\n",
    "            ],\n",
    "        )\n",
    "        self.go_no_go.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.go_no_go.df_by_block,\n",
    "            self.go_no_go.start_ts,\n",
    "            [\n",
    "                \"inter_stim_plus.started\",\n",
    "                \"inter_stim_plus.ended\",\n",
    "                \"go_image.started\",\n",
    "                \"go_image.stopped\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.king_devick = King_Devick(par_dir=self.par_dir)\n",
    "        self.king_devick.start_ts = self.get_start_ts(\"king_devick\", adj_ts_markers)\n",
    "        self.king_devick.end_ts = self.get_end_ts(\"king_devick\", adj_ts_markers)\n",
    "        self.king_devick.df_adj_ts = self.adjust_df_ts(\n",
    "            self.king_devick.df_simp,\n",
    "            self.king_devick.start_ts,\n",
    "            [\"card_image.started\", \"card_image.ended\"],\n",
    "        )\n",
    "\n",
    "        self.n_back = N_Back(par_dir=self.par_dir)\n",
    "        self.n_back.start_ts = self.get_start_ts(\"n_back\", adj_ts_markers)\n",
    "        self.n_back.end_ts = self.get_end_ts(\"n_back\", adj_ts_markers)\n",
    "        self.n_back.df_adj_ts = self.adjust_df_ts(\n",
    "            self.n_back.df_no_nan,\n",
    "            self.n_back.start_ts,\n",
    "            [\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "                \"inter_stim.started\",\n",
    "                \"inter_stim.ended\",\n",
    "            ],\n",
    "        )\n",
    "        self.n_back.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.n_back.df_by_block,\n",
    "            self.n_back.start_ts,\n",
    "            [\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "                \"inter_stim.started\",\n",
    "                \"inter_stim.ended\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.resting_state = Resting_State(par_dir=self.par_dir)\n",
    "        self.resting_state.start_ts = self.get_start_ts(\"resting_state\", adj_ts_markers)\n",
    "        self.resting_state.end_ts = self.get_end_ts(\"resting_state\", adj_ts_markers)\n",
    "        self.resting_state.df_adj_ts = self.adjust_df_ts(\n",
    "            self.resting_state.df_simp,\n",
    "            self.resting_state.start_ts,\n",
    "            [\"trial_cross.started\", \"halfway_tone.started\", \"done_sound.started\"],\n",
    "        )\n",
    "\n",
    "        self.tower_of_london = Tower_of_London(par_dir=self.par_dir)\n",
    "        self.tower_of_london.start_ts = self.get_start_ts(\n",
    "            \"tower_of_london\", adj_ts_markers\n",
    "        )\n",
    "        self.tower_of_london.end_ts = self.get_end_ts(\"tower_of_london\", adj_ts_markers)\n",
    "        self.tower_of_london.df_adj_ts = self.adjust_df_ts(\n",
    "            self.tower_of_london.df_no_nan,\n",
    "            self.tower_of_london.start_ts,\n",
    "            [\n",
    "                \"stim_image.started\",\n",
    "                \"stim_image.ended\",\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "            ],\n",
    "        )\n",
    "        self.tower_of_london.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.tower_of_london.df_by_block,\n",
    "            self.tower_of_london.start_ts,\n",
    "            [\n",
    "                \"stim_image.started\",\n",
    "                \"stim_image.ended\",\n",
    "                \"stim_text.started\",\n",
    "                \"stim_text.ended\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.video_narrative_cmiyc = Video_Narrative_CMIYC(par_dir=self.par_dir)\n",
    "        self.video_narrative_cmiyc.start_ts = self.get_start_ts(\n",
    "            \"video_narrative_cmiyc\", adj_ts_markers\n",
    "        )\n",
    "        self.video_narrative_cmiyc.end_ts = self.get_end_ts(\n",
    "            \"video_narrative_cmiyc\", adj_ts_markers\n",
    "        )\n",
    "        self.video_narrative_cmiyc.df_adj_ts = self.adjust_df_ts(\n",
    "            self.video_narrative_cmiyc.df_simp,\n",
    "            self.video_narrative_cmiyc.start_ts,\n",
    "            [\"video_start.started\", \"video_start.ended\"],\n",
    "        )\n",
    "\n",
    "        self.video_narrative_sherlock = Video_Narrative_Sherlock(par_dir=self.par_dir)\n",
    "        self.video_narrative_sherlock.start_ts = self.get_start_ts(\n",
    "            \"video_narrative_sherlock\", adj_ts_markers\n",
    "        )\n",
    "        self.video_narrative_sherlock.end_ts = self.get_end_ts(\n",
    "            \"video_narrative_sherlock\", adj_ts_markers\n",
    "        )\n",
    "        self.video_narrative_sherlock.df_adj_ts = self.adjust_df_ts(\n",
    "            self.video_narrative_sherlock.df_simp,\n",
    "            self.video_narrative_sherlock.start_ts,\n",
    "            [\"video_start.started\", \"video_start.ended\"],\n",
    "        )\n",
    "\n",
    "        self.vSAT = vSAT(par_dir=self.par_dir)\n",
    "        self.vSAT.start_ts = self.get_start_ts(\"vSAT\", adj_ts_markers)\n",
    "        self.vSAT.end_ts = self.get_end_ts(\"vSAT\", adj_ts_markers)\n",
    "        self.vSAT.df_adj_ts = self.adjust_df_ts(\n",
    "            self.vSAT.df_no_nan,\n",
    "            self.vSAT.start_ts,\n",
    "            [\n",
    "                \"inter_stim_text.started\",\n",
    "                \"inter_stim_text.ended\",\n",
    "                \"vSAT_square.started\",\n",
    "                \"vSAT_square.ended\",\n",
    "                \"feedback_sound.started\",\n",
    "                \"feedback_sound.ended\",\n",
    "            ],\n",
    "        )\n",
    "        self.vSAT.df_by_block_adj_ts = self.adjust_df_ts(\n",
    "            self.vSAT.df_by_block,\n",
    "            self.vSAT.start_ts,\n",
    "            [\n",
    "                \"inter_stim_text.started\",\n",
    "                \"inter_stim_text.ended\",\n",
    "                \"vSAT_square.started\",\n",
    "                \"vSAT_square.ended\",\n",
    "                \"feedback_sound.started\",\n",
    "                \"feedback_sound.ended\",\n",
    "            ],\n",
    "            by_block=True,\n",
    "        )\n",
    "\n",
    "        self.by_block_ts_dict = self._create_by_block_ts_dict()\n",
    "\n",
    "        self.exp_color_dict = {\n",
    "            \"audio_narrative\": \"yellow\",\n",
    "            \"go_no_go\": \"green\",\n",
    "            \"king_devick\": \"blue\",\n",
    "            \"n_back\": \"purple\",\n",
    "            \"resting_state\": \"pink\",\n",
    "            \"tower_of_london\": \"orange\",\n",
    "            \"video_narrative_cmiyc\": \"red\",\n",
    "            \"video_narrative_sherlock\": \"olive\",\n",
    "            \"vSAT\": \"cyan\",\n",
    "        }\n",
    "\n",
    "    def get_exp_order(self) -> list:\n",
    "        \"\"\"\n",
    "        Get the experiment order from a text file.\n",
    "\n",
    "        Returns:\n",
    "            list: Experiment order\n",
    "        \"\"\"\n",
    "\n",
    "        exp_order_filename = f\"{self.par_ID}_experiment_order.txt\"\n",
    "        exp_order_filepath = os.path.join(self.par_dir, exp_order_filename)\n",
    "\n",
    "        with open(exp_order_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        exp_order = []\n",
    "        for line in lines:\n",
    "            if \"Block\" in line or \"-\" in line or line == \"\\n\":\n",
    "                pass\n",
    "            else:\n",
    "                exp_order.append(line.strip(\"\\n\"))\n",
    "\n",
    "        return exp_order\n",
    "\n",
    "    def create_session_dict(self) -> dict:\n",
    "        \"\"\"\n",
    "        Create a dictionary containing the experiment names for each session.\n",
    "\n",
    "        Returns:\n",
    "            dict: Experiment names for each session.\n",
    "                keys:\n",
    "                    \"session_1001\", \"session_1002\", \"session_1003\"\n",
    "                values:\n",
    "                    list of experiment names\n",
    "        \"\"\"\n",
    "        session_dict = {}\n",
    "        session_exp_list = []\n",
    "        session_num = 1\n",
    "        for i, exp_name in enumerate(self.exp_order):\n",
    "            session_exp_list.append(exp_name)\n",
    "            if (i + 1) % 3 == 0:\n",
    "                session_name = f\"session_100{session_num}\"\n",
    "                session_dict[session_name] = session_exp_list\n",
    "                session_num += 1\n",
    "                session_exp_list = []\n",
    "        return session_dict\n",
    "\n",
    "    def load_form_info(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load the information from a participant's forms info a DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame of participant form info.\n",
    "        \"\"\"\n",
    "        forms_df = pd.read_excel(self.forms_filepath)\n",
    "        form_info = forms_df[forms_df[\"participant\"] == self.par_num]\n",
    "        return form_info.reset_index()\n",
    "\n",
    "    def _create_marker_ts_csv(self) -> None:\n",
    "        \"\"\"\n",
    "        Create a CSV file containing the start and end timestamps for each experiment.\n",
    "        \"\"\"\n",
    "        filepath = os.path.join(\n",
    "            self.par_dir,\n",
    "            f\"{self.par_ID}_marker_timestamps.csv\",\n",
    "        )\n",
    "        if os.path.exists(filepath):\n",
    "            pass\n",
    "        else:\n",
    "            marker_list = []\n",
    "            for exp_name, ts_list in self.all_marker_timestamps.items():\n",
    "                temp_list = []\n",
    "                temp_list.append(exp_name)\n",
    "                temp_list.extend(ts_list)\n",
    "                marker_list.append(temp_list)\n",
    "            marker_ts_df = pd.DataFrame(\n",
    "                marker_list, columns=[\"exp_name\", \"start_timestamp\", \"end_timestamp\"]\n",
    "            )\n",
    "            marker_ts_df.to_csv(filepath, index=False)\n",
    "\n",
    "    def _create_marker_ts_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a DataFrame from a CSV file containing the start and end timestamps for each experiment.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Start and end timestamps for each experiment\n",
    "        \"\"\"\n",
    "        marker_ts_filepath = os.path.join(\n",
    "            self.par_dir, f\"{self.par_ID}_marker_timestamps.csv\"\n",
    "        )\n",
    "\n",
    "        return pd.read_csv(marker_ts_filepath)\n",
    "\n",
    "    def get_start_ts(self, exp_name: str, adj_ts_markers: bool = True) -> float:\n",
    "        \"\"\"\n",
    "        Get the start timestamp of an experiment.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Name of the experiment.\n",
    "            adj_ts_markers (bool): Use adjusted end timestamp marker. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            float: Start timestamp of the experiment.\n",
    "        \"\"\"\n",
    "        if adj_ts_markers:\n",
    "            return float(int(self.all_marker_timestamps_adj[exp_name][0]) / 1e9)\n",
    "        else:\n",
    "            return float(int(self.all_marker_timestamps[exp_name][0]) / 1e9)\n",
    "\n",
    "    def get_end_ts(self, exp_name: str, adj_ts_markers: bool = True) -> float:\n",
    "        \"\"\"\n",
    "        Get the end timestamp of an experiment.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Name of the experiment.\n",
    "            adj_ts_markers (bool): Use adjusted end timestamp marker. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            float: End timestamp of the experiment.\n",
    "        \"\"\"\n",
    "        if adj_ts_markers:\n",
    "            return float(int(self.all_marker_timestamps_adj[exp_name][1]) / 1e9)\n",
    "        else:\n",
    "            return float(int(self.all_marker_timestamps[exp_name][1]) / 1e9)\n",
    "\n",
    "    def get_start_dt(\n",
    "        self, exp_name: str, adj_ts_markers: bool = True\n",
    "    ) -> datetime.datetime:\n",
    "        \"\"\"\n",
    "        Convert start timestamp of an experiment into the start datetime.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Experiment name.\n",
    "            adj_ts_markers (bool): Use adjusted end timestamp marker. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            datetime.datetime: Start datetime of an experiment.\n",
    "        \"\"\"\n",
    "        if adj_ts_markers:\n",
    "            return datetime.datetime.fromtimestamp(\n",
    "                int(self.all_marker_timestamps_adj[exp_name][0]) / 1e9\n",
    "            )\n",
    "        else:\n",
    "            return datetime.datetime.fromtimestamp(\n",
    "                int(self.all_marker_timestamps[exp_name][0]) / 1e9\n",
    "            )\n",
    "\n",
    "    def get_end_dt(\n",
    "        self, exp_name: str, adj_ts_markers: bool = True\n",
    "    ) -> datetime.datetime:\n",
    "        \"\"\"\n",
    "        Convert end timestamp of an experiment into the end datetime.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Experiment name.\n",
    "            adj_ts_markers (bool): Use adjusted end timestamp marker. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            datetime.datetime: End datetime of an experiment.\n",
    "        \"\"\"\n",
    "        if adj_ts_markers:\n",
    "            return datetime.datetime.fromtimestamp(\n",
    "                int(self.all_marker_timestamps_adj[exp_name][1]) / 1e9\n",
    "            )\n",
    "        else:\n",
    "            return datetime.datetime.fromtimestamp(\n",
    "                int(self.all_marker_timestamps[exp_name][1]) / 1e9\n",
    "            )\n",
    "\n",
    "    def _create_by_block_ts_dict(self) -> dict:\n",
    "        \"\"\"\n",
    "        Creates a dictionary with the start and end timestamps for each block and trial of each experiment.\n",
    "\n",
    "        Returns:\n",
    "            dict: Block and trial start and end timestamps for each experiment\n",
    "                keys:\n",
    "                    'audio_narrative', 'go_no_go', 'king_devick', 'n_back', 'resting_state',\n",
    "                    'tower_of_london', 'video_narrative_cmiyc', 'video_narrative_sherlock', 'vSAT'\n",
    "                values: start and end timestamp dict\n",
    "                    keys:\n",
    "                        (start timestamp, end_timestamp)\n",
    "                    values: block and trial dict\n",
    "                        keys:\n",
    "                            'block', 'trial'\n",
    "                        values:\n",
    "                            'block name', 'trial number'\n",
    "        \"\"\"\n",
    "\n",
    "        def format_ts(exp_name: str) -> Tuple[float, float]:\n",
    "            \"\"\"\n",
    "            Format timestamp into UTC second format from nanosecond format.\n",
    "\n",
    "            Args:\n",
    "                exp_name (str): Experiment name\n",
    "\n",
    "            Returns:\n",
    "                Tuple[float, float]: Start timestamp, end timestamp\n",
    "            \"\"\"\n",
    "            start_ts, end_ts = self.get_exp_ts(self.marker_ts_df, exp_name=exp_name)\n",
    "            return start_ts / 1e9, end_ts / 1e9\n",
    "\n",
    "        def get_value_dict(block: str, trial: int) -> dict:\n",
    "            \"\"\"\n",
    "            Create a dictionary with block and trial values.\n",
    "\n",
    "            Args:\n",
    "                block (str): Experiment block\n",
    "                trial (int): Experiment trial\n",
    "\n",
    "            Returns:\n",
    "                dict: Block and trial dictionary\n",
    "                    keys:\n",
    "                        'block', 'trial'\n",
    "                    values:\n",
    "                        'block name', 'trial number'\n",
    "            \"\"\"\n",
    "            return {\"block\": block, \"trial\": trial}\n",
    "\n",
    "        by_block_ts_dict = {}\n",
    "        for exp_name in self.exp_order:\n",
    "            block_ts_df = {}\n",
    "\n",
    "            if exp_name == \"audio_narrative\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.audio_narrative.df_simp[\n",
    "                    \"pieman_clip.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                clip_length = 423  # 423 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                value_dict = get_value_dict(\"audio_narrative\", 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"go_no_go\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(\n",
    "                        self.go_no_go.task_order_simp,\n",
    "                        self.go_no_go.df_by_block.values(),\n",
    "                    )\n",
    "                ):\n",
    "                    block_start_time = block_df[\"inter_stim_plus.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"go_image.started\"].iloc[-1] + 0.5\n",
    "                    )  # image shown for 0.5 seconds\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"king_devick\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                task_order = (\n",
    "                    self.king_devick.task_order_new\n",
    "                    if self.king_devick.task_order_new\n",
    "                    else self.king_devick.task_order\n",
    "                )\n",
    "                for i, (block, block_start_time, rt) in enumerate(\n",
    "                    zip(\n",
    "                        task_order,\n",
    "                        self.king_devick.df_simp[\"card_image.started\"].values,\n",
    "                        self.king_devick.df_simp[\"card_resp.rt\"].values,\n",
    "                    )\n",
    "                ):\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_ts = block_start_ts + rt\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"n_back\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(self.n_back.task_order_simp2, self.n_back.df_by_block.values())\n",
    "                ):\n",
    "                    block_start_time = block_df[\"stim_text.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"stim_text.started\"].iloc[-1] + 0.5\n",
    "                    )  # number shown for 0.5 seconds\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"resting_state\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.resting_state.df_simp[\n",
    "                    \"trial_cross.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                block_end_ts = block_start_ts + (\n",
    "                    self.resting_state.df_simp[\"halfway_tone.started\"].item()\n",
    "                    - block_start_time\n",
    "                )\n",
    "                value_dict = get_value_dict(self.resting_state.task_order_simp[0], 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "                block_start_time = self.resting_state.df_simp[\n",
    "                    \"halfway_tone.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                block_end_ts = block_start_ts + (\n",
    "                    self.resting_state.df_simp[\"done_sound.started\"].item()\n",
    "                    - block_start_time\n",
    "                )\n",
    "                value_dict = get_value_dict(self.resting_state.task_order_simp[1], 2)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"tower_of_london\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(\n",
    "                        self.tower_of_london.task_order_simp,\n",
    "                        self.tower_of_london.df_by_block.values(),\n",
    "                    )\n",
    "                ):\n",
    "                    block_start_time = block_df[\"stim_image.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"stim_text.started\"].iloc[-1] + 3\n",
    "                    )  # 3 seconds to respond\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"video_narrative_cmiyc\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.video_narrative_cmiyc.df_simp[\n",
    "                    \"video_start.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time  # NOTE\n",
    "                clip_length = 300  # 300 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                value_dict = get_value_dict(\"video_narrative_cmiyc\", 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"video_narrative_sherlock\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.video_narrative_sherlock.df_simp[\n",
    "                    \"video_start.started\"\n",
    "                ].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                clip_length = 300  # 300 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                value_dict = get_value_dict(\"video_narrative_sherlock\", 1)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "\n",
    "            elif exp_name == \"vSAT\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for i, (block, block_df) in enumerate(\n",
    "                    zip(self.vSAT.task_order_simp, self.vSAT.df_by_block.values())\n",
    "                ):\n",
    "                    block_start_time = block_df[\"inter_stim_text.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = (\n",
    "                        block_df[\"feedback_sound.started\"].iloc[-1] + 0.5\n",
    "                    )  # 0.5 second delay\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    value_dict = get_value_dict(block, i + 1)\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = value_dict\n",
    "            by_block_ts_dict[exp_name] = block_ts_df\n",
    "\n",
    "        return by_block_ts_dict\n",
    "\n",
    "    def get_exp(self, exp_name: str):\n",
    "        \"\"\"\n",
    "        Get an instance of the experiment class.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Experiment name\n",
    "\n",
    "        Returns:\n",
    "            class: Instance of experiment class\n",
    "        \"\"\"\n",
    "        if exp_name == \"audio_narrative\":\n",
    "            return self.audio_narrative\n",
    "        elif exp_name == \"go_no_go\":\n",
    "            return self.go_no_go\n",
    "        elif exp_name == \"king_devick\":\n",
    "            return self.king_devick\n",
    "        elif exp_name == \"n_back\":\n",
    "            return self.n_back\n",
    "        elif exp_name == \"resting_state\":\n",
    "            return self.resting_state\n",
    "        elif exp_name == \"tower_of_london\":\n",
    "            return self.tower_of_london\n",
    "        elif exp_name == \"video_narrative_cmiyc\":\n",
    "            return self.video_narrative_cmiyc\n",
    "        elif exp_name == \"video_narrative_sherlock\":\n",
    "            return self.video_narrative_sherlock\n",
    "        elif exp_name == \"vSAT\":\n",
    "            return self.vSAT\n",
    "\n",
    "\n",
    "def create_behav_results_tables(num_pars: int) -> None:\n",
    "    \"\"\"\n",
    "    Write the processed experiment and behavioral data into CSV files.\n",
    "\n",
    "    Args:\n",
    "        num_pars (int): Number of participants\n",
    "    \"\"\"\n",
    "\n",
    "    def get_num_rows(exp, new: bool = False) -> int:\n",
    "        \"\"\"\n",
    "        Get the number of rows needed for the experiment (number of blocks * number of trials).\n",
    "\n",
    "        Args:\n",
    "            exp (class): Instance of an experiment class\n",
    "            new (bool, optional): Is there a new number of rows? Defaults to False\n",
    "\n",
    "        Returns:\n",
    "            int: Number of rows in the experiment\n",
    "        \"\"\"\n",
    "        if new:\n",
    "            return int(exp.num_blocks * exp.num_trials_new)\n",
    "        else:\n",
    "            return int(exp.num_blocks * exp.num_trials)\n",
    "\n",
    "    def get_form_info_df(num_rows: int, form_info_cols: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get a DataFrame of form info for the specified columns.\n",
    "\n",
    "        Args:\n",
    "            num_rows (int): Number of rows in the experiment.\n",
    "            form_info_cols (list): Columns to select from the form info.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame of specified form info.\n",
    "        \"\"\"\n",
    "        cols = []\n",
    "        for col_name, dtype in form_info_cols.items():\n",
    "            form_data = par.form_info.loc[0, col_name]\n",
    "            cols.append(data_fun.create_col(form_data, num_rows, dtype))\n",
    "        form_info_df = pd.concat(cols, keys=[k for k in form_info_cols.keys()], axis=1)\n",
    "        return form_info_df\n",
    "\n",
    "    data_fun = Data_Functions()\n",
    "\n",
    "    audio_df_list = []\n",
    "    gng_df_list = []\n",
    "    kd_df_list = []\n",
    "    n_back_df_list = []\n",
    "    rs_df_list = []\n",
    "    tol_df_list = []\n",
    "    video_cmiyc_df_list = []\n",
    "    video_sherlock_df_list = []\n",
    "    vsat_df_list = []\n",
    "\n",
    "    form_info_cols = {\n",
    "        \"sex\": pd.StringDtype(),\n",
    "        \"age\": int,\n",
    "        \"hours_of_sleep\": float,\n",
    "    }  # columns to select from the form info\n",
    "\n",
    "    for i in range(num_pars):\n",
    "        par_num = f\"{(i+1):02d}\"\n",
    "        par = Participant_Behav(par_num=par_num, adj_ts_markers=False)\n",
    "\n",
    "        # Audio Narrative ----\n",
    "        exp = par.audio_narrative\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1])\n",
    "        block_col = pd.Series([\"audio_narrative\"])\n",
    "\n",
    "        temp_audio_df = exp.df_adj_ts\n",
    "        temp_audio_df.insert(0, \"block\", block_col)\n",
    "        temp_audio_df.insert(0, \"stim\", [\"audio_narrative\"])\n",
    "        temp_audio_df.insert(0, \"trial\", trial_col)\n",
    "        temp_audio_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_audio_df = data_fun.insert_df_after_col(\n",
    "            temp_audio_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_audio_df.rename(\n",
    "            columns={\n",
    "                \"pieman_clip.started\": \"stim_start\",\n",
    "                \"pieman_clip.ended\": \"stim_end\",\n",
    "                \"participant_response.text\": \"response\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        audio_df_list.append(temp_audio_df)\n",
    "\n",
    "        # Go/No-Go -----\n",
    "        exp = par.go_no_go\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        gng_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp, gng_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_gng_df = pd.DataFrame()\n",
    "        temp_gng_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_gng_df.reset_index(inplace=True, drop=True)\n",
    "        temp_gng_df.insert(0, \"block\", block_col)\n",
    "        temp_gng_df.insert(0, \"trial\", trial_col)\n",
    "        temp_gng_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_gng_df = data_fun.insert_df_after_col(\n",
    "            temp_gng_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_gng_df.rename(\n",
    "            columns={\n",
    "                \"GNG_stim\": \"stim\",\n",
    "                \"inter_stim_plus.started\": \"inter_stim_start\",\n",
    "                \"inter_stim_plus.ended\": \"inter_stim_end\",\n",
    "                \"go_image.started\": \"stim_start\",\n",
    "                \"go_image.stopped\": \"stim_end\",\n",
    "                \"go_resp.corr\": \"correct_response\",\n",
    "                \"go_resp.rt\": \"response_time\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        gng_df_list.append(temp_gng_df.copy())\n",
    "\n",
    "        # King Devick -----\n",
    "        exp = par.king_devick\n",
    "\n",
    "        if int(par_num) >= 15:  # participants 15+ have a 4th card\n",
    "            num_rows = get_num_rows(exp=exp, new=True)\n",
    "            trial_col = pd.Series([1, 2, 3, 4])\n",
    "            block_col = pd.Series(exp.task_order_new)\n",
    "        else:\n",
    "            num_rows = get_num_rows(exp=exp)\n",
    "            trial_col = pd.Series([1, 2, 3])\n",
    "            block_col = pd.Series(exp.task_order)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        temp_kd_df = exp.df_adj_ts\n",
    "        temp_kd_df.insert(0, \"block\", block_col)\n",
    "        temp_kd_df.insert(0, \"trial\", trial_col)\n",
    "        temp_kd_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_kd_df = data_fun.insert_df_after_col(\n",
    "            temp_kd_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_kd_df = temp_kd_df.rename(\n",
    "            columns={\n",
    "                \"card_image.started\": \"stim_start\",\n",
    "                \"card_image.ended\": \"stim_end\",\n",
    "                \"card_resp.rt\": \"response_time\",\n",
    "            }\n",
    "        )\n",
    "        kd_df_list.append(temp_kd_df.copy())\n",
    "\n",
    "        # N-Back -----\n",
    "        exp = par.n_back\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        n_back_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp2, n_back_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_n_back_df = pd.DataFrame()\n",
    "        temp_n_back_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_n_back_df.reset_index(inplace=True, drop=True)\n",
    "        temp_n_back_df.insert(0, \"block\", block_col)\n",
    "        temp_n_back_df.insert(0, \"trial\", trial_col)\n",
    "        temp_n_back_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_n_back_df = data_fun.insert_df_after_col(\n",
    "            temp_n_back_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_n_back_df.rename(\n",
    "            columns={\n",
    "                \"stim_text.started\": \"stim_start\",\n",
    "                \"stim_text.ended\": \"stim_end\",\n",
    "                \"inter_stim.started\": \"inter_stim_start\",\n",
    "                \"inter_stim.ended\": \"inter_stim_end\",\n",
    "                \"stim_resp.corr\": \"correct_response\",\n",
    "                \"stim_resp.rt\": \"response_time\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        n_back_df_list.append(temp_n_back_df.copy())\n",
    "\n",
    "        # Resting State -----\n",
    "        exp = par.resting_state\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1, 2])\n",
    "        block_col = pd.Series(exp.task_order_simp)\n",
    "\n",
    "        temp_rs_df = pd.DataFrame(\n",
    "            {\n",
    "                \"stim_start\": [\n",
    "                    exp.df_adj_ts[\"trial_cross.started\"][0],\n",
    "                    exp.df_adj_ts[\"halfway_tone.started\"][0],\n",
    "                ],\n",
    "                \"stim_end\": [\n",
    "                    exp.df_adj_ts[\"halfway_tone.started\"][0],\n",
    "                    exp.df_adj_ts[\"done_sound.started\"][0],\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        temp_rs_df.insert(0, \"block\", block_col)\n",
    "        temp_rs_df.insert(0, \"trial\", trial_col)\n",
    "        temp_rs_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_rs_df = data_fun.insert_df_after_col(\n",
    "            temp_rs_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        rs_df_list.append(temp_rs_df)\n",
    "\n",
    "        # Tower of London -----\n",
    "        exp = par.tower_of_london\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        tol_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp, tol_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_tol_df = pd.DataFrame()\n",
    "        temp_tol_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_tol_df.reset_index(inplace=True, drop=True)\n",
    "        temp_tol_df.insert(0, \"block\", block_col)\n",
    "        temp_tol_df.insert(0, \"trial\", trial_col)\n",
    "        temp_tol_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_tol_df = data_fun.insert_df_after_col(\n",
    "            temp_tol_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_tol_df.rename(\n",
    "            columns={\n",
    "                \"image_stim\": \"stim\",\n",
    "                \"stim_image.started\": \"stim_start\",\n",
    "                \"stim_image.ended\": \"stim_end\",\n",
    "                \"stim_text.started\": \"response_start\",\n",
    "                \"stim_text.ended\": \"response_end\",\n",
    "                \"stim_resp.corr\": \"correct_response\",\n",
    "                \"stim_resp.rt\": \"response_time\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        tol_df_list.append(temp_tol_df.copy())\n",
    "\n",
    "        # Video Narrative CMIYC ----\n",
    "        exp = par.video_narrative_cmiyc\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1])\n",
    "        block_col = pd.Series([\"video_narrative_cmiyc\"])\n",
    "\n",
    "        temp_video_cmiyc_df = exp.df_adj_ts\n",
    "        temp_video_cmiyc_df.insert(0, \"block\", block_col)\n",
    "        temp_video_cmiyc_df.insert(0, \"stim\", [\"video_narrative\"])\n",
    "        temp_video_cmiyc_df.insert(0, \"trial\", trial_col)\n",
    "        temp_video_cmiyc_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_video_cmiyc_df = data_fun.insert_df_after_col(\n",
    "            temp_video_cmiyc_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_video_cmiyc_df.rename(\n",
    "            columns={\n",
    "                \"video_start.started\": \"stim_start\",\n",
    "                \"video_start.ended\": \"stim_end\",\n",
    "                \"catchme_participant_response.text\": \"response\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        video_cmiyc_df_list.append(temp_video_cmiyc_df)\n",
    "\n",
    "        # Video Narrative Sherlock ----\n",
    "        exp = par.video_narrative_sherlock\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "        trial_col = pd.Series([1])\n",
    "        block_col = pd.Series([\"video_narrative_sherlock\"])\n",
    "\n",
    "        temp_video_sherlock_df = exp.df_adj_ts\n",
    "        temp_video_sherlock_df.insert(0, \"block\", block_col)\n",
    "        temp_video_sherlock_df.insert(0, \"stim\", [\"video_narrative\"])\n",
    "        temp_video_sherlock_df.insert(0, \"trial\", trial_col)\n",
    "        temp_video_sherlock_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_video_sherlock_df = data_fun.insert_df_after_col(\n",
    "            temp_video_sherlock_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_video_sherlock_df.rename(\n",
    "            columns={\n",
    "                \"video_start.started\": \"stim_start\",\n",
    "                \"video_start.ended\": \"stim_end\",\n",
    "                \"sherlock_participant_response.text\": \"response\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        video_sherlock_df_list.append(temp_video_sherlock_df)\n",
    "\n",
    "        # vSAT -----\n",
    "        exp = par.vSAT\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(\n",
    "            par_num, num_rows=num_rows, dtype=pd.StringDtype()\n",
    "        )\n",
    "\n",
    "        vsat_by_block = exp.df_by_block_adj_ts\n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        trial_list = []\n",
    "\n",
    "        for i, (block, block_df) in enumerate(\n",
    "            zip(exp.task_order_simp, vsat_by_block.values())\n",
    "        ):\n",
    "            block_df_list.append(block_df)\n",
    "            block_list.append([block] * exp.num_trials)\n",
    "            trial_list.append([(i + 1)] * block_df.shape[0])  # num rows in the block\n",
    "        trial_col = pd.Series(data_fun.flatten(trial_list))\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_vsat_df = pd.DataFrame()\n",
    "        temp_vsat_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_vsat_df.reset_index(inplace=True, drop=True)\n",
    "        temp_vsat_df.insert(0, \"block\", block_col)\n",
    "        temp_vsat_df.insert(0, \"trial\", trial_col)\n",
    "        temp_vsat_df.insert(0, \"participant\", par_num_col)\n",
    "        form_info_df = get_form_info_df(num_rows, form_info_cols)\n",
    "        temp_vsat_df = data_fun.insert_df_after_col(\n",
    "            temp_vsat_df, form_info_df, \"participant\"\n",
    "        )\n",
    "        temp_vsat_df.rename(\n",
    "            columns={\n",
    "                \"stim_resp.corr\": \"correct_response\",\n",
    "                \"inter_stim_text.started\": \"inter_stim_start\",\n",
    "                \"inter_stim_text.ended\": \"inter_stim_end\",\n",
    "                \"vSAT_square.started\": \"stim_start\",\n",
    "                \"vSAT_square.ended\": \"stim_end\",\n",
    "                \"stim_resp.rt\": \"response_time\",\n",
    "                \"feedback_sound.started\": \"feedback_sound_start\",\n",
    "                \"feedback_sound.ended\": \"feedback_sound_end\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        vsat_df_list.append(temp_vsat_df.copy())\n",
    "\n",
    "        # Audio Narrative ----\n",
    "        audio_df = pd.concat(audio_df_list, axis=0)\n",
    "        audio_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"processed_data/behavioral\",\n",
    "            f\"{par.audio_narrative.exp_name}_behav.csv\",\n",
    "        )\n",
    "        audio_df.to_csv(audio_filepath, index=False)\n",
    "\n",
    "        # Go/No-Go -----\n",
    "        gng_df = pd.concat(gng_df_list, axis=0)\n",
    "        gng_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"processed_data/behavioral\",\n",
    "            f\"{par.go_no_go.exp_name}_behav.csv\",\n",
    "        )\n",
    "        gng_df.to_csv(gng_filepath, index=False)\n",
    "\n",
    "        # King Devick -----\n",
    "        kd_df = pd.concat(kd_df_list, axis=0)\n",
    "        kd_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"processed_data/behavioral\",\n",
    "            f\"{par.king_devick.exp_name}_behav.csv\",\n",
    "        )\n",
    "        kd_df.to_csv(kd_filepath, index=False)\n",
    "\n",
    "        # N-Back -----\n",
    "        n_back_df = pd.concat(n_back_df_list, axis=0)\n",
    "        n_back_filepath = os.path.join(\n",
    "            os.getcwd(), \"processed_data/behavioral\", f\"{par.n_back.exp_name}_behav.csv\"\n",
    "        )\n",
    "        n_back_df.to_csv(n_back_filepath, index=False)\n",
    "\n",
    "        # Resting State -----\n",
    "        rs_df = pd.concat(rs_df_list, axis=0)\n",
    "        rs_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"processed_data/behavioral\",\n",
    "            f\"{par.resting_state.exp_name}_behav.csv\",\n",
    "        )\n",
    "        rs_df.to_csv(rs_filepath, index=False)\n",
    "\n",
    "        # Tower of London -----\n",
    "        tol_df = pd.concat(tol_df_list, axis=0)\n",
    "        tol_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"processed_data/behavioral\",\n",
    "            f\"{par.tower_of_london.exp_name}_behav.csv\",\n",
    "        )\n",
    "        tol_df.to_csv(tol_filepath, index=False)\n",
    "\n",
    "        # Video Narrative CMIYC ----\n",
    "        video_cmiyc_df = pd.concat(video_cmiyc_df_list, axis=0)\n",
    "        video_cmiyc_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"processed_data/behavioral\",\n",
    "            f\"{par.video_narrative_cmiyc.exp_name}_behav.csv\",\n",
    "        )\n",
    "        video_cmiyc_df.to_csv(video_cmiyc_filepath, index=False)\n",
    "\n",
    "        # Video Narrative Sherlock ----\n",
    "        video_sherlock_df = pd.concat(video_sherlock_df_list, axis=0)\n",
    "        video_sherlock_filepath = os.path.join(\n",
    "            os.getcwd(),\n",
    "            \"processed_data/behavioral\",\n",
    "            f\"{par.video_narrative_sherlock.exp_name}_behav.csv\",\n",
    "        )\n",
    "        video_sherlock_df.to_csv(video_sherlock_filepath, index=False)\n",
    "\n",
    "        # vSAT -----\n",
    "        vsat_df = pd.concat(vsat_df_list, axis=0)\n",
    "        vsat_filepath = os.path.join(\n",
    "            os.getcwd(), \"processed_data/behavioral\", f\"{par.vSAT.exp_name}_behav.csv\"\n",
    "        )\n",
    "        vsat_df.to_csv(vsat_filepath, index=False)\n",
    "\n",
    "\n",
    "def load_results(\n",
    "    results_dir: str, exp_name: str = None, par_num: list[int | list | tuple] = None\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Read the experiment behavioral results from CSV files into DataFrame or a dictionary of DataFrames.\n",
    "\n",
    "    Args:\n",
    "        results_dir (str): Path to the results directory\n",
    "        exp_name (str, optional): Get results for a specific experiment. Defaults to None\n",
    "        par_num (list[int | list | tuple], optional): Participants to select. Single participant, list of participants, or slice of participants.\n",
    "                                                      Defaults to None (all participants).\n",
    "\n",
    "    Returns:\n",
    "        Union[pd.DataFrame, dict]:\n",
    "            pd.DataFrame: Behavioral data for a specified experiment.\n",
    "            -or-\n",
    "            dict: Behavioral results dictionary\n",
    "                keys:\n",
    "                    'audio_narrative', 'go_no_go', 'king_devick', 'n_back', 'resting_state',\n",
    "                    'tower_of_london', 'video_narrative_cmiyc', 'video_narrative_sherlock', 'vSAT'\n",
    "                values:\n",
    "                    DataFrame of behavioral results for each experiment\n",
    "    \"\"\"\n",
    "\n",
    "    if exp_name:\n",
    "        for results_csv in os.listdir(results_dir):\n",
    "            if exp_name in results_csv:\n",
    "                full_path = os.path.join(results_dir, results_csv)\n",
    "                df = pd.read_csv(full_path)\n",
    "                if isinstance(par_num, int):\n",
    "                    return df[df[\"participant\"] == par_num]\n",
    "                elif isinstance(par_num, list):\n",
    "                    return df[df[\"participant\"].isin(par_num)]\n",
    "                elif isinstance(par_num, tuple):\n",
    "                    return df[\n",
    "                        (df[\"participant\"] >= par_num[0])\n",
    "                        & (df[\"participant\"] <= par_num[1])\n",
    "                    ]\n",
    "                else:\n",
    "                    return df\n",
    "        print(\n",
    "            \"Invalid experiment name.\"\n",
    "        )  # only reached if invalid experiment name argument\n",
    "    else:\n",
    "        exp_dict = {}\n",
    "        for results_csv in os.listdir(results_dir):\n",
    "            exp_name = results_csv.split(\"_behav\")[0]\n",
    "            full_path = os.path.join(results_dir, results_csv)\n",
    "            df = pd.read_csv(full_path)\n",
    "            if isinstance(par_num, int):\n",
    "                df = df[df[\"participant\"] == par_num]\n",
    "            elif isinstance(par_num, list):\n",
    "                df = df[df[\"participant\"].isin(par_num)]\n",
    "            elif isinstance(par_num, tuple):\n",
    "                df = df[\n",
    "                    (df[\"participant\"] >= par_num[0])\n",
    "                    & (df[\"participant\"] <= par_num[1])\n",
    "                ]\n",
    "            else:\n",
    "                pass\n",
    "            exp_dict[exp_name] = df\n",
    "        return exp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_num = \"01\"\n",
    "par = Participant_Behav(par_num, adj_ts_markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_behav_results_tables(num_pars=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c1e24752b3065052c27c07c0a22748a6118d05dd89b50e77c79e7ce74e5970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
