{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "class Data_Functions():\n",
    "    def get_exp_order(self) -> list:\n",
    "        \"\"\"Retuns the experiment order\"\"\"\n",
    "\n",
    "        exp_order_filename = f\"{self.par_ID}_experiment_order.txt\"\n",
    "        exp_order_filepath = os.path.join(self.par_dir, exp_order_filename)\n",
    "\n",
    "        with open(exp_order_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        exp_order = []\n",
    "        for line in lines:\n",
    "            if \"Block\" in line or \"-\" in line or line == \"\\n\":\n",
    "                pass\n",
    "            else:\n",
    "                exp_order.append(line.strip(\"\\n\"))\n",
    "        \n",
    "        return exp_order\n",
    "\n",
    "    def _parse_udp(self, udp) -> dict:\n",
    "        \"\"\"Returns a dict of the parsed UDP marker information\"\"\"\n",
    "\n",
    "        marker_ID_info = udp[2].strip(\",\").split(\"=\")\n",
    "        marker_ID_str = marker_ID_info[0]\n",
    "        marker_ID = marker_ID_info[1]\n",
    "\n",
    "        marker_val_info = udp[3].strip(\",\").split(\"=\")\n",
    "        marker_val_str = marker_val_info[0]\n",
    "        marker_val = marker_val_info[1]\n",
    "\n",
    "        marker_string_info = udp[4].strip(\",\").split(\"=\")\n",
    "        marker_string_str = marker_string_info[0]\n",
    "        marker_string = marker_string_info[1]\n",
    "\n",
    "        marker_ts_info = udp[5].strip(\"\\n\").split(\"=\")\n",
    "        marker_ts_str = marker_ts_info[0]\n",
    "        marker_ts = marker_ts_info[1]\n",
    "\n",
    "        marker_data = {marker_ID_str: marker_ID, marker_val_str: marker_val, marker_string_str: marker_string, marker_ts_str: marker_ts}\n",
    "        \n",
    "        return marker_data\n",
    "\n",
    "    def parse_log_file(self, par_dir, exp_name) -> list:\n",
    "        \"\"\"Returns a list of the marker data parsed from the log file\"\"\"\n",
    "\n",
    "        log_dir = os.path.join(par_dir, exp_name, \"data\")\n",
    "        for filename in os.listdir(log_dir):\n",
    "            if \".log\" in filename:\n",
    "                log_filename = filename\n",
    "        log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "        with open(log_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        udp_lines = []\n",
    "        for line in lines:\n",
    "            if \"UDP\" in line:\n",
    "                udp_lines.append(line.split(\"\\t\")[-1])\n",
    "\n",
    "        marker_data = []\n",
    "        try:\n",
    "            start_udp = udp_lines[0].split(\" \")\n",
    "            marker_data.append(self._parse_udp(start_udp))\n",
    "        except:\n",
    "            marker_data.append(\"_\")\n",
    "        try:\n",
    "            end_udp = udp_lines[1].split(\" \")\n",
    "            marker_data.append(self._parse_udp(end_udp))\n",
    "        except:\n",
    "            if exp_name == \"go_no_go\":\n",
    "                marker_ID = int(marker_data[0][\"marker_ID\"]) + 1\n",
    "                marker_val = 22\n",
    "                marker_string = \"go_no_go_end\"\n",
    "                end_ts = marker_data[0][\"timestamp\"]\n",
    "                end_ts = int(float(end_ts) + float(lines[-1].split(\"\\t\")[0])*1e9 - 0.4*1e9)\n",
    "                marker_data.append({'marker_ID': marker_ID, 'marker_value': marker_val, 'marker_string': marker_string, 'timestamp': end_ts})\n",
    "            else:\n",
    "                marker_data.append(\"_\")\n",
    "\n",
    "        return marker_data\n",
    "\n",
    "    def parse_narrative_log_file(self, par_dir, exp_name):\n",
    "        log_dir = os.path.join(par_dir, exp_name, \"data\")\n",
    "        for filename in os.listdir(log_dir):\n",
    "            if \".log\" in filename:\n",
    "                log_filename = filename\n",
    "        log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "        with open(log_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        udp_lines = []\n",
    "        for line in lines:\n",
    "            if \"UDP\" in line:\n",
    "                udp_lines.append(line.split(\"\\t\")[0])\n",
    "\n",
    "        end_time = float(udp_lines[1])*1e9\n",
    "\n",
    "        return end_time\n",
    "\n",
    "    def parse_task_order_file(self, par_dir, exp_name) -> pd.DataFrame:\n",
    "        \"\"\"Returns a data frame of the task order parsed from the task order file\"\"\"\n",
    "\n",
    "        exp_dir = os.path.join(par_dir, exp_name)\n",
    "        for filename in os.listdir(exp_dir):\n",
    "            if \".csv\" in filename:\n",
    "                task_order_filename = filename\n",
    "        task_order_filepath = os.path.join(exp_dir, task_order_filename)\n",
    "        task_order = pd.read_csv(task_order_filepath)\n",
    "\n",
    "        return task_order\n",
    "\n",
    "    def get_data_filepath(self, par_dir, exp_name) -> str:\n",
    "        \"\"\"Returns the filepath\"\"\"\n",
    "\n",
    "        data_dir = os.path.join(par_dir, exp_name, \"data\")\n",
    "        for filename in os.listdir(data_dir):\n",
    "            if \".csv\" in filename:\n",
    "                data_filename = filename\n",
    "        data_filepath = os.path.join(data_dir, data_filename)\n",
    "\n",
    "        return data_filepath\n",
    "\n",
    "    def csv_to_df(self, filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_all_marker_timestamps(self, par_dir, exp_order):\n",
    "        all_marker_timestamps = {}\n",
    "        for exp_name in exp_order:\n",
    "            start_marker, end_marker = self.parse_log_file(par_dir=par_dir, exp_name=exp_name)\n",
    "            if \"narrative\" in exp_name and \"participant_01\" not in par_dir and \"participant_02\" not in par_dir and \"participant_03\" not in par_dir:\n",
    "                try:\n",
    "                    start_ts = start_marker[\"timestamp\"]\n",
    "                except:\n",
    "                    start_ts = \"_\"\n",
    "                    print(\"ERROR: start marker not found\", exp_name)\n",
    "                try:\n",
    "                    end_ts = float(start_ts) + self.parse_narrative_log_file(par_dir, exp_name)\n",
    "                except:\n",
    "                    print(\"ERROR: end marker not found\", exp_name)\n",
    "            else:\n",
    "                try:\n",
    "                    start_ts = start_marker[\"timestamp\"]\n",
    "                except:\n",
    "                    start_ts = \"_\"\n",
    "                    print(\"ERROR: start marker not found\", exp_name)\n",
    "                try:\n",
    "                    end_ts = end_marker[\"timestamp\"]\n",
    "                except:\n",
    "                    end_ts = \"_\"\n",
    "                    print(\"ERROR: end marker not found\", exp_name)\n",
    "            all_marker_timestamps[exp_name] = [start_ts, end_ts]\n",
    "\n",
    "        return all_marker_timestamps\n",
    "\n",
    "    def get_cols(self, df, cols):\n",
    "        return df[cols]\n",
    "\n",
    "    def create_col(self, x, num_rows):  # TODO, specify dtype in function call\n",
    "        return pd.Series([x]*num_rows)\n",
    "\n",
    "    def flatten(self, input_list):\n",
    "        return [x for xs in input_list for x in xs]\n",
    "\n",
    "    def parse_df(self, df, num_blocks, num_trials):\n",
    "        df_by_block = {}\n",
    "        for i in range(num_blocks):\n",
    "            block_name = f\"block_{i+1}\"\n",
    "            if i == 0:\n",
    "                temp_df = df.iloc[i*num_trials:(i+1)*num_trials]\n",
    "                df_no_nan = temp_df.copy()\n",
    "            else:\n",
    "                temp_df = df.iloc[(i*num_trials)+i:((i+1)*num_trials)+i]  # skip Nan line between blocks\n",
    "                df_no_nan = pd.concat([df_no_nan, temp_df])\n",
    "            df_by_block[block_name] = temp_df\n",
    "\n",
    "        return df_by_block, df_no_nan\n",
    "\n",
    "    def get_exp_ts(self, df, exp_name):\n",
    "        df_temp = df[df[\"exp_name\"] == exp_name]\n",
    "        start_ts = df_temp[\"start_timestamp\"].item()\n",
    "        end_ts = df_temp[\"end_timestamp\"].item()\n",
    "\n",
    "        return start_ts, end_ts\n",
    "\n",
    "    def get_exp_dt(self, df, exp_name):\n",
    "        df_temp = df[df[\"exp_name\"] == exp_name]\n",
    "        start_dt = datetime.datetime.fromtimestamp(df_temp[\"start_timestamp\"].item()/1e9)\n",
    "        end_dt = datetime.datetime.fromtimestamp(df_temp[\"end_timestamp\"].item()/1e9)\n",
    "\n",
    "        return start_dt, end_dt\n",
    "\n",
    "    def get_start_index_dt(self, df, start_dt):\n",
    "        try:\n",
    "            for loc, dt in enumerate(df[\"datetime\"]):\n",
    "                if not dt < start_dt:\n",
    "                    break\n",
    "            if loc < df[\"datetime\"].shape[0]-1:\n",
    "                return loc\n",
    "            else:\n",
    "                print(\"ERROR: start index datetime not found!\")\n",
    "                return None\n",
    "        except:\n",
    "            print(\"ERROR: start index datetime not found!\")\n",
    "            return None\n",
    "\n",
    "    def get_end_index_dt(self, df, end_dt):\n",
    "        try:\n",
    "            for loc, dt in enumerate(df[\"datetime\"]):  \n",
    "                if dt > end_dt:\n",
    "                    break\n",
    "            return loc\n",
    "        except:\n",
    "            print(\"ERROR: end index datetime not found!\")\n",
    "            return None\n",
    "\n",
    "    def get_start_index_ts(self, df, start_ts):\n",
    "        try:\n",
    "            for loc, ts in enumerate(df[\"timestamps\"]):\n",
    "                if not ts < start_ts:\n",
    "                    break\n",
    "            if loc < df[\"timestamps\"].shape[0]-1:\n",
    "                return loc\n",
    "            else:\n",
    "                print(\"ERROR: start index timestamp not found!\")\n",
    "                return None\n",
    "        except:\n",
    "            print(\"ERROR: start index timestamp not found!\")\n",
    "            return None\n",
    "\n",
    "    def get_end_index_ts(self, df, end_ts):\n",
    "        try:    \n",
    "            for loc, ts in enumerate(df[\"timestamps\"]):  \n",
    "                if ts > end_ts:\n",
    "                    break\n",
    "            return loc\n",
    "        except:\n",
    "            print(\"ERROR: end index timestamp not found!\")\n",
    "            return None\n",
    "\n",
    "    def c_to_f(self, temp):\n",
    "        \"\"\"Convert celsius to fahrenheit\"\"\"\n",
    "        \n",
    "        return round(temp * 9/5 + 32, 2)\n",
    "\n",
    "class Audio_Narrative(Data_Functions):\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"audio_narrative\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "\n",
    "        cols = [\"pieman_clip.started\", \"participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\"ERROR: Pieman - Need to combine 'participant response' columns into a single column.\")\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"pieman_clip.started\"][0]\n",
    "\n",
    "class Go_No_Go(Data_Functions):\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"go_no_go\"\n",
    "        self.num_blocks = 4\n",
    "        self.num_trials = 20\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        cols = [\"match\", \"inter_stim_plus.started\", \"go_image.started\", \"go_resp.corr\", \"go_resp.rt\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials) \n",
    "    \n",
    "        self._correct_responses(df_by_block = self.df_by_block)\n",
    "        self._response_times(df_by_block = self.df_by_block)\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_go_list = []\n",
    "        self.num_corr_gng_list = []\n",
    "\n",
    "        for i, block in enumerate(df_by_block.values()):\n",
    "            if (i+1) % 2 != 0:  # Go blocks\n",
    "                num_corr_go = int(sum(block[\"go_resp.corr\"]))\n",
    "                self.num_corr_go_list.append(num_corr_go)\n",
    "            else:  # Go/No-Go blocks\n",
    "                num_corr_gng = int(sum(block[\"go_resp.corr\"]))\n",
    "                self.num_corr_gng_list.append(num_corr_gng)\n",
    "\n",
    "        self.total_corr_go = sum(self.num_corr_go_list)\n",
    "        self.total_corr_gng = sum(self.num_corr_gng_list)\n",
    "        self.total_corr = self.total_corr_go + self.total_corr_gng\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_go_list = []\n",
    "        self.resp_time_gng_list = []\n",
    "\n",
    "        for i, block in enumerate(df_by_block.values()):\n",
    "            if (i+1) % 2 != 0:  # Go blocks\n",
    "                try:  # handle Nan \n",
    "                    resp_time_go = np.nanmean(block[\"go_resp.rt\"])\n",
    "                    self.resp_time_go_list.append(resp_time_go)\n",
    "                except:\n",
    "                    pass\n",
    "            else:  # Go/No-Go blocks\n",
    "                try:  # handle Nan\n",
    "                    resp_time_gng = np.nanmean(block[\"go_resp.rt\"])\n",
    "                    self.resp_time_gng_list.append(resp_time_gng)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        self.avg_resp_time_go = mean(self.resp_time_go_list)\n",
    "        self.avg_resp_time_gng = mean(self.resp_time_gng_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_go, self.avg_resp_time_gng]\n",
    "\n",
    "class King_Devick(Data_Functions):  \n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"king_devick\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 3\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        \n",
    "        self.task_order = [\"card_1\", \"card_2\", \"card_3\"]\n",
    "        \n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        num_incorrect_col = pd.Series(self._parse_data_file(par_dir=par_dir))\n",
    "        self.df.insert(len(self.df.columns), \"num_incorrect\", num_incorrect_col)\n",
    "        cols = [\"card_image.started\", \"card_resp.rt\", \"num_incorrect\"]\n",
    "        self.df_simp = self.get_cols(self.df, cols)\n",
    "\n",
    "    def _parse_data_file(self, par_dir):\n",
    "        data_dir = os.path.join(par_dir, self.exp_name, \"data\")\n",
    "        for filename in os.listdir(data_dir):\n",
    "            if \"data.txt\" in filename:\n",
    "                data_filename = filename\n",
    "        data_filepath = os.path.join(data_dir, data_filename)\n",
    "\n",
    "        with open(data_filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        par_resp = []\n",
    "        for line in lines:\n",
    "            if \"number incorrect\" in line:\n",
    "                par_resp.append(line.split(\" \")[-1].strip(\"\\n\"))\n",
    "\n",
    "        return par_resp\n",
    "\n",
    "class N_Back(Data_Functions):\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"n_back\"\n",
    "        self.num_blocks = 9\n",
    "        self.num_trials = 20\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        \n",
    "        self.task_order = self.parse_task_order_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.task_order_simp, self.task_order_simp2 = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        cols = [\"match\", \"stim_text.started\", \"stim_resp.corr\", \"stim_resp.rt\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials)\n",
    "\n",
    "        self._correct_responses(df_by_block = self.df_by_block)\n",
    "        self._response_times(df_by_block = self.df_by_block)\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_ZB_list = []\n",
    "        self.num_corr_OB_list = []\n",
    "        self.num_corr_TB_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type[0:2] == \"ZB\":\n",
    "                num_corr_ZB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_ZB_list.append(num_corr_ZB)\n",
    "            elif task_type[0:2] == \"OB\":\n",
    "                num_corr_OB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_OB_list.append(num_corr_OB)\n",
    "            elif task_type[0:2] == \"TB\":\n",
    "                num_corr_TB = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_TB_list.append(num_corr_TB)\n",
    "\n",
    "        self.total_corr_ZB = sum(self.num_corr_ZB_list)\n",
    "        self.total_corr_OB = sum(self.num_corr_OB_list)\n",
    "        self.total_corr_TB = sum(self.num_corr_TB_list)\n",
    "        self.total_corr = self.total_corr_ZB + self.total_corr_OB + self.total_corr_TB\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_ZB_list = []\n",
    "        self.resp_time_OB_list = []\n",
    "        self.resp_time_TB_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type[0:2] == \"ZB\":\n",
    "                resp_time_ZB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_ZB_list.append(resp_time_ZB)\n",
    "            elif task_type[0:2] == \"OB\":\n",
    "                resp_time_OB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_OB_list.append(resp_time_OB)\n",
    "            elif task_type[0:2] == \"TB\":\n",
    "                resp_time_TB = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_TB_list.append(resp_time_TB)\n",
    "\n",
    "        self.avg_resp_time_ZB = mean(self.resp_time_ZB_list)\n",
    "        self.avg_resp_time_OB = mean(self.resp_time_OB_list)\n",
    "        self.avg_resp_time_TB = mean(self.resp_time_TB_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_ZB, self.avg_resp_time_OB, self.avg_resp_time_TB]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = []\n",
    "        task_order_simp2 = []\n",
    "        for task in task_order:\n",
    "            if \"ZB\" in task:\n",
    "                temp = task.split(\"-\")\n",
    "                task_simp = f\"{temp[0]}-{temp[1]}\"\n",
    "                task_simp2 = temp[0]\n",
    "            else:\n",
    "                task_simp = task.split(\"-\")[0]\n",
    "                task_simp2 = task_simp\n",
    "            task_order_simp.append(task_simp)\n",
    "            task_order_simp2.append(task_simp2)\n",
    "        \n",
    "        return task_order_simp, task_order_simp2\n",
    "\n",
    "class Resting_State(Data_Functions):\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"resting_state\"\n",
    "        self.num_blocks = 2\n",
    "        self.num_trials = 1\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "        \n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        cols = [\"trial_cross.started\", \"halfway_tone.started\", \"done_sound.started\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.replace(' ', '_') for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "class Tower_of_London(Data_Functions):\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"tower_of_london\"\n",
    "        self.num_blocks = 6\n",
    "        self.num_trials = 6\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        \n",
    "        self.task_order = self.parse_task_order_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    "\n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        cols = [\"match\", \"stim_image.started\", \"stim_text.started\", \"stim_resp.corr\", \"stim_resp.rt\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials) \n",
    "    \n",
    "        self._correct_responses(df_by_block = self.df_by_block)\n",
    "        self._response_times(df_by_block = self.df_by_block)\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_MM_list = []\n",
    "        self.num_corr_ZM_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"MM\":\n",
    "                num_corr_MM = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_MM_list.append(num_corr_MM)\n",
    "            elif task_type == \"ZM\":\n",
    "                num_corr_ZM = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_ZM_list.append(num_corr_ZM)\n",
    "\n",
    "        self.total_corr_MM = sum(self.num_corr_MM_list)\n",
    "        self.total_corr_ZM = sum(self.num_corr_ZM_list)\n",
    "        self.total_corr = self.total_corr_MM + self.total_corr_ZM\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_MM_list = []\n",
    "        self.resp_time_ZM_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"MM\":\n",
    "                resp_time_MM = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_MM_list.append(resp_time_MM)\n",
    "            elif task_type == \"ZM\":\n",
    "                resp_time_ZM = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_ZM_list.append(resp_time_ZM)\n",
    "\n",
    "        self.avg_resp_time_MM = mean(self.resp_time_MM_list)\n",
    "        self.avg_resp_time_ZM = mean(self.resp_time_ZM_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_MM, self.avg_resp_time_ZM]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "class Video_Narrative_CMIYC(Data_Functions): \n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"video_narrative_cmiyc\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "\n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        cols = [\"video_start.started\", \"catchme_participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"catchme_participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\"ERROR: Catchme - Need to combine 'participant response' columns into a single column.\")\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"video_start.started\"][0]\n",
    "\n",
    "class Video_Narrative_Sherlock(Data_Functions):\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"video_narrative_sherlock\"\n",
    "        self.num_blocks = 1\n",
    "        self.num_trials = 1\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        cols = [\"video_start.started\", \"sherlock_participant_response.text\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "\n",
    "        self.response = self.get_response()\n",
    "        self.block_start_time = self.get_clip_start_time()\n",
    "\n",
    "    def get_response(self):\n",
    "        try:\n",
    "            return self.df_simp[\"sherlock_participant_response.text\"][0]\n",
    "        except:\n",
    "            print(\"ERROR: Sherlock - Need to combine 'participant response' columns into a single column.\")\n",
    "\n",
    "    def get_clip_start_time(self):\n",
    "        return self.df_simp[\"video_start.started\"][0]\n",
    "\n",
    "class vSAT(Data_Functions):\n",
    "    def __init__(self, par_dir):\n",
    "        super().__init__()\n",
    "        self.exp_name = \"vSAT\"\n",
    "        self.num_blocks = 4\n",
    "        self.num_trials = 30\n",
    "        self.data_filepath = self.get_data_filepath(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.marker_data = self.parse_log_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "\n",
    "        self.task_order = self.parse_task_order_file(par_dir=par_dir, exp_name=self.exp_name)\n",
    "        self.task_order_simp = self._simp_task_order(task_order=self.task_order)\n",
    " \n",
    "        self.df = self.csv_to_df(filepath=self.data_filepath)\n",
    "        cols = [\"match\", \"stim_time\", \"x_pos\", \"y_pos\", \"inter_stim_text.started\", \"vSAT_square.started\", \"stim_resp.corr\", \"stim_resp.rt\", \"feedback_sound.started\"]\n",
    "        self.df_simp = self.get_cols(df=self.df, cols=cols)\n",
    "        self._add_pos_col()\n",
    "        self.df_by_block, self.df_no_nan = self.parse_df(df=self.df_simp, num_blocks=self.num_blocks, num_trials=self.num_trials) \n",
    "\n",
    "        self._correct_responses(df_by_block=self.df_by_block)\n",
    "        self._response_times(df_by_block=self.df_by_block)\n",
    "\n",
    "    def _correct_responses(self, df_by_block):\n",
    "        self.num_corr_SAT_list = []\n",
    "        self.num_corr_vSAT_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"SAT\":\n",
    "                num_corr_SAT = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_SAT_list.append(num_corr_SAT)\n",
    "            elif task_type == \"vSAT\":\n",
    "                num_corr_vSAT = int(sum(block[\"stim_resp.corr\"]))\n",
    "                self.num_corr_vSAT_list.append(num_corr_vSAT)\n",
    "\n",
    "        self.total_corr_SAT = sum(self.num_corr_SAT_list)\n",
    "        self.total_corr_vSAT = sum(self.num_corr_vSAT_list)\n",
    "        self.total_corr = self.total_corr_SAT + self.total_corr_vSAT\n",
    "\n",
    "    def _response_times(self, df_by_block):\n",
    "        self.resp_time_SAT_list = []\n",
    "        self.resp_time_vSAT_list = []\n",
    "\n",
    "        for task_type, block in zip(self.task_order_simp, df_by_block.values()):\n",
    "            if task_type == \"SAT\":\n",
    "                resp_time_SAT = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_SAT_list.append(resp_time_SAT)\n",
    "            elif task_type == \"vSAT\":\n",
    "                resp_time_vSAT = np.nanmean(block[\"stim_resp.rt\"])\n",
    "                self.resp_time_vSAT_list.append(resp_time_vSAT)\n",
    "\n",
    "        self.avg_resp_time_SAT = mean(self.resp_time_SAT_list)\n",
    "        self.avg_resp_time_vSAT = mean(self.resp_time_vSAT_list)\n",
    "        self.avg_resp_time = [self.avg_resp_time_SAT, self.avg_resp_time_vSAT]\n",
    "\n",
    "    def _simp_task_order(self, task_order):\n",
    "        task_order = task_order[\"task_order\"].to_list()\n",
    "        task_order_simp = [task.split(\"_\")[0] for task in task_order]\n",
    "\n",
    "        return task_order_simp\n",
    "\n",
    "    def _add_pos_col(self):\n",
    "        x_pos_col = self.df_simp[\"x_pos\"]\n",
    "        y_pos_col = self.df_simp[\"y_pos\"]\n",
    "\n",
    "        pos_list = []\n",
    "        for x_pos, y_pos in zip(x_pos_col, y_pos_col):\n",
    "            if x_pos == 0 and y_pos == 0:\n",
    "                pos = \"center\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == 0.25 and y_pos == 0.25:\n",
    "                pos = \"top-right\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == 0.25 and y_pos == -0.25:\n",
    "                pos = \"bottom-right\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == -0.25 and y_pos == 0.25:\n",
    "                pos = \"top-left\"\n",
    "                pos_list.append(pos)\n",
    "            elif x_pos == -0.25 and y_pos == -0.25:\n",
    "                pos = \"bottom-left\"\n",
    "                pos_list.append(pos)\n",
    "            else:\n",
    "                pos = \"Nan\"\n",
    "                pos_list.append(pos)\n",
    "\n",
    "        self.df_simp.insert(loc=4, column=\"position\", value=pos_list)\n",
    "        self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
    "\n",
    "class Participant_Behav(Data_Functions):\n",
    "    def __init__(self, par_num):\n",
    "        super().__init__()\n",
    "        self.par_num = par_num\n",
    "        self.par_ID = f\"participant_{self.par_num}\"\n",
    "        self.par_dir = os.path.join(os.getcwd(), \"participants\", self.par_ID)\n",
    "        \n",
    "        self.exp_order = self.get_exp_order()\n",
    "        self.all_marker_timestamps = self.get_all_marker_timestamps(par_dir=self.par_dir, exp_order=self.exp_order)\n",
    "        self._create_marker_ts_csv()\n",
    "        self.marker_ts_df = self._create_marker_ts_df()\n",
    "\n",
    "        self.audio_narrative = Audio_Narrative(par_dir=self.par_dir)\n",
    "        self.go_no_go = Go_No_Go(par_dir=self.par_dir)\n",
    "        self.king_devick = King_Devick(par_dir=self.par_dir)\n",
    "        self.n_back = N_Back(par_dir=self.par_dir)\n",
    "        self.resting_state = Resting_State(par_dir=self.par_dir)\n",
    "        self.tower_of_london = Tower_of_London(par_dir=self.par_dir)\n",
    "        self.video_narrative_cmiyc = Video_Narrative_CMIYC(par_dir=self.par_dir)\n",
    "        self.video_narrative_sherlock = Video_Narrative_Sherlock(par_dir=self.par_dir)\n",
    "        self.vSAT = vSAT(par_dir=self.par_dir)\n",
    "\n",
    "        self.by_block_ts_df = self._create_by_block_ts_df()\n",
    "\n",
    "    def _create_marker_ts_csv(self):\n",
    "        filepath = os.path.join(self.par_dir, f\"{self.par_ID}_marker_timestamps.csv\", )\n",
    "        if os.path.exists(filepath):\n",
    "            pass\n",
    "        else:\n",
    "            marker_list = []\n",
    "            for exp_name, ts_list in self.all_marker_timestamps.items():\n",
    "                temp_list = []\n",
    "                temp_list.append(exp_name)\n",
    "                temp_list.extend(ts_list)\n",
    "                marker_list.append(temp_list)\n",
    "\n",
    "            marker_ts_df = pd.DataFrame(marker_list, columns=[\"exp_name\", \"start_timestamp\", \"end_timestamp\"])\n",
    "            \n",
    "            marker_ts_df.to_csv(filepath, index=False)\n",
    "\n",
    "    def _create_marker_ts_df(self):\n",
    "        marker_ts_filepath = os.path.join(self.par_dir, f\"{self.par_ID}_marker_timestamps.csv\")\n",
    "        \n",
    "        return self.csv_to_df(marker_ts_filepath)\n",
    "\n",
    "    def _create_by_block_ts_df(self):\n",
    "        def format_ts(exp_name):\n",
    "            start_ts, end_ts = self.get_exp_ts(self.marker_ts_df, exp_name=exp_name)\n",
    "            return start_ts/1e9, end_ts/1e9\n",
    "\n",
    "        by_block_ts_df = {}\n",
    "        for exp_name in self.exp_order:\n",
    "            block_ts_df = {}\n",
    "\n",
    "            if exp_name == \"audio_narrative\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.audio_narrative.df_simp[\"pieman_clip.started\"].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                clip_length = 423  # 423 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = exp_name\n",
    "            elif exp_name == \"go_no_go\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for block, block_df in zip(self.go_no_go.task_order_simp, self.go_no_go.df_by_block.values()):\n",
    "                    block_start_time = block_df[\"inter_stim_plus.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = block_df[\"go_image.started\"].iloc[-1] + 0.5  # image shown for 0.5 seconds\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = block\n",
    "            elif exp_name == \"king_devick\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for block, block_start_time, rt in zip(self.king_devick.task_order, self.king_devick.df_simp[\"card_image.started\"].values, self.king_devick.df_simp[\"card_resp.rt\"].values):\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_ts = block_start_ts + rt\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = block\n",
    "            elif exp_name == \"n_back\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for block, block_df in zip(self.n_back.task_order_simp2, self.n_back.df_by_block.values()):\n",
    "                    block_start_time = block_df[\"stim_text.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = block_df[\"stim_text.started\"].iloc[-1] + 0.5  # number shown for 0.5 seconds\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = block\n",
    "            elif exp_name == \"resting_state\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.resting_state.df_simp[\"trial_cross.started\"].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                block_end_ts = block_start_ts + (self.resting_state.df_simp[\"halfway_tone.started\"].item() - block_start_time)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = self.resting_state.task_order_simp[0]\n",
    "                block_start_time = self.resting_state.df_simp[\"halfway_tone.started\"].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                block_end_ts = block_start_ts + (self.resting_state.df_simp[\"done_sound.started\"].item() - block_start_time)\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = self.resting_state.task_order_simp[1]\n",
    "            elif exp_name == \"tower_of_london\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for block, block_df in zip(self.tower_of_london.task_order_simp, self.tower_of_london.df_by_block.values()):\n",
    "                    block_start_time = block_df[\"stim_image.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = block_df[\"stim_text.started\"].iloc[-1] + 3  # 3 seconds to respond\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = block\n",
    "            elif exp_name == \"video_narrative_cmiyc\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.video_narrative_cmiyc.df_simp[\"video_start.started\"].item()\n",
    "                block_start_ts = start_ts + block_start_time  # NOTE\n",
    "                clip_length = 300  # 300 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = exp_name\n",
    "            elif exp_name == \"video_narrative_sherlock\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                block_start_time = self.video_narrative_sherlock.df_simp[\"video_start.started\"].item()\n",
    "                block_start_ts = start_ts + block_start_time\n",
    "                clip_length = 300  # 300 second clip\n",
    "                block_end_ts = block_start_ts + clip_length\n",
    "                block_ts_df[(block_start_ts, block_end_ts)] = exp_name\n",
    "            elif exp_name == \"vSAT\":\n",
    "                start_ts, _ = format_ts(exp_name)\n",
    "                for block, block_df in zip(self.vSAT.task_order_simp, self.vSAT.df_by_block.values()):\n",
    "                    block_start_time = block_df[\"inter_stim_text.started\"].iloc[0]\n",
    "                    block_start_ts = start_ts + block_start_time\n",
    "                    block_end_time = block_df[\"feedback_sound.started\"].iloc[-1] + 0.5  # 0.5 second delay\n",
    "                    block_end_ts = start_ts + block_end_time\n",
    "                    block_ts_df[(block_start_ts, block_end_ts)] = block\n",
    "            by_block_ts_df[exp_name] = block_ts_df\n",
    "\n",
    "        return by_block_ts_df\n",
    "\n",
    "    def get_exp(self, exp_name):\n",
    "            if exp_name == \"audio_narrative\":\n",
    "                return self.audio_narrative\n",
    "            elif exp_name == \"go_no_go\":\n",
    "                return self.go_no_go\n",
    "            elif exp_name == \"king_devick\":\n",
    "                return self.king_devick\n",
    "            elif exp_name == \"n_back\":\n",
    "                return self.n_back\n",
    "            elif exp_name == \"resting_state\":\n",
    "                return self.resting_state\n",
    "            elif exp_name == \"tower_of_london\":\n",
    "                return self.tower_of_london\n",
    "            elif exp_name == \"video_narrative_cmiyc\":\n",
    "                return self.video_narrative_cmiyc\n",
    "            elif exp_name == \"video_narrative_sherlock\":\n",
    "                return self.video_narrative_sherlock\n",
    "            elif exp_name == \"vSAT\":\n",
    "                return self.vSAT\n",
    "\n",
    "def create_behav_results_tables(num_pars):\n",
    "    def get_num_rows(exp):\n",
    "        return int(exp.num_blocks * exp.num_trials)\n",
    "\n",
    "    data_fun = Data_Functions()\n",
    "    audio_df_list = []\n",
    "    gng_df_list = []\n",
    "    kd_df_list = []\n",
    "    n_back_df_list = []\n",
    "    tol_df_list = []\n",
    "    video_cmiyc_df_list = []\n",
    "    video_sherlock_df_list = []\n",
    "    vsat_df_list = []\n",
    "\n",
    "    for i in range(num_pars):\n",
    "        par_num = f\"{(i+1):02d}\"\n",
    "        par = Participant_Behav(par_num=par_num)\n",
    "\n",
    "        # Audio Narative ----\n",
    "        exp = par.audio_narrative\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "\n",
    "        temp_audio_df = pd.DataFrame([exp.response], columns=[\"response\"])\n",
    "        temp_audio_df.insert(0, \"participant\", par_num_col)\n",
    "        audio_df_list.append(temp_audio_df)\n",
    "\n",
    "        # Go/No-Go -----\n",
    "        exp = par.go_no_go\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "\n",
    "        gng_by_block = exp.df_by_block\n",
    "        temp_block_df = pd.DataFrame() \n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        \n",
    "        for block, block_df in zip(exp.task_order_simp, gng_by_block.values()):\n",
    "            temp_block_df = block_df[[\"go_resp.corr\", \"go_resp.rt\"]]\n",
    "            block_df_list.append(temp_block_df)\n",
    "            block_list.append([block]*exp.num_trials)\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_gng_df = pd.DataFrame()\n",
    "        temp_gng_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_gng_df.reset_index(inplace=True, drop=True)\n",
    "        temp_gng_df.insert(0, \"block\", block_col)\n",
    "        temp_gng_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_gng_df.rename(columns={\"go_resp.corr\": \"correct_response\", \"go_resp.rt\": \"response_time\"}, inplace=True)\n",
    "        gng_df_list.append(temp_gng_df.copy())\n",
    "\n",
    "        # King Devick -----\n",
    "        exp = par.king_devick\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "        block_col = pd.Series(exp.task_order)\n",
    "\n",
    "        temp_kd_df = exp.df_simp[[\"card_resp.rt\", \"num_incorrect\"]]\n",
    "        temp_kd_df.insert(0, \"block\", block_col)\n",
    "        temp_kd_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
    "        kd_df_list.append(temp_kd_df.copy())\n",
    "\n",
    "        # N-Back -----\n",
    "        exp = par.n_back\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "\n",
    "        n_back_by_block = exp.df_by_block\n",
    "        temp_block_df = pd.DataFrame() \n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        \n",
    "        for block, block_df in zip(exp.task_order_simp2, n_back_by_block.values()):\n",
    "            temp_block_df = block_df[[\"stim_resp.corr\", \"stim_resp.rt\"]]\n",
    "            block_df_list.append(temp_block_df)\n",
    "            block_list.append([block]*exp.num_trials)\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_n_back_df = pd.DataFrame()\n",
    "        temp_n_back_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_n_back_df.reset_index(inplace=True, drop=True)\n",
    "        temp_n_back_df.insert(0, \"block\", block_col)\n",
    "        temp_n_back_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_n_back_df.rename(columns={\"stim_resp.corr\": \"correct_response\", \"stim_resp.rt\": \"response_time\"}, inplace=True)\n",
    "        n_back_df_list.append(temp_n_back_df.copy())\n",
    "\n",
    "        # Tower of London -----\n",
    "        exp = par.tower_of_london\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "\n",
    "        tol_by_block = exp.df_by_block\n",
    "        temp_block_df = pd.DataFrame() \n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        \n",
    "        for block, block_df in zip(exp.task_order_simp, tol_by_block.values()):\n",
    "            temp_block_df = block_df[[\"stim_resp.corr\", \"stim_resp.rt\"]]\n",
    "            block_df_list.append(temp_block_df)\n",
    "            block_list.append([block]*exp.num_trials)\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_tol_df = pd.DataFrame()\n",
    "        temp_tol_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_tol_df.reset_index(inplace=True, drop=True)\n",
    "        temp_tol_df.insert(0, \"block\", block_col)\n",
    "        temp_tol_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_tol_df.rename(columns={\"stim_resp.corr\": \"correct_response\", \"stim_resp.rt\": \"response_time\"}, inplace=True)\n",
    "        tol_df_list.append(temp_tol_df.copy())\n",
    "\n",
    "        # Video Narative CMIYC ----\n",
    "        exp = par.video_narrative_cmiyc\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "        \n",
    "        temp_video_cmiyc_df = pd.DataFrame([exp.response], columns=[\"response\"])\n",
    "        temp_video_cmiyc_df.insert(0, \"participant\", par_num_col)\n",
    "        video_cmiyc_df_list.append(temp_video_cmiyc_df)\n",
    "\n",
    "        # Video Narative Sherlock ----\n",
    "        exp = par.video_narrative_sherlock\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "        \n",
    "        temp_video_sherlock_df = pd.DataFrame([exp.response], columns=[\"response\"])\n",
    "        temp_video_sherlock_df.insert(0, \"participant\", par_num_col)\n",
    "        video_sherlock_df_list.append(temp_video_sherlock_df)\n",
    "\n",
    "        # vSAT -----\n",
    "        exp = par.vSAT\n",
    "        num_rows = get_num_rows(exp=exp)\n",
    "        par_num_col = data_fun.create_col(par_num, num_rows=num_rows)\n",
    "\n",
    "        vsat_by_block = exp.df_by_block\n",
    "        temp_block_df = pd.DataFrame() \n",
    "        block_df_list = []\n",
    "        block_list = []\n",
    "        \n",
    "        for block, block_df in zip(exp.task_order_simp, vsat_by_block.values()):\n",
    "            temp_block_df = block_df[[\"stim_resp.corr\", \"stim_resp.rt\"]]\n",
    "            block_df_list.append(temp_block_df)\n",
    "            block_list.append([block]*exp.num_trials)\n",
    "        block_col = pd.Series(data_fun.flatten(block_list))\n",
    "\n",
    "        temp_vsat_df = pd.DataFrame()\n",
    "        temp_vsat_df = pd.concat(block_df_list, axis=0)\n",
    "        temp_vsat_df.reset_index(inplace=True, drop=True)\n",
    "        temp_vsat_df.insert(0, \"block\", block_col)\n",
    "        temp_vsat_df.insert(0, \"participant\", par_num_col)\n",
    "        temp_vsat_df.rename(columns={\"stim_resp.corr\": \"correct_response\", \"stim_resp.rt\": \"response_time\"}, inplace=True)\n",
    "        vsat_df_list.append(temp_vsat_df.copy())\n",
    "\n",
    "        # Audio Narative ----\n",
    "        audio_df = pd.concat(audio_df_list, axis=0)\n",
    "        audio_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.audio_narrative.exp_name}_behav.csv\")\n",
    "        audio_df.to_csv(audio_filepath, index=False)\n",
    "        # Go/No-Go -----\n",
    "        gng_df = pd.concat(gng_df_list, axis=0)\n",
    "        gng_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.go_no_go.exp_name}_behav.csv\")\n",
    "        gng_df.to_csv(gng_filepath, index=False)\n",
    "        # King Devick -----\n",
    "        kd_df = pd.concat(kd_df_list, axis=0)\n",
    "        kd_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.king_devick.exp_name}_behav.csv\")\n",
    "        kd_df.to_csv(kd_filepath, index=False)\n",
    "        # N-Back -----\n",
    "        n_back_df = pd.concat(n_back_df_list, axis=0)\n",
    "        n_back_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.n_back.exp_name}_behav.csv\")\n",
    "        n_back_df.to_csv(n_back_filepath, index=False)\n",
    "        # Tower of London -----\n",
    "        tol_df = pd.concat(tol_df_list, axis=0)\n",
    "        tol_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.tower_of_london.exp_name}_behav.csv\")\n",
    "        tol_df.to_csv(tol_filepath, index=False)\n",
    "        # Video Narative CMIYC ----\n",
    "        video_cmiyc_df = pd.concat(video_cmiyc_df_list, axis=0)\n",
    "        video_cmiyc_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.video_narrative_cmiyc.exp_name}_behav.csv\")\n",
    "        video_cmiyc_df.to_csv(video_cmiyc_filepath, index=False)\n",
    "        # Video Narative Sherlock ----\n",
    "        video_sherlock_df = pd.concat(video_sherlock_df_list, axis=0)\n",
    "        video_sherlock_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.video_narrative_sherlock.exp_name}_behav.csv\")\n",
    "        video_sherlock_df.to_csv(video_sherlock_filepath, index=False)\n",
    "        # vSAT -----\n",
    "        vsat_df = pd.concat(vsat_df_list, axis=0)\n",
    "        vsat_filepath = os.path.join(os.getcwd(), \"results/behavioral\", f\"{par.vSAT.exp_name}_behav.csv\")\n",
    "        vsat_df.to_csv(vsat_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n",
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_kd_df.rename(columns={\"card_resp.rt\": \"response_time\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "num_pars = 13\n",
    "create_behav_results_tables(num_pars=num_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio narrative response:\n",
      " The story begins with Jim, a journalist for the Ram student newspaper. Jim approaches the dean of Fordham asking about equality or something. The dean calls jim a punk and tells him to leave, Out of the corner of his eye, Jim sees a student run up, and throw a creaM pie into the face of the dean before running off. Jim asks the dean to comment on the cream pie, which the dean replies, Fuck Off. Jim runs back to the news room and tells his future polizter prize winning editor, who is a big guy, about the story. Editor calls the dean a dick and prints the story on the first page. While writing, Jim\n",
      "\n",
      "Video narrative (CMIYC) response:\n",
      " The clip opens with three similar loking men all claiming to be con man, frank abignail. The narrator then explains that frank pretended to be a pilot, work at a hospital, and go into law all fredelaently before his 19th birthday. he cashed fake checks in 26 countries and all 50 states. When he is caught he is in a french prison and has a serious sickness. the cop played by tom hanks does not be the cop explains that he beeds a doctor becasue he is to be flown back to the usa in the morning. the french doctor is not available until the next day. frank runs out of the room in an escape attempt and is cheered on by other prisoners\n",
      "\n",
      "Video narrative (Sherlock) response:\n",
      "the clip begins with john watson walking with a cane in a park when he walks past an old friend of his named mike.mike says hi and reintroduces himself but john alsready knows him. the two get coffee and sit on a bench where john explains that he just got home from milotary service and was shot. he also tells mike he cant afford to live in london. mike says thats the second time hes heard someone say that to him today. cut to a body bag being opened and sherlock is introduced. he asks how fresh the body is,. the female assistant says very fresh and that the dead man was her coworker abd he was nnice. sherlock then asks for a riding crop and procedes to smack the shit out of the body much to the assitants confusion. she \n",
      "\n",
      "Go/No-Go:\n",
      "'Go blocks' correct responses: 40/40\n",
      "'Go blocks' avg response time: 0.412 seconds\n",
      "'Go/No-Go blocks' correct responses: 39/40\n",
      "'Go/No-Go blocks' avg response time: 0.489 seconds\n",
      "\n",
      "N-Back:\n",
      "'Zero-back blocks' correct responses: 51/60\n",
      "'Zero-back blocks' avg response time: 0.479 seconds\n",
      "'One-back blocks' correct responses: 48/60\n",
      "'One-back blocks' avg response time: 0.709 seconds\n",
      "'Two-back blocks' correct responses: 51/60\n",
      "'Two-back blocks' avg response time: 0.509 seconds\n",
      "\n",
      "Tower of London:\n",
      "'Multi-move blocks' correct responses: 18/18\n",
      "'Multi-move blocks' avg response time: 0.844 seconds\n",
      "'Zero-move blocks' correct responses: 18/18\n",
      "'Zero-move blocks' avg response time: 0.609 seconds\n",
      "\n",
      "vSAT:\n",
      "'SAT blocks' correct responses: 52/60\n",
      "'SAT blocks' avg response time: 0.492 seconds\n",
      "'vSAT blocks' correct responses: 56/60\n",
      "'vSAT blocks' avg response time: 0.484 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackg\\AppData\\Local\\Temp\\ipykernel_6316\\1935797185.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "par_num = \"08\"\n",
    "par = Participant_Behav(par_num=par_num)\n",
    "\n",
    "print(\"Audio narrative response:\")\n",
    "print(par.audio_narrative.response)\n",
    "print(\"\\nVideo narrative (CMIYC) response:\")\n",
    "print(par.video_narrative_cmiyc.response)\n",
    "print(\"\\nVideo narrative (Sherlock) response:\")\n",
    "print(par.video_narrative_sherlock.response)\n",
    "\n",
    "print(\"\\nGo/No-Go:\")\n",
    "print(\"'Go blocks' correct responses:\", f\"{par.go_no_go.total_corr_go}/{par.go_no_go.num_trials*2}\")\n",
    "print(\"'Go blocks' avg response time:\", f\"{round(par.go_no_go.avg_resp_time_go, 3)} seconds\")\n",
    "print(\"'Go/No-Go blocks' correct responses:\", f\"{par.go_no_go.total_corr_gng}/{par.go_no_go.num_trials*2}\")\n",
    "print(\"'Go/No-Go blocks' avg response time:\", f\"{round(par.go_no_go.avg_resp_time_gng, 3)} seconds\")\n",
    "\n",
    "print(\"\\nN-Back:\")\n",
    "print(\"'Zero-back blocks' correct responses:\", f\"{par.n_back.total_corr_ZB}/{par.n_back.num_trials*3}\")\n",
    "print(\"'Zero-back blocks' avg response time:\", f\"{round(par.n_back.avg_resp_time_ZB, 3)} seconds\")\n",
    "print(\"'One-back blocks' correct responses:\", f\"{par.n_back.total_corr_OB}/{par.n_back.num_trials*3}\")\n",
    "print(\"'One-back blocks' avg response time:\", f\"{round(par.n_back.avg_resp_time_OB, 3)} seconds\")\n",
    "print(\"'Two-back blocks' correct responses:\", f\"{par.n_back.total_corr_TB}/{par.n_back.num_trials*3}\")\n",
    "print(\"'Two-back blocks' avg response time:\", f\"{round(par.n_back.avg_resp_time_TB, 3)} seconds\")\n",
    "\n",
    "print(\"\\nTower of London:\")\n",
    "print(\"'Multi-move blocks' correct responses:\", f\"{par.tower_of_london.total_corr_MM}/{par.tower_of_london.num_trials*3}\")\n",
    "print(\"'Multi-move blocks' avg response time:\", f\"{round(par.tower_of_london.avg_resp_time_MM, 3)} seconds\")\n",
    "print(\"'Zero-move blocks' correct responses:\", f\"{par.tower_of_london.total_corr_ZM}/{par.tower_of_london.num_trials*3}\")\n",
    "print(\"'Zero-move blocks' avg response time:\", f\"{round(par.tower_of_london.avg_resp_time_ZM, 3)} seconds\")\n",
    "\n",
    "print(\"\\nvSAT:\")\n",
    "print(\"'SAT blocks' correct responses:\", f\"{par.vSAT.total_corr_SAT}/{par.vSAT.num_trials*2}\")\n",
    "print(\"'SAT blocks' avg response time:\", f\"{round(par.vSAT.avg_resp_time_SAT, 3)} seconds\")\n",
    "print(\"'vSAT blocks' correct responses:\", f\"{par.vSAT.total_corr_vSAT}/{par.vSAT.num_trials*2}\")\n",
    "print(\"'vSAT blocks' avg response time:\", f\"{round(par.vSAT.avg_resp_time_vSAT, 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c1e24752b3065052c27c07c0a22748a6118d05dd89b50e77c79e7ce74e5970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
