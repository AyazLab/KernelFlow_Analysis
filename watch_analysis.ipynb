{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from behav_analysis import Data_Functions, Participant_Behav\n",
    "    \n",
    "class Participant_Watch():\n",
    "    def __init__(self, par_num):\n",
    "        self.data_fun = Data_Functions()\n",
    "        self.par_num = par_num\n",
    "        self.par_ID = f\"participant_{self.par_num}\"\n",
    "        self.par_dir = os.path.join(os.getcwd(), \"participants\", self.par_ID)\n",
    "        self.par_behav = Participant_Behav(par_num=self.par_num)\n",
    "        self.exp_order = self.par_behav.exp_order\n",
    "        self._dir_list = self._get_data_dirs()\n",
    "        \n",
    "        self.modalities = [\"ACC\", \"BVP\", \"EDA\", \"HR\", \"IBI\", \"TEMP\"]\n",
    "        self.modality_df_dict = self._create_modality_df_dict()\n",
    "        self.marker_ts_df = self.par_behav.marker_ts_df\n",
    "        self.exp_modality_data_dict = self._create_exp_modality_dict()\n",
    "\n",
    "    def _get_data_dirs(self):\n",
    "        watch_dir = os.path.join(self.par_dir, \"watch_data\")\n",
    "        dir_list = []\n",
    "        for dir_name in os.listdir(watch_dir):\n",
    "            dir_list.append(os.path.join(watch_dir, dir_name))\n",
    "\n",
    "        return dir_list\n",
    "\n",
    "    def _create_modality_df(self, modality):\n",
    "        df_list = []\n",
    "        for watch_dir in self._dir_list:\n",
    "            filepath = os.path.join(watch_dir, modality + \".csv\")\n",
    "            temp_df = pd.read_csv(filepath)\n",
    "            initial_ts = int(float(temp_df.columns[0]))\n",
    "            if modality != \"IBI\":\n",
    "                samp_freq = int(temp_df.iloc[0][0])\n",
    "                ts_col = pd.Series([initial_ts + i/samp_freq for i in range(temp_df.size)])\n",
    "                dt_col = pd.Series([datetime.datetime.fromtimestamp(ts) for ts in ts_col])\n",
    "                temp_df = temp_df[1:]\n",
    "                temp_df.insert(loc=0, column=\"timestamps\", value=ts_col)\n",
    "                temp_df.insert(loc=1, column=\"datetime\", value=dt_col)\n",
    "\n",
    "                if modality == \"ACC\":\n",
    "                    temp_df.rename(columns={temp_df.columns[2]: \"accel_x\", temp_df.columns[3]: \"accel_y\", temp_df.columns[4]: \"accel_z\"}, inplace=True)\n",
    "                    temp_df[\"accel_x\"] = temp_df[\"accel_x\"]/64\n",
    "                    temp_df[\"accel_y\"] = temp_df[\"accel_y\"]/64\n",
    "                    temp_df[\"accel_z\"] = temp_df[\"accel_z\"]/64\n",
    "                elif modality == \"BVP\" or modality == \"EDA\" or modality == \"HR\":\n",
    "                    temp_df.rename(columns={temp_df.columns[2]: modality}, inplace=True)    \n",
    "                elif modality == \"TEMP\":\n",
    "                    temp_df.rename(columns={temp_df.columns[2]: \"TEMP_C\"}, inplace=True)\n",
    "                    temp_F_col = pd.Series([self.data_fun.c_to_f(temp_C) for temp_C in temp_df[\"TEMP_C\"]])\n",
    "                    temp_df = temp_df.drop(columns=\"TEMP_C\")\n",
    "                    temp_df.insert(loc=2, column=\"TEMP\", value=temp_F_col)\n",
    "            elif modality == \"IBI\":\n",
    "                ts_col = temp_df.iloc[:, 0] + initial_ts\n",
    "                dt_col = pd.Series([datetime.datetime.fromtimestamp(ts) for ts in ts_col])\n",
    "                temp_df.insert(loc=0, column=\"timestamps\", value=ts_col)\n",
    "                temp_df.insert(loc=1, column=\"datetime\", value=dt_col)\n",
    "                temp_df = temp_df.drop(columns=temp_df.columns[2])\n",
    "                temp_df.rename(columns={temp_df.columns[2]: modality}, inplace=True)    \n",
    "            df_list.append(temp_df)\n",
    "        df = pd.concat(df_list, axis=0)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_modality_df_dict(self):\n",
    "        modality_df_dict = {}\n",
    "        for modality in self.modalities:\n",
    "            modality_df_dict[modality] = self._create_modality_df(modality)\n",
    "        \n",
    "        return modality_df_dict\n",
    "\n",
    "    def _create_exp_modality_dict(self):\n",
    "        def _add_block_col(exp_name, modality, df):\n",
    "            exp = self.par_behav.get_exp(exp_name=exp_name)\n",
    "            num_blocks = exp.num_blocks\n",
    "            num_rows = df.shape[0]\n",
    "            df = df.reset_index()\n",
    "            col_list = []\n",
    "            # TODO\n",
    "            if exp_name == \"audio_narrative\" or exp_name == \"video_narrative_cmiyc\" or exp_name == \"video_narrative_sherlock\":\n",
    "                for ts_tuple, block in self.par_behav.by_block_ts_df[exp_name].items():\n",
    "                    start_ts = ts_tuple[0]\n",
    "                    end_ts =  ts_tuple[1]\n",
    "                    block_start_idx = self.data_fun.get_start_index_ts(df, start_ts)\n",
    "                    block_end_idx = self.data_fun.get_end_index_ts(df, end_ts)\n",
    "                    col_list.append(self.data_fun.create_col(None, block_start_idx))\n",
    "                    col_list.append(self.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "                    col_list.append(self.data_fun.create_col(None, num_rows-block_end_idx))\n",
    "                block_col = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "                df.insert(0, \"block\", block_col)\n",
    "            elif exp_name == \"resting_state\":\n",
    "                for i, (ts_tuple, block) in enumerate(self.par_behav.by_block_ts_df[exp_name].items()):\n",
    "                    print(ts_tuple, block)\n",
    "                    start_ts = ts_tuple[0]\n",
    "                    end_ts =  ts_tuple[1]\n",
    "                    block_start_idx = self.data_fun.get_start_index_ts(df, start_ts)\n",
    "                    block_end_idx = self.data_fun.get_end_index_ts(df, end_ts)\n",
    "                    if i == 0:\n",
    "                        col_list.append(self.data_fun.create_col(None, block_start_idx))\n",
    "                        col_list.append(self.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "                    elif i == num_blocks-1:\n",
    "                        col_list.append(self.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "                        col_list.append(self.data_fun.create_col(None, num_rows-block_end_idx))\n",
    "                block_col = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "                df.insert(0, \"block\", block_col)\n",
    "            #block_col = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "            #df.insert(0, \"block\", block_col)\n",
    "\n",
    "            return df\n",
    "\n",
    "        exp_modality_dict = {}\n",
    "        for exp_name in self.exp_order:\n",
    "            start_dt, end_dt = self.data_fun.get_exp_dt(self.marker_ts_df, exp_name=exp_name)\n",
    "            exp_modality_data_dict = {} \n",
    "            for modality, df in self.modality_df_dict.items():\n",
    "                start_idx = self.data_fun.get_start_index_dt(df=self.modality_df_dict[modality], start_dt=start_dt)\n",
    "                end_idx = self.data_fun.get_end_index_dt(df=self.modality_df_dict[modality], end_dt=end_dt)\n",
    "                modality_df_temp = self.modality_df_dict[modality].iloc[start_idx:end_idx]\n",
    "                modality_df = _add_block_col(exp_name=exp_name, modality=modality, df=modality_df_temp)\n",
    "                exp_modality_data_dict[modality] = modality_df\n",
    "            exp_modality_dict[exp_name] = exp_modality_data_dict\n",
    "\n",
    "        return exp_modality_dict\n",
    "\n",
    "    def _plot_exp_regions(self, ax):\n",
    "        for exp_name in self.exp_order:\n",
    "            start_dt, end_dt = self.data_fun.get_exp_dt(self.marker_ts_df, exp_name=exp_name)\n",
    "            ax.axvline(start_dt, linestyle=\"dashed\", color=\"k\", alpha=0.75)\n",
    "            ax.axvline(end_dt, linestyle=\"dashed\", color=\"k\", alpha=0.75)\n",
    "            if exp_name == \"audio_narrative\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"yellow\", alpha=0.4, label=\"Audio Narrative\")\n",
    "            elif exp_name == \"go_no_go\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"green\", alpha=0.4, label=\"Go//No-Go\")\n",
    "            elif exp_name == \"king_devick\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"blue\", alpha=0.4, label=\"King Devick\")\n",
    "            elif exp_name == \"n_back\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"purple\", alpha=0.4, label=\"N-back\")\n",
    "            elif exp_name == \"resting_state\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"pink\", alpha=0.4, label=\"Resting State\")\n",
    "            elif exp_name == \"tower_of_london\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"orange\", alpha=0.4, label=\"Tower of London\")\n",
    "            elif exp_name == \"video_narrative_cmiyc\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"red\", alpha=0.4, label=\"Video Narrative CMIYC\")\n",
    "            elif exp_name == \"video_narrative_sherlock\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"olive\", alpha=0.4, label=\"Video Narrative Sherlock\")\n",
    "            elif exp_name == \"vSAT\":\n",
    "                ax.axvspan(start_dt, end_dt, color=\"cyan\", alpha=0.4, label=\"vSAT\")\n",
    "\n",
    "    def plot_modality(self, modality):\n",
    "        datetime_fmt = mdates.DateFormatter('%H:%M:%S')\n",
    "        modality_df = self.modality_df_dict[modality]\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 6))\n",
    "        \n",
    "        if modality == \"ACC\":\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"accel_x\"], color=\"black\")\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"accel_y\"], color=\"darkslategray\")\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"accel_z\"], color=\"darkblue\")\n",
    "            ax.set_ylabel(\"Acceleration (g)\", fontsize=16, color=\"k\")\n",
    "            ax.set_title(\"Acceleration\", fontsize=20, color=\"k\")\n",
    "        elif modality == \"BVP\":\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"BVP\"], color=\"k\")\n",
    "            ax.set_ylabel(\"BVP\", fontsize=16, color=\"k\")\n",
    "            ax.set_title(\"Photoplethysmograph\", fontsize=20, color=\"k\")\n",
    "        elif modality == \"EDA\":\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"EDA\"], color=\"k\")\n",
    "            ax.set_ylabel(\"EDA (μS)\", fontsize=16, color=\"k\")\n",
    "            ax.set_title(\"Electrodermal\", fontsize=20, color=\"k\")\n",
    "        elif modality == \"HR\":\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"HR\"], color=\"k\")\n",
    "            ax.set_ylabel(\"Heart Rate (BPM)\", fontsize=16, color=\"k\")\n",
    "            ax.set_title(\"Heart Rate\", fontsize=20, color=\"k\")\n",
    "        elif modality == \"IBI\":\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"IBI\"], color=\"k\")\n",
    "            ax.set_ylabel(\"Interbeat Interval (seconds)\", fontsize=16, color=\"k\")\n",
    "            ax.set_title(\"Heart Rate Variability\", fontsize=20, color=\"k\")\n",
    "        elif modality == \"TEMP\":\n",
    "            ax.plot(modality_df[\"datetime\"], modality_df[\"TEMP\"], color=\"k\")\n",
    "            ax.set_ylabel(\"Temperature (F)\", fontsize=16, color=\"k\")\n",
    "            ax.set_title(\"Temperature\", fontsize=20, color=\"k\")\n",
    "\n",
    "        ax.set_xlabel(\"Time\", fontsize=16, color=\"k\")\n",
    "        ax.xaxis.set_major_formatter(datetime_fmt)\n",
    "        self._plot_exp_regions(ax=ax)\n",
    "        ax.legend(bbox_to_anchor=(1.0, 0.75), facecolor='white', framealpha=1)\n",
    "\n",
    "def create_watch_results_tables(num_pars):\n",
    "    def _create_df(par_list, exp_name, modality):\n",
    "        temp_df_list = []\n",
    "        for par in par_list:\n",
    "            temp_df = pd.DataFrame()\n",
    "            temp_df[modality] = par.exp_modality_data_dict[exp_name][modality][modality]\n",
    "            # TODO add block column\n",
    "            temp_df.reset_index(inplace=True, drop=True)\n",
    "            par_num_col = par.data_fun.create_col(par.par_num, num_rows=temp_df.shape[0])\n",
    "            temp_df.insert(loc=0, column=\"participant\", value=par_num_col)\n",
    "            temp_df_list.append(temp_df)\n",
    "        df = pd.concat(temp_df_list, axis=0)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        return df\n",
    "\n",
    "    def _data_to_excel(exp_name, data_dict):\n",
    "        filepath = os.path.join(os.getcwd(), \"results/watch\", f\"{exp_name}_watch.xlsx\")\n",
    "        with pd.ExcelWriter(filepath, engine='xlsxwriter') as writer:\n",
    "            for modality, df in data_dict.items():\n",
    "                df.to_excel(writer, sheet_name=modality, index=False)\n",
    "\n",
    "    par_list = []                \n",
    "    for i in range(num_pars):\n",
    "        par_num = f\"{(i+1):02d}\"\n",
    "        print(par_num)\n",
    "        par = Participant_Watch(par_num=par_num)\n",
    "        par_list.append(par)\n",
    "\n",
    "    for exp_name in par.exp_order:\n",
    "        if exp_name == \"resting_state\" or exp_name == \"audio_narrative\" or exp_name == \"video_narrative_cmiyc\" or exp_name == \"video_narrative_sherlock\":\n",
    "            data_dict = {}\n",
    "            for modality in par.modalities: \n",
    "                if modality == \"ACC\":\n",
    "                    temp_df_list = []\n",
    "                    for par in par_list:\n",
    "                        temp_df = pd.DataFrame()\n",
    "                        temp_df[\"accel_x\"] = par.exp_modality_data_dict[exp_name][modality][\"accel_x\"]\n",
    "                        temp_df[\"accel_y\"] = par.exp_modality_data_dict[exp_name][modality][\"accel_y\"]\n",
    "                        temp_df[\"accel_z\"] = par.exp_modality_data_dict[exp_name][modality][\"accel_z\"]\n",
    "                        temp_df.reset_index(inplace=True, drop=True)\n",
    "                        par_num_col = par.data_fun.create_col(par.par_num, num_rows=temp_df.shape[0])\n",
    "                        temp_df.insert(0, \"participant\", par_num_col)\n",
    "                        temp_df_list.append(temp_df)\n",
    "                    ACC_df = pd.concat(temp_df_list, axis=0)\n",
    "                    ACC_df.reset_index(inplace=True, drop=True)\n",
    "                    ACC_df.insert(0, \"block\", par.exp_modality_data_dict[exp_name][modality][\"block\"])\n",
    "                    data_dict[modality] = ACC_df\n",
    "                elif modality == \"BVP\" or modality == \"EDA\" or modality == \"HR\" or modality == \"IBI\" or modality == \"TEMP\":\n",
    "                    modality_df = _create_df(par_list, exp_name, modality)\n",
    "                    modality_df.insert(0, \"block\", par.exp_modality_data_dict[exp_name][modality][\"block\"])\n",
    "                    data_dict[modality] = modality_df\n",
    "\n",
    "            _data_to_excel(exp_name, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\behav_analysis.py:628: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n"
     ]
    }
   ],
   "source": [
    "num_pars = 1\n",
    "create_watch_results_tables(num_pars=num_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 14:43:45.306938\n",
      "2022-06-15 14:47:15.292924\n",
      "2022-06-15 14:47:15.292924\n",
      "2022-06-15 14:50:45.312315\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.fromtimestamp(1655318625.306938))\n",
    "print(datetime.datetime.fromtimestamp(1655318835.292924))\n",
    "\n",
    "print(datetime.datetime.fromtimestamp(1655318835.292924))\n",
    "print(datetime.datetime.fromtimestamp(1655319045.3123152))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\behav_analysis.py:628: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_simp.drop(columns=[\"x_pos\", \"y_pos\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resting_state\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "resting_state\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "resting_state\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "resting_state\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "resting_state\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "resting_state\n",
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n",
      "go_no_go\n",
      "go_no_go\n",
      "go_no_go\n",
      "go_no_go\n",
      "go_no_go\n",
      "go_no_go\n",
      "video_narrative_sherlock\n",
      "video_narrative_sherlock\n",
      "video_narrative_sherlock\n",
      "video_narrative_sherlock\n",
      "video_narrative_sherlock\n",
      "video_narrative_sherlock\n",
      "king_devick\n",
      "king_devick\n",
      "king_devick\n",
      "king_devick\n",
      "king_devick\n",
      "king_devick\n",
      "vSAT\n",
      "vSAT\n",
      "vSAT\n",
      "vSAT\n",
      "vSAT\n",
      "vSAT\n",
      "audio_narrative\n",
      "audio_narrative\n",
      "audio_narrative\n",
      "audio_narrative\n",
      "audio_narrative\n",
      "audio_narrative\n",
      "n_back\n",
      "n_back\n",
      "n_back\n",
      "n_back\n",
      "n_back\n",
      "n_back\n",
      "tower_of_london\n",
      "tower_of_london\n",
      "tower_of_london\n",
      "tower_of_london\n",
      "tower_of_london\n",
      "tower_of_london\n",
      "video_narrative_cmiyc\n",
      "video_narrative_cmiyc\n",
      "video_narrative_cmiyc\n",
      "video_narrative_cmiyc\n",
      "video_narrative_cmiyc\n",
      "video_narrative_cmiyc\n"
     ]
    }
   ],
   "source": [
    "par_num = \"01\"\n",
    "par = Participant_Watch(par_num=par_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par.par_behav.audio_narrative.num_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1655321361.5756736, 1655321784.5756736) audio_narrative\n"
     ]
    }
   ],
   "source": [
    "for ts_tuple, block in par.par_behav.by_block_ts_df[\"audio_narrative\"].items():\n",
    "    print(ts_tuple, block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1655318625.306938, 1655318835.292924) eyes_closed\n",
      "(1655318835.292924, 1655319045.3123152) eyes_open\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"resting_state\"\n",
    "for ts_tuple, block in par.par_behav.by_block_ts_df[exp_name].items():\n",
    "    print(ts_tuple, block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1655318625.306938, 1655318835.292924) eyes_closed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'timestamps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zackg\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\zackg\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zackg\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamps'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\watch_analysis.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m start_ts \u001b[39m=\u001b[39m ts_tuple[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m end_ts \u001b[39m=\u001b[39m  ts_tuple[\u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m block_start_idx \u001b[39m=\u001b[39m par\u001b[39m.\u001b[39;49mdata_fun\u001b[39m.\u001b[39;49mget_start_index_ts(df, start_ts)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m block_end_idx \u001b[39m=\u001b[39m par\u001b[39m.\u001b[39mdata_fun\u001b[39m.\u001b[39mget_end_index_ts(df, end_ts)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m col_list\u001b[39m.\u001b[39mappend(par\u001b[39m.\u001b[39mdata_fun\u001b[39m.\u001b[39mcreate_col(\u001b[39mNone\u001b[39;00m, block_start_idx))\n",
      "File \u001b[1;32mc:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\behav_analysis.py:189\u001b[0m, in \u001b[0;36mData_Functions.get_start_index_ts\u001b[1;34m(self, df, start_ts)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_start_index_ts\u001b[39m(\u001b[39mself\u001b[39m, df, start_ts):\n\u001b[1;32m--> 189\u001b[0m     \u001b[39mfor\u001b[39;00m loc, ts \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(df[\u001b[39m\"\u001b[39;49m\u001b[39mtimestamps\u001b[39;49m\u001b[39m\"\u001b[39;49m]):\n\u001b[0;32m    190\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ts \u001b[39m<\u001b[39m start_ts:\n\u001b[0;32m    191\u001b[0m             watch_start_ts \u001b[39m=\u001b[39m ts\n",
      "File \u001b[1;32mc:\\Users\\zackg\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\zackg\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamps'"
     ]
    }
   ],
   "source": [
    "for ts_tuple, block in par.par_behav.by_block_ts_df[exp_name].items():\n",
    "    print(ts_tuple, block)     \n",
    "    start_ts = ts_tuple[0]\n",
    "    end_ts =  ts_tuple[1]\n",
    "    block_start_idx = par.data_fun.get_start_index_ts(df, start_ts)\n",
    "    block_end_idx = par.data_fun.get_end_index_ts(df, end_ts)\n",
    "    col_list.append(par.data_fun.create_col(None, block_start_idx))\n",
    "    col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "    col_list.append(par.data_fun.create_col(None, num_rows-block_end_idx))\n",
    "block_col = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "df.insert(0, \"block\", block_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>index</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>datetime</th>\n",
       "      <th>HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>23</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:43:18</td>\n",
       "      <td>143.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:43:19</td>\n",
       "      <td>144.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:43:20</td>\n",
       "      <td>144.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>26</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:43:21</td>\n",
       "      <td>145.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>27</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:43:22</td>\n",
       "      <td>145.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>None</td>\n",
       "      <td>467</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:50:42</td>\n",
       "      <td>79.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>None</td>\n",
       "      <td>468</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:50:43</td>\n",
       "      <td>79.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>None</td>\n",
       "      <td>469</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:50:44</td>\n",
       "      <td>79.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>None</td>\n",
       "      <td>470</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:50:45</td>\n",
       "      <td>79.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>None</td>\n",
       "      <td>471</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>2022-06-15 14:50:46</td>\n",
       "      <td>78.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    block  index    timestamps            datetime      HR\n",
       "0    None     23  1.655319e+09 2022-06-15 14:43:18  143.58\n",
       "1    None     24  1.655319e+09 2022-06-15 14:43:19  144.12\n",
       "2    None     25  1.655319e+09 2022-06-15 14:43:20  144.69\n",
       "3    None     26  1.655319e+09 2022-06-15 14:43:21  145.19\n",
       "4    None     27  1.655319e+09 2022-06-15 14:43:22  145.21\n",
       "..    ...    ...           ...                 ...     ...\n",
       "444  None    467  1.655319e+09 2022-06-15 14:50:42   79.25\n",
       "445  None    468  1.655319e+09 2022-06-15 14:50:43   79.18\n",
       "446  None    469  1.655319e+09 2022-06-15 14:50:44   79.12\n",
       "447  None    470  1.655319e+09 2022-06-15 14:50:45   79.05\n",
       "448  None    471  1.655319e+09 2022-06-15 14:50:46   78.98\n",
       "\n",
       "[449 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = par.exp_modality_data_dict[\"resting_state\"][\"HR\"]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what to do with i value in these enumerates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\watch_analysis.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m exp_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn_back\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m modality \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHR\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNum blocks:\u001b[39m\u001b[39m\"\u001b[39m, exp\u001b[39m.\u001b[39mnum_blocks)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m par\u001b[39m.\u001b[39mexp_modality_data_dict[exp_name][modality]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zackg/OneDrive/Ayaz%20Lab/KernelFlow_Analysis/watch_analysis.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mreset_index()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "exp_name = \"n_back\"\n",
    "modality = \"HR\"\n",
    "print(\"Num blocks:\", exp.num_blocks)\n",
    "df = par.exp_modality_data_dict[exp_name][modality]\n",
    "df = df.reset_index()\n",
    "num_rows = df.shape[0]\n",
    "print(\"Num rows:\", num_rows)\n",
    "\n",
    "col_list = []\n",
    "for ts_tuple, block in par.par_behav.by_block_ts_df[exp_name].items():\n",
    "    print(ts_tuple, block)\n",
    "    start_ts = ts_tuple[0]\n",
    "    end_ts =  ts_tuple[1]\n",
    "    block_start_idx = par.data_fun.get_start_index_ts(df, start_ts)\n",
    "    block_end_idx = par.data_fun.get_end_index_ts(df, end_ts)\n",
    "    print(block_start_idx, block_end_idx)\n",
    "    if i == 0:\n",
    "        col_list.append(par.data_fun.create_col(None, block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "    elif i == exp.num_blocks-1:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(None, num_rows-block_end_idx))\n",
    "    else:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "test5 = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "df.insert(0, \"block\", test5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "exp_name = \"tower_of_london\"\n",
    "modality = \"HR\"\n",
    "print(\"Num blocks:\", exp.num_blocks)\n",
    "df = par.exp_modality_data_dict[exp_name][modality]\n",
    "df = df.reset_index()\n",
    "num_rows = df.shape[0]\n",
    "print(\"Num rows:\", num_rows)\n",
    "\n",
    "col_list = []\n",
    "for ts_tuple, block in par.par_behav.by_block_ts_df[exp_name].items():\n",
    "    print(ts_tuple, block)\n",
    "    start_ts = ts_tuple[0]\n",
    "    end_ts =  ts_tuple[1]\n",
    "    block_start_idx = par.data_fun.get_start_index_ts(df, start_ts)\n",
    "    block_end_idx = par.data_fun.get_end_index_ts(df, end_ts)\n",
    "    print(block_start_idx, block_end_idx)\n",
    "    if i == 0:\n",
    "        col_list.append(par.data_fun.create_col(None, block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "    elif i == exp.num_blocks-1:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(None, num_rows-block_end_idx))\n",
    "    else:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "test6 = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "df.insert(0, \"block\", test6)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "exp_name = \"go_no_go\"\n",
    "modality = \"HR\"\n",
    "print(\"Num blocks:\", exp.num_blocks)\n",
    "df = par.exp_modality_data_dict[exp_name][modality]\n",
    "df = df.reset_index()\n",
    "num_rows = df.shape[0]\n",
    "print(\"Num rows:\", num_rows)\n",
    "\n",
    "col_list = []\n",
    "for ts_tuple, block in par.par_behav.by_block_ts_df[exp_name].items():\n",
    "    print(ts_tuple, block)\n",
    "    start_ts = ts_tuple[0]\n",
    "    end_ts =  ts_tuple[1]\n",
    "    block_start_idx = par.data_fun.get_start_index_ts(df, start_ts)\n",
    "    block_end_idx = par.data_fun.get_end_index_ts(df, end_ts)\n",
    "    print(block_start_idx, block_end_idx)\n",
    "    if i == 0:\n",
    "        col_list.append(par.data_fun.create_col(None, block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "    elif i == exp.num_blocks-1:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(None, num_rows-block_end_idx))\n",
    "    else:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "test7 = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "df.insert(0, \"block\", test7)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "exp_name = \"vSAT\"\n",
    "modality = \"HR\"\n",
    "print(\"Num blocks:\", exp.num_blocks)\n",
    "df = par.exp_modality_data_dict[exp_name][modality]\n",
    "df = df.reset_index()\n",
    "num_rows = df.shape[0]\n",
    "print(\"Num rows:\", num_rows)\n",
    "\n",
    "col_list = []\n",
    "for ts_tuple, block in par.par_behav.by_block_ts_df[exp_name].items():\n",
    "    print(ts_tuple, block)\n",
    "    start_ts = ts_tuple[0]\n",
    "    end_ts =  ts_tuple[1]\n",
    "    block_start_idx = par.data_fun.get_start_index_ts(df, start_ts)\n",
    "    block_end_idx = par.data_fun.get_end_index_ts(df, end_ts)\n",
    "    print(block_start_idx, block_end_idx)\n",
    "    if i == 0:\n",
    "        col_list.append(par.data_fun.create_col(None, block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "    elif i == exp.num_blocks-1:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "        col_list.append(par.data_fun.create_col(None, num_rows-block_end_idx))\n",
    "    else:\n",
    "        col_list.append(par.data_fun.create_col(block, block_end_idx-block_start_idx))\n",
    "test8 = pd.concat(col_list, axis=0, ignore_index=True)\n",
    "df.insert(0, \"block\", test8)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accelerometer ###\n",
    "par.plot_modality(\"ACC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Photoplethysmograph ###\n",
    "par.plot_modality(\"BVP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Electrodermal ###\n",
    "par.plot_modality(\"EDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heart Rate ###\n",
    "par.plot_modality(\"HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interbeat Interval ###\n",
    "par.plot_modality(\"IBI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temperature ###\n",
    "par.plot_modality(\"TEMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc7c3b5b3ed8bccdeb6381f95d0763ef1bb082ae76d136fc0c3d4673d6eca8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
