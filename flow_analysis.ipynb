{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import snirf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# %matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "from typing import Union\n",
    "from statistics import mean\n",
    "from behav_analysis import Participant_Behav, load_results\n",
    "from data_functions import Data_Functions\n",
    "\n",
    "\n",
    "class Process_Flow:\n",
    "    \"\"\"\n",
    "    This class contains functions for processing Kernel Flow data.\n",
    "    Wrapper around an snirf.Snirf object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filepath: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize by loading SNIRF file.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to SNIRF file.\n",
    "        \"\"\"\n",
    "        self.data_fun = Data_Functions()\n",
    "        self.snirf_file = self.load_snirf(filepath)\n",
    "\n",
    "    def load_snirf(self, filepath: str) -> snirf.Snirf:\n",
    "        \"\"\"\n",
    "        Load SNIRF file.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to SNIRF file.\n",
    "\n",
    "        Returns:\n",
    "            snirf.Snirf: SNIRF file object.\n",
    "        \"\"\"\n",
    "        return snirf.Snirf(filepath, \"r+\", dynamic_loading=True)\n",
    "\n",
    "    def get_time_origin(\n",
    "        self, fmt: str = \"datetime\", offset=True\n",
    "    ) -> Union[datetime.datetime, float]:\n",
    "        \"\"\"\n",
    "        Get the time origin (start time) from the SNIRF file.\n",
    "\n",
    "        Args:\n",
    "            fmt (str, optional): Format to get the time origin in: \"datetime\" or \"timestamp\". Defaults to \"datetime\".\n",
    "            offset (bool): Offset the datetime by 4 hours. Defaults to True.\n",
    "\n",
    "        Raises:\n",
    "            Exception: Invalid fmt argument.\n",
    "\n",
    "        Returns:\n",
    "            Union[datetime.datetime, float]:\n",
    "                datetime.datetime: Time origin datetime.\n",
    "                -or-\n",
    "                float: Time origin timestamp.\n",
    "        \"\"\"\n",
    "        start_date = self.snirf_file.nirs[0].metaDataTags.MeasurementDate\n",
    "        start_time = self.snirf_file.nirs[0].metaDataTags.MeasurementTime\n",
    "        start_str = start_date + \" \" + start_time\n",
    "        if offset:\n",
    "            time_origin = datetime.datetime.strptime(\n",
    "                start_str, \"%Y-%m-%d %H:%M:%S\"\n",
    "            ) - datetime.timedelta(\n",
    "                hours=4\n",
    "            )  # 4 hour offset\n",
    "        else:\n",
    "            time_origin = datetime.datetime.strptime(start_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "        if fmt.lower() == \"datetime\":\n",
    "            return time_origin\n",
    "        elif fmt.lower() == \"timestamp\":\n",
    "            return datetime.datetime.timestamp(time_origin)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Invalid 'fmt' argument. Must be 'datetime' or 'timestamp'.\"\n",
    "            )\n",
    "\n",
    "    def get_subject_ID(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the subject ID from the SNIRF file.\n",
    "\n",
    "        Returns:\n",
    "            str: Subject ID.\n",
    "        \"\"\"\n",
    "        return self.snirf_file.nirs[0].metaDataTags.SubjectID\n",
    "\n",
    "    def get_time_rel(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the relative time array from the SNIRF file.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Relative time array.\n",
    "        \"\"\"\n",
    "        return self.snirf_file.nirs[0].data[0].time\n",
    "\n",
    "    def get_time_abs(self, fmt: str = \"datetime\") -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert relative time array into an absolute time array.\n",
    "\n",
    "        Args:\n",
    "            fmt (str, optional): Format to get the time array in: \"datetime\" or \"timestamp\". Defaults to \"datetime\".\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Absolute time array.\n",
    "        \"\"\"\n",
    "        time_rel = self.get_time_rel()\n",
    "        if fmt.lower() == \"datetime\":\n",
    "            time_origin_dt = self.get_time_origin(\"datetime\")\n",
    "            return np.array(\n",
    "                [\n",
    "                    datetime.timedelta(seconds=time_rel[i]) + time_origin_dt\n",
    "                    for i in range(len(time_rel))\n",
    "                ]\n",
    "            )\n",
    "        elif fmt.lower() == \"timestamp\":\n",
    "            time_origin_ts = self.get_time_origin(\"timestamp\")\n",
    "            return time_rel + time_origin_ts\n",
    "\n",
    "    def get_data(\n",
    "        self, fmt: str = \"array\", cols: list[int | list | tuple] = None\n",
    "    ) -> Union[np.ndarray, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Get timeseries data from the SNIRF file.\n",
    "\n",
    "        Args:\n",
    "            fmt (str): Format of data (np.ndarray or pd.DataFrame). Defaults to \"array\".\n",
    "            cols (list[int | list | tuple]): Data cols to select. Single col, list of cols, or slice of cols.\n",
    "                                             Defaults to None (all columns).\n",
    "\n",
    "        Raises:\n",
    "            Exception: Invalid fmt argument.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Timeseries data array.\n",
    "        \"\"\"\n",
    "        if cols or cols == 0:\n",
    "            if isinstance(cols, tuple):\n",
    "                data = (\n",
    "                    self.snirf_file.nirs[0].data[0].dataTimeSeries[:, cols[0] : cols[1]]\n",
    "                )\n",
    "            else:\n",
    "                data = self.snirf_file.nirs[0].data[0].dataTimeSeries[:, cols]\n",
    "        else:\n",
    "            data = self.snirf_file.nirs[0].data[0].dataTimeSeries\n",
    "\n",
    "        if \"array\" in fmt.lower():\n",
    "            return data\n",
    "        elif \"dataframe\" in fmt.lower():\n",
    "            return pd.DataFrame(data)\n",
    "        else:\n",
    "            raise Exception(\"Invalid fmt argument. Must be 'array' or 'dataframe'.\")\n",
    "\n",
    "    def get_source_pos_2d(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the 2D source position array.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 2D source position array\n",
    "        \"\"\"\n",
    "        return self.snirf_file.nirs[0].probe.sourcePos2D\n",
    "\n",
    "    def get_source_pos_3d(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the 3D source position array.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 3D source position array\n",
    "        \"\"\"\n",
    "        return self.snirf_file.nirs[0].probe.sourcePos3D\n",
    "\n",
    "    def get_detector_pos_2d(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the 2D detector position array.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 2D detector position array\n",
    "        \"\"\"\n",
    "        return self.snirf_file.nirs[0].probe.detectorPos2D\n",
    "\n",
    "    def get_detector_pos_3d(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the 3D detector position array.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 3D detector position array\n",
    "        \"\"\"\n",
    "        return self.snirf_file.nirs[0].probe.detectorPos3D\n",
    "\n",
    "    def get_marker_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get a DataFrame of marker data from the \"stim\" part of the SNIRF file.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Marker \"stim\" data.\n",
    "        \"\"\"\n",
    "        marker_data = self.snirf_file.nirs[0].stim[0].data\n",
    "        marker_data_cols = self.snirf_file.nirs[0].stim[0].dataLabels\n",
    "        return pd.DataFrame(marker_data, columns=marker_data_cols)\n",
    "\n",
    "    def get_unique_data_types(self) -> list:\n",
    "        \"\"\"\n",
    "        Get unique data types from the SNIRF file.\n",
    "\n",
    "        Returns:\n",
    "            list: Unique data types.\n",
    "        \"\"\"\n",
    "        data_types = []\n",
    "        for i in range(len(self.snirf_file.nirs[0].data[0].measurementList)):\n",
    "            data_type = self.snirf_file.nirs[0].data[0].measurementList[i].dataType\n",
    "            if data_type not in data_types:\n",
    "                data_types.append(data_type)\n",
    "        return data_types\n",
    "\n",
    "    def get_data_type_label(self, channel_num: int) -> str:\n",
    "        \"\"\"\n",
    "        Get the data type label for a channel(s).\n",
    "\n",
    "        Args:\n",
    "            channel_num (int): Channel number to get the data type label of.\n",
    "\n",
    "        Returns:\n",
    "            str: Data type label of the channel.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.snirf_file.nirs[0].data[0].measurementList[channel_num].dataTypeLabel\n",
    "        )\n",
    "\n",
    "    def get_unique_data_type_labels(self) -> list:\n",
    "        \"\"\"\n",
    "        Get unique data type labels from the SNIRF file.\n",
    "\n",
    "        Returns:\n",
    "            list: Unique data type labels.\n",
    "        \"\"\"\n",
    "        data_type_labels = []\n",
    "        for i in range(len(self.snirf_file.nirs[0].data[0].measurementList)):\n",
    "            data_type_label = (\n",
    "                self.snirf_file.nirs[0].data[0].measurementList[i].dataTypeLabel\n",
    "            )\n",
    "            if data_type_label not in data_type_labels:\n",
    "                data_type_labels.append(data_type_label)\n",
    "        return data_type_labels\n",
    "\n",
    "    def create_source_dict(self) -> dict:\n",
    "        \"\"\"\n",
    "        Count the occurrences of each source index.\n",
    "\n",
    "        Returns:\n",
    "            dict: Counts for each source index.\n",
    "        \"\"\"\n",
    "        source_dict = {}\n",
    "        for i in range(len(self.snirf_file.nirs[0].data[0].measurementList)):\n",
    "            source = self.snirf_file.nirs[0].data[0].measurementList[i].sourceIndex\n",
    "            source_dict[source] = source_dict.get(source, 0) + 1\n",
    "        source_dict = self.data_fun.sort_dict(source_dict, \"keys\")\n",
    "        return source_dict\n",
    "\n",
    "    def create_detector_dict(self) -> dict:\n",
    "        \"\"\"\n",
    "        Count the occurrences of each detector index.\n",
    "\n",
    "        Returns:\n",
    "            dict: Counts for each detector index.\n",
    "        \"\"\"\n",
    "        detector_dict = {}\n",
    "        for i in range(len(self.snirf_file.nirs[0].data[0].measurementList)):\n",
    "            detector = self.snirf_file.nirs[0].data[0].measurementList[i].detectorIndex\n",
    "            detector_dict[detector] = detector_dict.get(detector, 0) + 1\n",
    "        detector_dict = self.data_fun.sort_dict(detector_dict, \"keys\")\n",
    "        return detector_dict\n",
    "\n",
    "    def plot_pos_2d(self) -> None:\n",
    "        \"\"\"\n",
    "        Plot the detector/source 2D positions.\n",
    "        \"\"\"\n",
    "        detector_pos_2d = self.get_detector_pos_2d()\n",
    "        x_detector = detector_pos_2d[:, 0]\n",
    "        y_detector = detector_pos_2d[:, 1]\n",
    "\n",
    "        source_pos_2d = self.get_source_pos_2d()\n",
    "        x_source = source_pos_2d[:, 0]\n",
    "        y_source = source_pos_2d[:, 1]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(x_detector, y_detector)\n",
    "        ax.scatter(x_source, y_source)\n",
    "        ax.set_title(\"Detector/Source 2D Plot\")\n",
    "        ax.set_xlabel(\"X-Position (mm)\")\n",
    "        ax.set_ylabel(\"Y-Position (mm)\")\n",
    "        ax.legend([\"Detector\", \"Source\"])\n",
    "\n",
    "    def plot_pos_3d(self) -> None:\n",
    "        \"\"\"\n",
    "        Plot the detector/source 3D positions.\n",
    "        \"\"\"\n",
    "        detector_pos_3d = self.get_detector_pos_3d()\n",
    "        x_detector = detector_pos_3d[:, 0]\n",
    "        y_detector = detector_pos_3d[:, 1]\n",
    "        z_detector = detector_pos_3d[:, 2]\n",
    "\n",
    "        source_pos_3d = self.get_source_pos_3d()\n",
    "        x_source = source_pos_3d[:, 0]\n",
    "        y_source = source_pos_3d[:, 1]\n",
    "        z_source = source_pos_3d[:, 2]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        ax.scatter(x_detector, y_detector, z_detector)\n",
    "        ax.scatter(x_source, y_source, z_source)\n",
    "        ax.set_title(\"Detector/Source 3D Plot\")\n",
    "        ax.set_xlabel(\"X-Position (mm)\")\n",
    "        ax.set_ylabel(\"Y-Position (mm)\")\n",
    "        ax.set_zlabel(\"Z-Position (mm)\")\n",
    "        ax.legend([\"Detector\", \"Source\"])\n",
    "\n",
    "\n",
    "class Participant_Flow:\n",
    "    \"\"\"\n",
    "    This class contains functions, data structures, and info necessary for\n",
    "    processing Kernel Flow data from the experiments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, par_num):\n",
    "        self.data_fun = Data_Functions()\n",
    "        self.adj_ts_markers = True\n",
    "        self.par_behav = Participant_Behav(par_num, self.adj_ts_markers)\n",
    "        self.par_num, self.par_ID = self.data_fun.process_par(par_num)\n",
    "        data_dir = r\"C:\\Kernel\\raw_data\"  # TODO: make this path relative\n",
    "        self.flow_data_dir = os.path.join(data_dir, self.par_ID, \"kernel_data\")\n",
    "        self.plot_color_dict = {\n",
    "            0: \"purple\",\n",
    "            1: \"orange\",\n",
    "            2: \"green\",\n",
    "            3: \"yellow\",\n",
    "            4: \"pink\",\n",
    "            5: \"skyblue\",\n",
    "        }\n",
    "        self.flow_session_dict = self.create_flow_session_dict(wrapper=True)\n",
    "\n",
    "    def load_flow_session(\n",
    "        self, session: list[str | int], wrapper: bool = False\n",
    "    ) -> snirf.Snirf:\n",
    "        \"\"\"\n",
    "        Load Kernel Flow data for an experiment session.\n",
    "\n",
    "        Args:\n",
    "            session list[str | int]: Experiment session.\n",
    "            wrapper (bool, optional) Option to return Process_Flow-wrapped SNIRF file.\n",
    "                                     Defaults to false.\n",
    "\n",
    "        Raises:\n",
    "            Exception: Invalid session number argument.\n",
    "\n",
    "        Returns:\n",
    "            snirf.Snirf: SNIRF file object.\n",
    "            -or-\n",
    "            Process_Flow object for each experiment session.\n",
    "        \"\"\"\n",
    "        if isinstance(session, str):\n",
    "            if \"session\" not in session:\n",
    "                session = f\"session_{session}\"\n",
    "        elif isinstance(session, int):\n",
    "            session = f\"session_{session}\"\n",
    "        try:\n",
    "            session_dir = os.path.join(self.flow_data_dir, session)\n",
    "            filename = os.listdir(session_dir)[0]\n",
    "            filepath = os.path.join(session_dir, filename)\n",
    "            if wrapper:\n",
    "                return Process_Flow(filepath)\n",
    "            else:\n",
    "                return Process_Flow(filepath).snirf_file\n",
    "        except:\n",
    "            print(\"Invalid session number.\")\n",
    "            raise\n",
    "\n",
    "    def load_flow_exp(self, exp_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load Kernel Flow data for the time frame of a specified experiment.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Name of the experiment.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Kernel Flow data for an experiment.\n",
    "        \"\"\"\n",
    "\n",
    "        def _offset_time_array(exp_name: str, time_array: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            Offset a Kernel Flow datetime array for an experiment by the time-offset.\n",
    "\n",
    "            Args:\n",
    "                exp_name (str): Name of the experiment.\n",
    "                time_array (np.ndarray): Datetime array.\n",
    "\n",
    "            Returns:\n",
    "                np.ndarray: Time-offset datetime array.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                time_offset = self.get_time_offset(exp_name)\n",
    "            except KeyError:  # if experiment start time missing, use avg of all other experiments\n",
    "                time_offset_list = []\n",
    "                for exp_name in self.par_behav.exp_order:\n",
    "                    try:\n",
    "                        time_offset = self.get_time_offset(exp_name)\n",
    "                        time_offset_list.append(time_offset)\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                time_offset = mean(time_offset_list)\n",
    "            time_offset_dt = datetime.timedelta(seconds=time_offset)\n",
    "            time_abs_dt_offset = time_array + time_offset_dt\n",
    "            return time_abs_dt_offset\n",
    "\n",
    "        session = self.par_behav.get_key_from_value(\n",
    "            self.par_behav.session_dict, exp_name\n",
    "        )\n",
    "        flow_session = self.load_flow_session(session, wrapper=True)\n",
    "\n",
    "        start_dt = self.par_behav.get_start_dt(exp_name, self.adj_ts_markers)\n",
    "        end_dt = self.par_behav.get_end_dt(exp_name, self.adj_ts_markers)\n",
    "        time_abs_dt = flow_session.get_time_abs(\"datetime\")\n",
    "        time_abs_dt_offset = _offset_time_array(exp_name, time_abs_dt)\n",
    "        start_idx = self.par_behav.get_start_index_dt(time_abs_dt_offset, start_dt)\n",
    "        end_idx = self.par_behav.get_end_index_dt(time_abs_dt_offset, end_dt)\n",
    "\n",
    "        flow_data = flow_session.get_data(\"dataframe\")\n",
    "        flow_data.insert(0, \"datetime\", time_abs_dt_offset)\n",
    "        return flow_data.iloc[start_idx:end_idx, :]\n",
    "\n",
    "    def create_flow_session_dict(self, wrapper: bool = False) -> dict:\n",
    "        \"\"\"\n",
    "        Create a dictionary of Kernel Flow data for all experiment sessions.\n",
    "\n",
    "        wrapper (bool, optional) Option to return Process_Flow-wrapped SNIRF file.\n",
    "                                 Default to false.\n",
    "\n",
    "        Returns:\n",
    "            dict: Kernel Flow data for all experiment sessions.\n",
    "                keys:\n",
    "                    \"session_1001\", \"session_1002\", \"session_1003\"\n",
    "                values:\n",
    "                    SNIRF file object for each experiment session\n",
    "                    -or-\n",
    "                    Process_Flow object for each experiment session\n",
    "        \"\"\"\n",
    "        flow_session_dict = {}\n",
    "        for session in self.par_behav.session_dict.keys():\n",
    "            flow_session_dict[session] = self.load_flow_session(session, wrapper)\n",
    "        return flow_session_dict\n",
    "\n",
    "    def create_abs_marker_df(self, session: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the \"stim\" marker DataFrame into absolute time.\n",
    "\n",
    "        Args:\n",
    "            session (str): Experiment session.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Marker \"stim\" data in absolute time.\n",
    "        \"\"\"\n",
    "        marker_df = self.flow_session_dict[session].get_marker_df()\n",
    "        time_origin_ts = self.flow_session_dict[session].get_time_origin(\"timestamp\")\n",
    "        marker_df[\"Timestamp\"] = marker_df[\"Timestamp\"] + time_origin_ts\n",
    "        marker_df.rename({\"Timestamp\": \"Start timestamp\"}, axis=1, inplace=True)\n",
    "\n",
    "        for idx, row in marker_df.iterrows():\n",
    "            end_ts = row[\"Start timestamp\"] + row[\"Duration\"]\n",
    "            marker_df.at[idx, \"End timestamp\"] = end_ts\n",
    "            exp_num = int(row[\"Experiment\"])\n",
    "            exp_name = self.par_behav.marker_dict[exp_num]\n",
    "            marker_df.at[idx, \"Experiment\"] = exp_name\n",
    "\n",
    "        marker_df.rename({\"Experiment\": \"Marker\"}, axis=1, inplace=True)\n",
    "        marker_df.drop([\"Value\"], axis=1, inplace=True)\n",
    "        marker_df = marker_df[\n",
    "            [\"Marker\", \"Start timestamp\", \"Duration\", \"End timestamp\"]\n",
    "        ]\n",
    "        return marker_df\n",
    "\n",
    "    def get_time_offset(self, exp_name: str) -> float:\n",
    "        \"\"\"\n",
    "        Get the time offset (in seconds) between the behavioral and Kernel Flow data files.\n",
    "        Number of seconds that the Kernel Flow data is ahead of the behavioral data.\n",
    "\n",
    "        Args:\n",
    "            exp_name (str): Name of the experiment.\n",
    "\n",
    "        Returns:\n",
    "            float: Time offset (in seconds).\n",
    "        \"\"\"\n",
    "        exp = self.par_behav.get_exp(exp_name)\n",
    "        exp_start_ts = exp.start_ts\n",
    "        marker_sent_time = float(exp.marker_data[\"start_marker\"][\"sent_time\"])\n",
    "        session = self.par_behav.get_key_from_value(\n",
    "            self.par_behav.session_dict, exp_name\n",
    "        )\n",
    "        marker_df = self.create_abs_marker_df(session)\n",
    "        row = marker_df.loc[marker_df[\"Marker\"].str.startswith(exp_name)].reset_index()\n",
    "        kernel_start_ts = row.loc[0, \"Start timestamp\"]\n",
    "        time_offset = kernel_start_ts - (exp_start_ts + marker_sent_time)\n",
    "        return float(time_offset)\n",
    "\n",
    "    def plot_flow_session(self, session: str) -> None:\n",
    "        # NOTE not time offset\n",
    "        flow_session = self.flow_session_dict[session]\n",
    "        time_abs_dt = flow_session.get_time_abs(\"datetime\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 6))\n",
    "        ax.plot(\n",
    "            time_abs_dt, flow_session.get_data(cols=0)\n",
    "        )  # NOTE: get_data argument is a placeholder\n",
    "        for exp_name in self.par_behav.session_dict[session]:\n",
    "            exp_start_dt = self.par_behav.get_start_dt(exp_name)\n",
    "            exp_end_dt = self.par_behav.get_end_dt(exp_name)\n",
    "            ax.axvline(exp_start_dt, linestyle=\"dashed\", color=\"k\", alpha=0.75)\n",
    "            ax.axvline(exp_end_dt, linestyle=\"dashed\", color=\"k\", alpha=0.75)\n",
    "            ax.axvspan(\n",
    "                exp_start_dt,\n",
    "                exp_end_dt,\n",
    "                color=self.par_behav.exp_color_dict[exp_name],\n",
    "                alpha=0.4,\n",
    "                label=exp_name,\n",
    "            )\n",
    "        datetime_fmt = mdates.DateFormatter(\"%H:%M:%S\")\n",
    "        ax.xaxis.set_major_formatter(datetime_fmt)\n",
    "        ax.set_xlabel(\"Time\", fontsize=16, color=\"k\")\n",
    "        ax.legend(bbox_to_anchor=(1.0, 0.75), facecolor=\"white\", framealpha=1)\n",
    "\n",
    "    def plot_flow_exp(self, exp_name: str) -> None:\n",
    "        channel_nums = [0, 1]  # NOTE testing\n",
    "        flow_exp = self.load_flow_exp(exp_name)\n",
    "        session = self.par_behav.get_key_from_value(\n",
    "            self.par_behav.session_dict, exp_name\n",
    "        )\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 6))\n",
    "\n",
    "        data_traces = []\n",
    "        data_labels = []\n",
    "        for channel_num in channel_nums:\n",
    "            data_type_label = self.flow_session_dict[session].get_data_type_label(\n",
    "                channel_num\n",
    "            )\n",
    "            legend_label = f\"Ch {channel_num} ({data_type_label})\"\n",
    "            if data_type_label == \"HbO\":\n",
    "                color = \"red\"\n",
    "            elif data_type_label == \"HbR\":\n",
    "                color = \"blue\"\n",
    "            (data_trace,) = ax.plot(\n",
    "                flow_exp[\"datetime\"],\n",
    "                flow_exp.iloc[:, channel_num + 1],\n",
    "                color=color,\n",
    "                label=legend_label,\n",
    "            )\n",
    "            data_traces.append(data_trace)\n",
    "            data_labels.append(legend_label)\n",
    "\n",
    "        exp_start_dt = self.par_behav.get_start_dt(exp_name, self.adj_ts_markers)\n",
    "        exp_end_dt = self.par_behav.get_end_dt(exp_name, self.adj_ts_markers)\n",
    "        ax.axvline(exp_start_dt, linestyle=\"dashed\", color=\"k\", alpha=0.75)\n",
    "        ax.axvline(exp_end_dt, linestyle=\"dashed\", color=\"k\", alpha=0.75)\n",
    "        results_dir = r\"C:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\processed_data\\behavioral\"  # NOTE: temporary\n",
    "        exp_results = load_results(results_dir, exp_name, self.par_num)\n",
    "        exp_title = self.par_behav.format_exp_name(exp_name)\n",
    "\n",
    "        stim_spans = []\n",
    "        for _, row in exp_results.iterrows():\n",
    "            try:\n",
    "                uni_stim_dict = self.par_behav.create_unique_stim_dict(\n",
    "                    exp_results, \"stim\"\n",
    "                )\n",
    "                stim = row[\"stim\"]\n",
    "                legend_label = self.par_behav.format_exp_name(row[\"stim\"])\n",
    "            except KeyError:\n",
    "                uni_stim_dict = self.par_behav.create_unique_stim_dict(\n",
    "                    exp_results, \"block\"\n",
    "                )\n",
    "                stim = row[\"block\"]\n",
    "                legend_label = self.par_behav.format_exp_name(row[\"block\"])\n",
    "            color_index = uni_stim_dict[stim]\n",
    "            stim_start = datetime.datetime.fromtimestamp(row[\"stim_start\"])\n",
    "            try:\n",
    "                stim_end = datetime.datetime.fromtimestamp(row[\"stim_end\"])\n",
    "            except ValueError:\n",
    "                if exp_name == \"go_no_go\":\n",
    "                    stim_time = 0.5  # seconds\n",
    "                stim_end = datetime.datetime.fromtimestamp(\n",
    "                    row[\"stim_start\"] + stim_time\n",
    "                )\n",
    "            stim_span = ax.axvspan(\n",
    "                stim_start,\n",
    "                stim_end,\n",
    "                color=self.plot_color_dict[color_index],\n",
    "                alpha=0.4,\n",
    "                label=legend_label,\n",
    "            )\n",
    "            stim_spans.append(stim_span)\n",
    "\n",
    "        data_legend = ax.legend(\n",
    "            handles=data_traces,\n",
    "            bbox_to_anchor=(1.0, 1.0),\n",
    "            facecolor=\"white\",\n",
    "            framealpha=1,\n",
    "            title=\"Kernel Flow Data\",\n",
    "        )\n",
    "\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        uni_labels = dict(zip(labels, handles))\n",
    "        [uni_labels.pop(data_label) for data_label in data_labels]\n",
    "\n",
    "        stim_legend = ax.legend(\n",
    "            uni_labels.values(),\n",
    "            uni_labels.keys(),\n",
    "            bbox_to_anchor=(1.0, 0.75),\n",
    "            facecolor=\"white\",\n",
    "            framealpha=1,\n",
    "            title=\"Stimulus\",\n",
    "        )\n",
    "\n",
    "        ax.add_artist(data_legend)\n",
    "        ax.set_title(exp_title)\n",
    "        datetime_fmt = mdates.DateFormatter(\"%H:%M:%S\")\n",
    "        ax.xaxis.set_major_formatter(datetime_fmt)\n",
    "        ax.set_xlabel(\"Time\", fontsize=16, color=\"k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_01\n"
     ]
    }
   ],
   "source": [
    "# SNIRF file loading\n",
    "par_num = 1\n",
    "par = Participant_Flow(par_num)\n",
    "print(par.par_ID)\n",
    "# exp_name = \"tower_of_london\"\n",
    "# par.plot_flow_exp(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant                         1\n",
       "sex                                 M\n",
       "age                                25\n",
       "hours_of_sleep                    8.0\n",
       "trial                               1\n",
       "block                          1_back\n",
       "match                             0.0\n",
       "stim_start          1655322551.858229\n",
       "stim_end            1655322552.358229\n",
       "inter_stim_start    1655322552.358229\n",
       "inter_stim_end      1655322555.358229\n",
       "correct_response                  1.0\n",
       "response_time                1.287123\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir = r\"C:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\processed_data\\behavioral\"  # NOTE: temporary\n",
    "exp_results = load_results(results_dir, exp_name=\"n_back\", par_num=1)\n",
    "exp_results.loc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_list = par.flow_session_dict[\"session_1003\"].get_time_abs(\"timestamp\")\n",
    "stim_start_ts = exp_results.loc[exp_results['participant'] == 1, 'stim_start'].values[0]\n",
    "stim_end_ts = exp_results.loc[exp_results['participant'] == 1, 'stim_end'].values[0]\n",
    "data_fun = Data_Functions()\n",
    "start_idx, start = data_fun.find_closest_ts(stim_start_ts, ts_list)\n",
    "end_idx, end = data_fun.find_closest_ts(stim_end_ts, ts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4282</th>\n",
       "      <th>4283</th>\n",
       "      <th>4284</th>\n",
       "      <th>4285</th>\n",
       "      <th>4286</th>\n",
       "      <th>4287</th>\n",
       "      <th>4288</th>\n",
       "      <th>4289</th>\n",
       "      <th>4290</th>\n",
       "      <th>4291</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>3.914275</td>\n",
       "      <td>1.430917</td>\n",
       "      <td>3.073586</td>\n",
       "      <td>0.148639</td>\n",
       "      <td>2.727371</td>\n",
       "      <td>0.355025</td>\n",
       "      <td>4.394125</td>\n",
       "      <td>0.912574</td>\n",
       "      <td>2.934429</td>\n",
       "      <td>0.535574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>2.564982</td>\n",
       "      <td>-1.104725</td>\n",
       "      <td>1.516514</td>\n",
       "      <td>-0.361627</td>\n",
       "      <td>-0.514603</td>\n",
       "      <td>1.446447</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>1.075552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.672175</td>\n",
       "      <td>1.675839</td>\n",
       "      <td>2.581518</td>\n",
       "      <td>0.494772</td>\n",
       "      <td>2.694944</td>\n",
       "      <td>0.422407</td>\n",
       "      <td>3.730156</td>\n",
       "      <td>1.304782</td>\n",
       "      <td>2.570597</td>\n",
       "      <td>1.037048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916298</td>\n",
       "      <td>-0.533447</td>\n",
       "      <td>2.390451</td>\n",
       "      <td>-0.811287</td>\n",
       "      <td>1.481926</td>\n",
       "      <td>-0.112917</td>\n",
       "      <td>-1.241427</td>\n",
       "      <td>2.090492</td>\n",
       "      <td>0.614429</td>\n",
       "      <td>0.488256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>3.890635</td>\n",
       "      <td>1.133280</td>\n",
       "      <td>2.870586</td>\n",
       "      <td>-0.182814</td>\n",
       "      <td>3.454614</td>\n",
       "      <td>-0.304021</td>\n",
       "      <td>4.222064</td>\n",
       "      <td>0.555219</td>\n",
       "      <td>3.032418</td>\n",
       "      <td>0.178172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406948</td>\n",
       "      <td>-0.201813</td>\n",
       "      <td>2.556703</td>\n",
       "      <td>-1.471034</td>\n",
       "      <td>1.694347</td>\n",
       "      <td>-0.660910</td>\n",
       "      <td>-0.309917</td>\n",
       "      <td>1.320174</td>\n",
       "      <td>1.168289</td>\n",
       "      <td>-0.344950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>3.662318</td>\n",
       "      <td>1.623327</td>\n",
       "      <td>2.741567</td>\n",
       "      <td>0.302309</td>\n",
       "      <td>2.901100</td>\n",
       "      <td>0.150964</td>\n",
       "      <td>4.110166</td>\n",
       "      <td>1.023732</td>\n",
       "      <td>2.566612</td>\n",
       "      <td>0.461980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254860</td>\n",
       "      <td>0.270285</td>\n",
       "      <td>2.668580</td>\n",
       "      <td>-0.700273</td>\n",
       "      <td>1.808278</td>\n",
       "      <td>-0.358649</td>\n",
       "      <td>0.120045</td>\n",
       "      <td>0.808742</td>\n",
       "      <td>1.012583</td>\n",
       "      <td>0.475709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "484  3.914275  1.430917  3.073586  0.148639  2.727371  0.355025  4.394125   \n",
       "485  3.672175  1.675839  2.581518  0.494772  2.694944  0.422407  3.730156   \n",
       "486  3.890635  1.133280  2.870586 -0.182814  3.454614 -0.304021  4.222064   \n",
       "487  3.662318  1.623327  2.741567  0.302309  2.901100  0.150964  4.110166   \n",
       "\n",
       "         7         8         9     ...      4282      4283      4284  \\\n",
       "484  0.912574  2.934429  0.535574  ...  0.024230  0.066427  2.564982   \n",
       "485  1.304782  2.570597  1.037048  ...  0.916298 -0.533447  2.390451   \n",
       "486  0.555219  3.032418  0.178172  ...  0.406948 -0.201813  2.556703   \n",
       "487  1.023732  2.566612  0.461980  ...  0.254860  0.270285  2.668580   \n",
       "\n",
       "         4285      4286      4287      4288      4289      4290      4291  \n",
       "484 -1.104725  1.516514 -0.361627 -0.514603  1.446447  0.053463  1.075552  \n",
       "485 -0.811287  1.481926 -0.112917 -1.241427  2.090492  0.614429  0.488256  \n",
       "486 -1.471034  1.694347 -0.660910 -0.309917  1.320174  1.168289 -0.344950  \n",
       "487 -0.700273  1.808278 -0.358649  0.120045  0.808742  1.012583  0.475709  \n",
       "\n",
       "[4 rows x 4292 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_exp = par.load_flow_exp(exp_name=\"n_back\")\n",
    "flow_exp.loc[start_idx:end_idx, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hours_of_sleep</th>\n",
       "      <th>trial</th>\n",
       "      <th>block</th>\n",
       "      <th>match</th>\n",
       "      <th>stim_start</th>\n",
       "      <th>stim_end</th>\n",
       "      <th>inter_stim_start</th>\n",
       "      <th>inter_stim_end</th>\n",
       "      <th>correct_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.287123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.390993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.052730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2_back</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.336876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2_back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.860685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2_back</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.655323e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant sex  age  hours_of_sleep  trial   block  match    stim_start  \\\n",
       "0              1   M   25             8.0      1  1_back    0.0  1.655323e+09   \n",
       "1              1   M   25             8.0      1  1_back    0.0  1.655323e+09   \n",
       "2              1   M   25             8.0      1  1_back    0.0  1.655323e+09   \n",
       "3              1   M   25             8.0      1  1_back    0.0  1.655323e+09   \n",
       "4              1   M   25             8.0      1  1_back    0.0  1.655323e+09   \n",
       "..           ...  ..  ...             ...    ...     ...    ...           ...   \n",
       "175            1   M   25             8.0      9  2_back    0.0  1.655323e+09   \n",
       "176            1   M   25             8.0      9  2_back    0.0  1.655323e+09   \n",
       "177            1   M   25             8.0      9  2_back    1.0  1.655323e+09   \n",
       "178            1   M   25             8.0      9  2_back    0.0  1.655323e+09   \n",
       "179            1   M   25             8.0      9  2_back    1.0  1.655323e+09   \n",
       "\n",
       "         stim_end  inter_stim_start  inter_stim_end  correct_response  \\\n",
       "0    1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "1    1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "2    1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "3    1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "4    1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "..            ...               ...             ...               ...   \n",
       "175  1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "176  1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "177  1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "178  1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "179  1.655323e+09      1.655323e+09    1.655323e+09               1.0   \n",
       "\n",
       "     response_time  \n",
       "0         1.287123  \n",
       "1         0.667091  \n",
       "2         0.495045  \n",
       "3         0.514930  \n",
       "4         0.390993  \n",
       "..             ...  \n",
       "175       1.048739  \n",
       "176       1.052730  \n",
       "177       0.336876  \n",
       "178       1.860685  \n",
       "179       0.728680  \n",
       "\n",
       "[180 rows x 13 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hours_of_sleep</th>\n",
       "      <th>trial</th>\n",
       "      <th>block</th>\n",
       "      <th>match</th>\n",
       "      <th>stim</th>\n",
       "      <th>inter_stim_start</th>\n",
       "      <th>inter_stim_end</th>\n",
       "      <th>stim_start</th>\n",
       "      <th>stim_end</th>\n",
       "      <th>correct_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.519317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.655319e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.346970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>GNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_go</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>GNG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.483166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>GNG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.501150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>GNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_go</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>GNG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>go</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.668113e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant sex  age  hours_of_sleep  trial block  match   stim  \\\n",
       "0               1   M   25             8.0      1    go    1.0     go   \n",
       "1               1   M   25             8.0      1    go    1.0     go   \n",
       "2               1   M   25             8.0      1    go    1.0     go   \n",
       "3               1   M   25             8.0      1    go    1.0     go   \n",
       "4               1   M   25             8.0      1    go    1.0     go   \n",
       "...           ...  ..  ...             ...    ...   ...    ...    ...   \n",
       "1195           15   M   21             4.0      4   GNG    0.0  no_go   \n",
       "1196           15   M   21             4.0      4   GNG    1.0     go   \n",
       "1197           15   M   21             4.0      4   GNG    1.0     go   \n",
       "1198           15   M   21             4.0      4   GNG    0.0  no_go   \n",
       "1199           15   M   21             4.0      4   GNG    1.0     go   \n",
       "\n",
       "      inter_stim_start  inter_stim_end    stim_start      stim_end  \\\n",
       "0         1.655319e+09    1.655319e+09  1.655319e+09  1.655319e+09   \n",
       "1         1.655319e+09    1.655319e+09  1.655319e+09  1.655319e+09   \n",
       "2         1.655319e+09    1.655319e+09  1.655319e+09  1.655319e+09   \n",
       "3         1.655319e+09    1.655319e+09  1.655319e+09  1.655319e+09   \n",
       "4         1.655319e+09    1.655319e+09  1.655319e+09  1.655319e+09   \n",
       "...                ...             ...           ...           ...   \n",
       "1195      1.668113e+09             NaN  1.668113e+09  1.668113e+09   \n",
       "1196      1.668113e+09             NaN  1.668113e+09  1.668113e+09   \n",
       "1197      1.668113e+09             NaN  1.668113e+09  1.668113e+09   \n",
       "1198      1.668113e+09             NaN  1.668113e+09  1.668113e+09   \n",
       "1199      1.668113e+09             NaN  1.668113e+09  1.668113e+09   \n",
       "\n",
       "      correct_response  response_time  \n",
       "0                  1.0       0.464158  \n",
       "1                  1.0       0.519317  \n",
       "2                  1.0       0.391665  \n",
       "3                  1.0       0.369224  \n",
       "4                  1.0       0.346970  \n",
       "...                ...            ...  \n",
       "1195               1.0            NaN  \n",
       "1196               1.0       0.483166  \n",
       "1197               1.0       0.501150  \n",
       "1198               0.0       0.455444  \n",
       "1199               1.0       0.555467  \n",
       "\n",
       "[1200 rows x 14 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_results(results_dir, exp_name=\"go_no_go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resting_state': ['1655318597132985856', '1655319046498280192'],\n",
       " 'go_no_go': ['1655319077757890816', 1655319658105890816],\n",
       " 'video_narrative_sherlock': ['1655319701271292160', '1655320221337090304'],\n",
       " 'king_devick': ['1655320708087190272', '1655320812768597504'],\n",
       " 'vSAT': ['1655320849648648960', '1655321297900087808'],\n",
       " 'audio_narrative': ['1655321341378796544', '1655321969673715968'],\n",
       " 'n_back': ['1655322474922427648', '1655323229971006464'],\n",
       " 'tower_of_london': ['1655323376734011904', '1655323800804804096'],\n",
       " 'video_narrative_cmiyc': ['1655323836059942144', '1655324337910405632']}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_index = exp_results.loc[exp_results[\"trial\"] == 9].index[-1]\n",
    "last_row = exp_results.iloc[last_index]\n",
    "last_row[\"stim_end\"]\n",
    "par.par_behav.all_marker_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audio_narrative_behav.csv',\n",
       " 'go_no_go_behav.csv',\n",
       " 'king_devick_behav.csv',\n",
       " 'n_back_behav.csv',\n",
       " 'resting_state_behav.csv',\n",
       " 'tower_of_london_behav.csv',\n",
       " 'video_narrative_cmiyc_behav.csv',\n",
       " 'video_narrative_sherlock_behav.csv',\n",
       " 'vSAT_behav.csv']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_dir = r\"C:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\processed_data\\behavioral\"\n",
    "os.listdir(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1655319653.803778"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = load_results(par_dir, \"go_no_go\", 1)\n",
    "end_ts = float(exp_df.iloc[-1][\"stim_end\"])\n",
    "end_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1655320819.5579717\n",
      "1655320816.5579717\n"
     ]
    }
   ],
   "source": [
    "par_num = 1\n",
    "par = Participant_Flow(par_num) \n",
    "exp_name = \"king_devick\"   \n",
    "exp_results = load_results(results_dir, exp_name, par_num)\n",
    "print(par.par_behav.get_exp(exp_name).end_ts)\n",
    "print(exp_results[\"stim_end\"].iloc[-1])\n",
    "# print(par.par_behav.n_back.start_ts + 755.9447)\n",
    "# print(1655323229971006464/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resting_state',\n",
       " 'go_no_go',\n",
       " 'video_narrative_sherlock',\n",
       " 'king_devick',\n",
       " 'vSAT',\n",
       " 'audio_narrative',\n",
       " 'n_back',\n",
       " 'tower_of_london',\n",
       " 'video_narrative_cmiyc']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par.par_behav.exp_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.plot_flow_exp(\"king_devick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par_num = 1\n",
    "# exp_name = \"n_back\"\n",
    "# exp_results = load_results(results_dir, exp_name, par_num)\n",
    "# flow_exp = par.load_flow_exp(exp_name)\n",
    "# session = par.par_behav.get_key_from_value(\n",
    "#     par.par_behav.session_dict, exp_name\n",
    "# )\n",
    "# ts_list = par.flow_session_dict[session].get_time_abs(\"timestamp\")\n",
    "# data_fun = Data_Functions()\n",
    "# blocks = list(exp_results[\"block\"].unique())\n",
    "# exp_baseline_avg_dict = {block: [] for block in blocks}  # initialize with unique blocks\n",
    "# for _, row in exp_results.iterrows():\n",
    "#     stim_start_ts = row[\"stim_start\"]\n",
    "#     start_idx, _ = data_fun.find_closest_ts(stim_start_ts, ts_list)\n",
    "#     stim_end_ts = row[\"stim_end\"]\n",
    "#     end_idx, _ = data_fun.find_closest_ts(stim_end_ts, ts_list)\n",
    "    \n",
    "#     baseline_row = flow_exp.loc[start_idx, 0:]\n",
    "#     stim_rows = flow_exp.loc[start_idx:end_idx, 0:]\n",
    "#     avg_norm_rows = (stim_rows - baseline_row).mean()  # all channels for a stim\n",
    "#     exp_baseline_avg_dict[row[\"block\"]].append(avg_norm_rows)  # add to block in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No valid timestamp found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m stim_end_ts \u001b[39m=\u001b[39m exp_results\u001b[39m.\u001b[39mloc[exp_results[\u001b[39m'\u001b[39m\u001b[39mparticipant\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m par_num, \u001b[39m'\u001b[39m\u001b[39mstim_end\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]  \u001b[39m# TODO\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data_fun \u001b[39m=\u001b[39m Data_Functions()\n\u001b[1;32m----> 6\u001b[0m start_idx, _ \u001b[39m=\u001b[39m data_fun\u001b[39m.\u001b[39;49mfind_closest_ts(stim_start_ts, ts_list)\n\u001b[0;32m      7\u001b[0m end_idx, _ \u001b[39m=\u001b[39m data_fun\u001b[39m.\u001b[39mfind_closest_ts(stim_end_ts, ts_list)\n\u001b[0;32m      9\u001b[0m flow_exp \u001b[39m=\u001b[39m par\u001b[39m.\u001b[39mload_flow_exp(exp_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mn_back\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zackg\\OneDrive\\Ayaz Lab\\KernelFlow_Analysis\\data_functions.py:712\u001b[0m, in \u001b[0;36mData_Functions.find_closest_ts\u001b[1;34m(self, given_ts, ts_list)\u001b[0m\n\u001b[0;32m    710\u001b[0m valid_ts \u001b[39m=\u001b[39m ts_arr[ts_arr \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m given_ts]\n\u001b[0;32m    711\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(valid_ts) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 712\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo valid timestamp found.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    713\u001b[0m idx \u001b[39m=\u001b[39m bisect\u001b[39m.\u001b[39mbisect_left(valid_ts, given_ts)  \u001b[39m# index of closest timestamp\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mException\u001b[0m: No valid timestamp found."
     ]
    }
   ],
   "source": [
    "ts_list = par.flow_session_dict[\"session_1003\"].get_time_abs(\"timestamp\")\n",
    "stim_start_ts = exp_results.loc[exp_results['participant'] == par_num, 'stim_start'].values[0]  # TODO\n",
    "stim_end_ts = exp_results.loc[exp_results['participant'] == par_num, 'stim_end'].values[0]  # TODO\n",
    "\n",
    "data_fun = Data_Functions()\n",
    "start_idx, _ = data_fun.find_closest_ts(stim_start_ts, ts_list)\n",
    "end_idx, _ = data_fun.find_closest_ts(stim_end_ts, ts_list)\n",
    "\n",
    "flow_exp = par.load_flow_exp(exp_name=\"n_back\")\n",
    "baseline_row = flow_exp.loc[start_idx, 0:]\n",
    "stim_rows = flow_exp.loc[start_idx:end_idx, 0:]\n",
    "avg_rows = (stim_rows - baseline_row).mean()\n",
    "avg_rows\n",
    "\n",
    "\n",
    "# for each participant\n",
    "    # for each experiment\n",
    "        # for each block (all blocks, not just unique)\n",
    "            # for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4282</th>\n",
       "      <th>4283</th>\n",
       "      <th>4284</th>\n",
       "      <th>4285</th>\n",
       "      <th>4286</th>\n",
       "      <th>4287</th>\n",
       "      <th>4288</th>\n",
       "      <th>4289</th>\n",
       "      <th>4290</th>\n",
       "      <th>4291</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-0.2421</td>\n",
       "      <td>0.244921</td>\n",
       "      <td>-0.492068</td>\n",
       "      <td>0.346133</td>\n",
       "      <td>-0.032427</td>\n",
       "      <td>0.067382</td>\n",
       "      <td>-0.663969</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>-0.363832</td>\n",
       "      <td>0.501474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892068</td>\n",
       "      <td>-0.599874</td>\n",
       "      <td>-0.174531</td>\n",
       "      <td>0.293438</td>\n",
       "      <td>-0.034588</td>\n",
       "      <td>0.248709</td>\n",
       "      <td>-0.726824</td>\n",
       "      <td>0.644045</td>\n",
       "      <td>0.560967</td>\n",
       "      <td>-0.587296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>-0.023641</td>\n",
       "      <td>-0.297637</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.331453</td>\n",
       "      <td>0.727243</td>\n",
       "      <td>-0.659046</td>\n",
       "      <td>-0.172061</td>\n",
       "      <td>-0.357354</td>\n",
       "      <td>0.097989</td>\n",
       "      <td>-0.357402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382719</td>\n",
       "      <td>-0.268239</td>\n",
       "      <td>-0.008279</td>\n",
       "      <td>-0.366309</td>\n",
       "      <td>0.177833</td>\n",
       "      <td>-0.299284</td>\n",
       "      <td>0.204685</td>\n",
       "      <td>-0.126273</td>\n",
       "      <td>1.114826</td>\n",
       "      <td>-1.420502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>-0.251958</td>\n",
       "      <td>0.19241</td>\n",
       "      <td>-0.33202</td>\n",
       "      <td>0.15367</td>\n",
       "      <td>0.173729</td>\n",
       "      <td>-0.204061</td>\n",
       "      <td>-0.28396</td>\n",
       "      <td>0.111158</td>\n",
       "      <td>-0.367817</td>\n",
       "      <td>-0.073594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23063</td>\n",
       "      <td>0.203858</td>\n",
       "      <td>0.103599</td>\n",
       "      <td>0.404452</td>\n",
       "      <td>0.291764</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.634647</td>\n",
       "      <td>-0.637705</td>\n",
       "      <td>0.95912</td>\n",
       "      <td>-0.599843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "484       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "485   -0.2421  0.244921 -0.492068  0.346133 -0.032427  0.067382 -0.663969   \n",
       "486 -0.023641 -0.297637    -0.203 -0.331453  0.727243 -0.659046 -0.172061   \n",
       "487 -0.251958   0.19241  -0.33202   0.15367  0.173729 -0.204061  -0.28396   \n",
       "\n",
       "         7         8         9     ...      4282      4283      4284  \\\n",
       "484       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "485  0.392208 -0.363832  0.501474  ...  0.892068 -0.599874 -0.174531   \n",
       "486 -0.357354  0.097989 -0.357402  ...  0.382719 -0.268239 -0.008279   \n",
       "487  0.111158 -0.367817 -0.073594  ...   0.23063  0.203858  0.103599   \n",
       "\n",
       "         4285      4286      4287      4288      4289      4290      4291  \n",
       "484       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "485  0.293438 -0.034588  0.248709 -0.726824  0.644045  0.560967 -0.587296  \n",
       "486 -0.366309  0.177833 -0.299284  0.204685 -0.126273  1.114826 -1.420502  \n",
       "487  0.404452  0.291764  0.002978  0.634647 -0.637705   0.95912 -0.599843  \n",
       "\n",
       "[4 rows x 4292 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_rows - baseline_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12942475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean\n",
    "mean([-.2421, -0.023641, -0.251958, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment order: ['resting_state', 'go_no_go', 'video_narrative_sherlock', 'king_devick', 'vSAT', 'audio_narrative', 'n_back', 'tower_of_london', 'video_narrative_cmiyc']\n",
      "\n",
      "Experiment time origin: 2022-06-15 14:43:17.132986\n",
      "Start marker sent time: 11.6911\n",
      "Start marker sent time (absolute): 2022-06-15 14:43:28.824086\n",
      "Flow time origin: 2022-06-15 18:43:22\n",
      "\n",
      "Kernel marker data (original):\n",
      "     Timestamp    Duration  Value  Experiment\n",
      "0    19.105127  441.473551    1.0        51.0\n",
      "1  1120.861606  514.570869    1.0        81.0\n",
      "\n",
      "Kernel marker data (absolute):\n",
      "                           Marker  Start timestamp    Duration  End timestamp\n",
      "0             resting_state_start     1.655319e+09  441.473551   1.655319e+09\n",
      "1  video_narrative_sherlock_start     1.655320e+09  514.570869   1.655320e+09\n",
      "\n",
      "Time offset: 12.281\n"
     ]
    }
   ],
   "source": [
    "print(f\"Experiment order: {par.par_behav.exp_order}\\n\")\n",
    "\n",
    "exp_name = \"resting_state\"\n",
    "exp = par.par_behav.get_exp(exp_name)\n",
    "exp_time_origin_ts = exp.start_ts\n",
    "exp_time_origin_dt = datetime.datetime.fromtimestamp(exp_time_origin_ts)\n",
    "print(f\"Experiment time origin: {exp_time_origin_dt}\")\n",
    "start_marker_sent_time = float(exp.marker_data[\"start_marker\"][\"sent_time\"])\n",
    "print(f\"Start marker sent time: {start_marker_sent_time}\")\n",
    "start_marker_sent_time_abs = exp_time_origin_dt + datetime.timedelta(seconds=start_marker_sent_time)\n",
    "print(f\"Start marker sent time (absolute): {start_marker_sent_time_abs}\")\n",
    "\n",
    "# The behavioral start marker sent time (absolute) and \n",
    "# kernel start marker receive time (absolute) should be identical.\n",
    "\n",
    "flow_time_origin = par.flow_session_dict[\"session_1001\"].get_time_origin(offset=False)\n",
    "print(f\"Flow time origin: {flow_time_origin}\\n\")\n",
    "session = par.par_behav.get_key_from_value(par.par_behav.session_dict, exp_name)\n",
    "marker_df = par.flow_session_dict[session].get_marker_df()\n",
    "print(f\"Kernel marker data (original):\\n{marker_df}\\n\")\n",
    "marker_df_abs = par.create_abs_marker_df(session)\n",
    "print(f\"Kernel marker data (absolute):\\n{marker_df_abs}\")\n",
    "\n",
    "row = marker_df_abs.loc[marker_df_abs[\"Marker\"].str.startswith(exp_name)].reset_index()\n",
    "kernel_start_marker_ts = row.loc[0, \"Start timestamp\"]\n",
    "time_offset = kernel_start_marker_ts - (exp_time_origin_ts + start_marker_sent_time)\n",
    "print(f\"\\nTime offset: {round(time_offset, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference:\n",
      "------------\n",
      "12.281, resting_state\n",
      "12.285, video_narrative_sherlock\n",
      "11.98, king_devick\n",
      "11.981, vSAT\n",
      "11.983, audio_narrative\n",
      "12.577, n_back\n",
      "12.58, tower_of_london\n",
      "12.582, video_narrative_cmiyc\n"
     ]
    }
   ],
   "source": [
    "# Time offset issue\n",
    "# Kernel Flow PC - Behavioral Task PC\n",
    "par_num = 1\n",
    "par = Participant_Flow(par_num)\n",
    "time_offset_list = []\n",
    "print(\"Time difference:\\n------------\")\n",
    "for exp_name in par.par_behav.exp_order:\n",
    "    try:\n",
    "        time_offset = round(par.get_time_offset(exp_name), 3)\n",
    "        time_offset_list.append(time_offset)\n",
    "        print(f\"{time_offset}, {exp_name}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m# Plot the original and filtered signals\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m plt\u001b[39m.\u001b[39;49mplot(t, x, \u001b[39m'\u001b[39;49m\u001b[39mb-\u001b[39;49m\u001b[39m'\u001b[39;49m, linewidth\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUnfiltered signal\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m plt\u001b[39m.\u001b[39mplot(t, y, \u001b[39m'\u001b[39m\u001b[39mr-\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFiltered signal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\pyplot.py:2728\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2726\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2727\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2728\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2729\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2730\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mpl_toolkits\\mplot3d\\axes3d.py:1303\u001b[0m, in \u001b[0;36mAxes3D.plot\u001b[1;34m(self, xs, ys, zdir, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     art3d\u001b[39m.\u001b[39mline_2d_to_3d(line, zs\u001b[39m=\u001b[39mzs, zdir\u001b[39m=\u001b[39mzdir)\n\u001b[0;32m   1302\u001b[0m xs, ys, zs \u001b[39m=\u001b[39m art3d\u001b[39m.\u001b[39mjuggle_axes(xs, ys, zs, zdir)\n\u001b[1;32m-> 1303\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_scale_xyz(xs, ys, zs, had_data)\n\u001b[0;32m   1304\u001b[0m \u001b[39mreturn\u001b[39;00m lines\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mpl_toolkits\\mplot3d\\axes3d.py:575\u001b[0m, in \u001b[0;36mAxes3D.auto_scale_xyz\u001b[1;34m(self, X, Y, Z, had_data)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_scale_xyz\u001b[39m(\u001b[39mself\u001b[39m, X, Y, Z\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, had_data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    572\u001b[0m     \u001b[39m# This updates the bounding boxes as to keep a record as to what the\u001b[39;00m\n\u001b[0;32m    573\u001b[0m     \u001b[39m# minimum sized rectangular volume holds the data.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mshape(X) \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mshape(Y):\n\u001b[1;32m--> 575\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxy_dataLim\u001b[39m.\u001b[39;49mupdate_from_data_xy(\n\u001b[0;32m    576\u001b[0m             np\u001b[39m.\u001b[39;49mcolumn_stack([np\u001b[39m.\u001b[39;49mravel(X), np\u001b[39m.\u001b[39;49mravel(Y)]), \u001b[39mnot\u001b[39;49;00m had_data)\n\u001b[0;32m    577\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxy_dataLim\u001b[39m.\u001b[39mupdate_from_data_x(X, \u001b[39mnot\u001b[39;00m had_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\transforms.py:954\u001b[0m, in \u001b[0;36mBbox.update_from_data_xy\u001b[1;34m(self, xy, ignore, updatex, updatey)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xy) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    952\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m path \u001b[39m=\u001b[39m Path(xy)\n\u001b[0;32m    955\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_from_path(path, ignore\u001b[39m=\u001b[39mignore,\n\u001b[0;32m    956\u001b[0m                       updatex\u001b[39m=\u001b[39mupdatex, updatey\u001b[39m=\u001b[39mupdatey)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\path.py:129\u001b[0m, in \u001b[0;36mPath.__init__\u001b[1;34m(self, vertices, codes, _interpolation_steps, closed, readonly)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, vertices, codes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _interpolation_steps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    100\u001b[0m              closed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, readonly\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    101\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m    Create a new path with the given vertices and codes.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m        and codes as read-only arrays.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     vertices \u001b[39m=\u001b[39m _to_unmasked_float_array(vertices)\n\u001b[0;32m    130\u001b[0m     _api\u001b[39m.\u001b[39mcheck_shape((\u001b[39mNone\u001b[39;00m, \u001b[39m2\u001b[39m), vertices\u001b[39m=\u001b[39mvertices)\n\u001b[0;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m codes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\cbook\\__init__.py:1369\u001b[0m, in \u001b[0;36m_to_unmasked_float_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39masarray(x, \u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39mfilled(np\u001b[39m.\u001b[39mnan)\n\u001b[0;32m   1368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1369\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(x, \u001b[39mfloat\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import firwin, lfilter\n",
    "\n",
    "# Define the filter parameters\n",
    "order = 20\n",
    "fs = 1.0  # Sampling frequency (Hz)\n",
    "cutoff = 0.1  # Cut-off frequency (Hz)\n",
    "\n",
    "# Design the filter coefficients using the firwin function\n",
    "nyq = 0.5 * fs\n",
    "taps = firwin(order + 1, cutoff/nyq)\n",
    "\n",
    "# Generate a signal\n",
    "t = par.flow_session_dict[\"session_1001\"].get_time_abs(\"datetime\")[0:11000]\n",
    "x = par.flow_session_dict[\"session_1001\"].get_data(\"array\", 0)[0:11000]\n",
    "\n",
    "# Apply the filter using the lfilter function\n",
    "y = lfilter(taps, 1.0, x)\n",
    "\n",
    "# Plot the original and filtered signals\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(t, x, 'b-', linewidth=1, alpha=0.5, label='Unfiltered signal')\n",
    "plt.plot(t, y, 'r-', linewidth=2, label='Filtered signal')\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c1e24752b3065052c27c07c0a22748a6118d05dd89b50e77c79e7ce74e5970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
